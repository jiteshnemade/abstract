{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTDIR = \"./prepro/text/\"\n",
    "ABSTRACTDIR = \"./prepro/abstract/\"\n",
    "CLEANEDDIR= \"./prepro/cleaned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files=os.listdir(TEXTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1303.5778v1.Speech_Recognition_with_Deep_Recurrent_Neural_Networks.txt',\n",
       " '1312.6026v5.How_to_Construct_Deep_Recurrent_Neural_Networks.txt',\n",
       " '1402.1128v1.Long_Short_Term_Memory_Based_Recurrent_Neural_Network_Architectures_for_Large_Vocabulary_Speech_Recognition.txt',\n",
       " '1402.3511v1.A_Clockwork_RNN.txt',\n",
       " '1412.7927v1.Polyphonic_Music_Generation_by_Modeling_Temporal_Dependencies_Using_a_RNN_DBN.txt',\n",
       " '1502.02367v4.Gated_Feedback_Recurrent_Neural_Networks.txt',\n",
       " '1504.01483v1.Transferring_Knowledge_from_a_RNN_to_a_DNN.txt',\n",
       " '1504.08025v2.Note_on_Equivalence_Between_Recurrent_Neural_Network_Time_Series_Models_and_Variational_Bayesian_Models.txt',\n",
       " '1509.00552v2.DAG_Recurrent_Neural_Networks_For_Scene_Labeling.txt',\n",
       " '1509.05329v1.Recurrent_Spatial_Transformer_Networks.txt',\n",
       " '1510.04953v1.Optimizing_and_Contrasting_Recurrent_Neural_Network_Architectures.txt',\n",
       " '1511.01169v5.adaQN_An_Adaptive_Quasi_Newton_Algorithm_for_Training_RNNs.txt',\n",
       " '1511.05552v4.Recurrent_Neural_Networks_Hardware_Implementation_on_FPGA.txt',\n",
       " '1511.08400v7.Regularizing_RNNs_by_Stabilizing_Activations.txt',\n",
       " '1512.03958v1.RNN_Fisher_Vectors_for_Action_Recognition_and_Image_Annotation.txt',\n",
       " '1602.01895v1.Generate_Image_Descriptions_based_on_Deep_RNN_and_Memory_Cells_for_Images_Features.txt',\n",
       " '1602.04335v1.Learning_Over_Long_Time_Lags.txt',\n",
       " '1602.07749v1.Toward_Mention_Detection_Robustness_with_Recurrent_Neural_Networks.txt',\n",
       " '1603.05118v2.Recurrent_Dropout_without_Memory_Loss.txt',\n",
       " '1603.09420v1.Minimal_Gated_Unit_for_Recurrent_Neural_Networks.txt',\n",
       " '1604.03640v1.Bridging_the_Gaps_Between_Residual_Learning_Recurrent_Neural_Networks_and_Visual_Cortex.txt',\n",
       " '1604.05358v1.Text_based_LSTM_networks_for_Automatic_Music_Composition.txt',\n",
       " '1605.00064v1.Higher_Order_Recurrent_Neural_Networks.txt',\n",
       " '1605.01988v3.LSTM_with_Working_Memory.txt',\n",
       " '1606.02096v1.Towards_Playlist_Generation_Algorithms_Using_RNNs_Trained_on_Within_Track_Transitions.txt',\n",
       " '1606.02555v1.Improving_Recurrent_Neural_Networks_For_Sequence_Labelling.txt',\n",
       " '1606.06630v2.On_Multiplicative_Integration_with_Recurrent_Neural_Networks.txt',\n",
       " '1608.04080v1.Dynamic_Hand_Gesture_Recognition_for_Wearable_Devices_with_Low_Complexity_Recurrent_Neural_Networks.txt',\n",
       " '1609.07724v1.The_RNN_ELM_Classifier.txt',\n",
       " '1609.08209v1.Automatic_Construction_of_a_Recurrent_Neural_Network_based_Classifier_for_Vehicle_Passage_Detection.txt',\n",
       " '1609.09171v2.Empirical_Evaluation_of_RNN_Architectures_on_Sentence_Classification_Task.txt',\n",
       " '1611.05490v1.Semantic_Regularisation_for_Recurrent_Image_Annotation.txt',\n",
       " '1611.06668v2.MV_RNN_A_Multi_View_Recurrent_Neural_Network_for_Sequential_Recommendation.txt',\n",
       " '1611.07065v2.Recurrent_Neural_Networks_With_Limited_Numerical_Precision.txt',\n",
       " '1611.07485v2.Scene_Labeling_using_Gated_Recurrent_Units_with_Explicit_Long_Range_Conditioning.txt',\n",
       " '1612.04687v2.Real_time_interactive_sequence_generation_and_control_with_Recurrent_Neural_Network_ensembles.txt',\n",
       " '1702.01923v1.Comparative_Study_of_CNN_and_RNN_for_Natural_Language_Processing.txt',\n",
       " '1702.07805v4.Analyzing_and_Exploiting_NARX_Recurrent_Neural_Networks_for_Long_Term_Dependencies.txt',\n",
       " '1703.07841v1.Classification_based_RNN_machine_translation_using_GRUs.txt',\n",
       " '1703.10089v2.Position_based_Content_Attention_for_Time_Series_Forecasting_with_Sequence_to_sequence_RNNs.txt',\n",
       " '1704.02581v2.Modeling_Temporal_Dynamics_and_Spatial_Configurations_of_Actions_Using_Two_Stream_Recurrent_Neural_Networks.txt',\n",
       " '1704.05420v2.Diagonal_RNNs_in_Symbolic_Music_Modeling.txt',\n",
       " '1705.01020v1.Modeling_Source_Syntax_for_Neural_Machine_Translation.txt',\n",
       " '1705.08052v1.Compressing_Recurrent_Neural_Network_with_Tensor_Train.txt',\n",
       " '1705.08131v1.Black_Box_Attacks_against_RNN_based_Malware_Detection_Algorithms.txt',\n",
       " '1705.08639v2.Fast_Slow_Recurrent_Neural_Networks.txt',\n",
       " '1706.01740v1.Label_Dependencies_Aware_Recurrent_Neural_Networks.txt',\n",
       " '1706.02222v1.Gated_Recurrent_Neural_Tensor_Network.txt',\n",
       " '1706.02761v3.Gated_Orthogonal_Recurrent_Units_On_Learning_to_Forget.txt',\n",
       " '1706.03542v1.Exploring_the_Syntactic_Abilities_of_RNNs_with_Multi_task_Learning.txt',\n",
       " '1706.07506v1.Inter_Session_Modeling_for_Session_Based_Recommendation.txt',\n",
       " '1707.01265v2.Multiple_Range_Restricted_Bidirectional_Gated_Recurrent_Units_with_Attention_for_Relation_Classification.txt',\n",
       " '1707.07631v1.Deep_Architectures_for_Neural_Machine_Translation.txt',\n",
       " '1708.01009v1.Revisiting_Activation_Regularization_for_Language_RNNs.txt',\n",
       " '1708.02043v2.What_is_the_Role_of_Recurrent_Neural_Networks_RNNs_in_an_Image_Caption_Generator.txt',\n",
       " '1709.02232v1.RNN_based_Early_Cyber_Attack_Detection_for_the_Tennessee_Eastman_Process.txt',\n",
       " '1709.04005v2.Addressee_and_Response_Selection_in_Multi_Party_Conversations_with_Speaker_Interaction_RNNs.txt',\n",
       " '1709.04057v2.Parallelizing_Linear_Recurrent_Neural_Nets_Over_Sequence_Length.txt',\n",
       " '1709.06404v1.Interactive_Music_Generation_with_Positional_Constraints_using_Anticipation_RNNs.txt',\n",
       " '1709.07626v1.BreathRNNet_Breathing_Based_Authentication_on_Resource_Constrained_IoT_Devices_using_RNNs.txt',\n",
       " '1709.08907v2.Input_to_Output_Gate_to_Improve_RNN_Language_Models.txt',\n",
       " '1710.02603v2.Low_Rank_RNN_Adaptation_for_Context_Aware_Language_Modeling.txt',\n",
       " '1710.03414v1.Network_of_Recurrent_Neural_Networks.txt',\n",
       " '1710.07706v1.Low_Precision_RNNs_Quantizing_RNNs_Without_Losing_Accuracy.txt',\n",
       " '1710.10197v1.Advanced_LSTM_A_Study_about_Better_Time_Dependency_Modeling_in_Emotion_Recognition.txt',\n",
       " '1711.02809v2.A_New_Hybrid_parameter_Recurrent_Neural_Networks_for_Online_Handwritten_Chinese_Character_Recognition.txt',\n",
       " '1711.05734v2.Chipmunk_A_Systolically_Scalable_0_9_mm_2_3_08_Gop_s_mW_1_2_mW_Accelerator_for_Near_Sensor_Recurrent_Neural_Network_Inference.txt',\n",
       " '1711.06788v2.MinimalRNN_Toward_More_Interpretable_and_Trainable_Recurrent_Neural_Networks.txt',\n",
       " '1712.05134v2.Learning_Compact_Recurrent_Neural_Networks_with_Block_Term_Tensor_Decomposition.txt',\n",
       " '1712.07316v1.A_Flexible_Approach_to_Automated_RNN_Architecture_Generation.txt',\n",
       " '1801.04340v4.Predicting_Future_Lane_Changes_of_Other_Highway_Vehicles_using_RNN_based_Deep_Models.txt',\n",
       " '1801.06831v1.Dense_Recurrent_Neural_Networks_for_Scene_Labeling.txt',\n",
       " '1801.08322v3.Phonocardiographic_Sensing_using_Deep_Learning_for_Abnormal_Heartbeat_Detection.txt',\n",
       " '1802.10410v2.Tensor_Decomposition_for_Compressing_Recurrent_Neural_Network.txt',\n",
       " '1803.04687v1.Multimodal_Recurrent_Neural_Networks_with_Information_Transfer_Layers_for_Indoor_Scene_Labeling.txt',\n",
       " '1803.05383v1.Use_of_recurrent_infomax_to_improve_the_memory_capability_of_input_driven_recurrent_neural_networks.txt',\n",
       " '1803.11138v1.Colorless_green_recurrent_networks_dream_hierarchically.txt',\n",
       " '1804.06511v1.Fast_Weight_Long_Short_Term_Memory.txt',\n",
       " '1805.02983v1.Augmenting_Recurrent_Neural_Networks_with_High_Order_User_Contextual_Preference_for_Session_Based_Recommendation.txt',\n",
       " '1805.04908v1.On_the_Practical_Computational_Power_of_Finite_Precision_RNNs_for_Language_Recognition.txt',\n",
       " '1805.07869v1.Learning_Device_Models_with_Recurrent_Neural_Networks.txt',\n",
       " '1805.12098v1.Context_aware_Cascade_Attention_based_RNN_for_Video_Emotion_Recognition.txt',\n",
       " '1806.00526v1.Multi_Step_Prediction_of_Dynamic_Systems_with_Recurrent_Neural_Networks.txt',\n",
       " '1807.01705v1.Transfer_Learning_for_Clinical_Time_Series_Analysis_using_Recurrent_Neural_Networks.txt',\n",
       " '1808.01591v1.LISA_Explaining_Recurrent_Neural_Network_Judgments_via_Layer_wIse_Semantic_Accumulation_and_Example_to_Pattern_Transformation.txt',\n",
       " '1808.02608v1.End_to_end_Speech_Recognition_with_Word_based_RNN_Language_Models.txt',\n",
       " '1808.06170v1.Linked_Recurrent_Neural_Networks.txt',\n",
       " '1809.00042v1.What_do_RNN_Language_Models_Learn_about_Filler_Gap_Dependencies.txt',\n",
       " '1809.02836v1.Context_Free_Transductions_with_Neural_Stacks.txt',\n",
       " '1810.10999v1.Reversible_Recurrent_Neural_Networks.txt',\n",
       " '1810.12563v1.Shorten_Spatial_spectral_RNN_with_Parallel_GRU_for_Hyperspectral_Image_Classification.txt',\n",
       " '1811.01866v1.Do_RNNs_learn_human_like_abstract_word_order_preferences.txt',\n",
       " '1811.04778v1.Scene_Parsing_via_Dense_Recurrent_Neural_Networks_with_Attentional_Selection.txt',\n",
       " '1811.09961v4.Deep_RNN_Framework_for_Visual_Sequential_Applications.txt',\n",
       " '1812.07609v2.RNNFast_An_Accelerator_for_Recurrent_Neural_Networks_Using_Domain_Wall_Memory.txt',\n",
       " '1812.11527v2.Comparison_between_DeepESNs_and_gated_RNNs_on_multivariate_time_series_prediction.txt',\n",
       " '1901.02358v1.FastGRNN_A_Fast_Accurate_Stable_and_Tiny_Kilobyte_Sized_Gated_Recurrent_Neural_Network.txt',\n",
       " '1901.04281v1.RNNSecureNet_Recurrent_neural_networks_for_Cyber_security_use_cases.txt',\n",
       " '1901.05574v1.Visual_Reasoning_of_Feature_Attribution_with_Deep_Recurrent_Neural_Networks.txt',\n",
       " '1901.07859v1.How_do_Mixture_Density_RNNs_Predict_the_Future.txt',\n",
       " '1901.10400v1.Predicting_Individual_Responses_to_Vasoactive_Medications_in_Children_with_Septic_Shock.txt',\n",
       " '1902.01739v2.An_RNN_based_IMM_Filter_Surrogate.txt',\n",
       " '1902.02390v2.Investigating_Recurrent_Neural_Network_Memory_Structures_using_Neuro_Evolution.txt',\n",
       " '1902.02627v2.Fast_Transient_Simulation_of_High_Speed_Channels_Using_Recurrent_Neural_Network.txt',\n",
       " '1902.03455v1.Contextual_Recurrent_Neural_Networks.txt',\n",
       " '1902.10297v1.Representing_Formal_Languages_A_Comparison_Between_Finite_Automata_and_Recurrent_Neural_Networks.txt',\n",
       " '1902.10858v1.Cascaded_Recurrent_Neural_Networks_for_Hyperspectral_Image_Classification.txt',\n",
       " '1903.01341v1.Using_stigmergy_as_a_computational_memory_in_the_design_of_recurrent_neural_networks.txt',\n",
       " '1903.05609v2.Realization_theory_of_recurrent_neural_networks_and_rational_systems.txt',\n",
       " '1903.11703v2.Recurrent_Neural_Networks_For_Accurate_RSSI_Indoor_Localization.txt',\n",
       " '1904.00291v1.Two_phase_flow_regime_prediction_using_LSTM_based_deep_recurrent_neural_network.txt',\n",
       " '1904.03302v1.Measuring_scheduling_efficiency_of_RNNs_for_NLP_applications.txt',\n",
       " '1904.12933v1.Recurrent_Neural_Networks_in_the_Eye_of_Differential_Equations.txt',\n",
       " '1905.08527v1.CNNs_found_to_jump_around_more_skillfully_than_RNNs_Compositional_generalization_in_seq2seq_convolutional_networks.txt',\n",
       " '1905.09691v1.Population_based_Global_Optimisation_Methods_for_Learning_Long_term_Dependencies_with_RNNs.txt',\n",
       " '1905.12340v1.Rethinking_Full_Connectivity_in_Recurrent_Neural_Networks.txt',\n",
       " '1907.03329v1.Fast_ES_RNN_A_GPU_Implementation_of_the_ES_RNN_Algorithm.txt',\n",
       " '1907.03907v1.Latent_ODEs_for_Irregularly_Sampled_Time_Series.txt',\n",
       " '1907.11848v1.Recurrent_Neural_Networks_with_Long_Term_Temporal_Dependencies_in_Machine_Tool_Wear_Diagnosis_and_Prognosis.txt',\n",
       " '1908.07062v3.Recurrent_Neural_Networks_An_Embedded_Computing_Perspective.txt',\n",
       " '1908.08976v1.MASR_A_Modular_Accelerator_for_Sparse_RNNs.txt',\n",
       " '1909.00021v1.A_single_layer_RNN_can_approximate_stacked_and_bidirectional_RNNs_and_topologies_in_between.txt',\n",
       " '1909.02279v1.Accelerating_Transformer_Decoding_via_a_Hybrid_of_Self_attention_and_Recurrent_Neural_Network.txt',\n",
       " '1909.03082v1.One_Size_Does_Not_Fit_All_Multi_Scale_Cascaded_RNNs_for_Radar_Classification.txt',\n",
       " '1909.05414v1.Time_weighted_Attentional_Session_Aware_Recommender_System.txt',\n",
       " '1910.02558v2.Pushing_the_limits_of_RNN_Compression.txt',\n",
       " '1911.07806v2.Action_Anticipation_with_RBF_Kernelized_Feature_Mapping_RNN.txt',\n",
       " '2001.00058v1.Towards_Improving_the_Performance_of_the_RNN_based_Inversion_Model_in_Output_Tracking_Control.txt',\n",
       " '2002.02805v1.Short_Term_Blood_Glucose_Prediction_based_on_Continuous_Glucose_Monitoring_Data.txt',\n",
       " '2002.05615v1.Verifiable_RNN_Based_Policies_for_POMDPs_Under_Temporal_Logic_Constraints.txt',\n",
       " '2002.07422v1.Assessing_the_Memory_Ability_of_Recurrent_Neural_Networks.txt',\n",
       " '2002.11474v1.RTMobile_Beyond_Real_Time_Mobile_Acceleration_of_RNNs_for_Speech_Recognition.txt',\n",
       " '2003.03601v1.RNN_based_Online_Learning_An_Efficient_First_Order_Optimization_Algorithm_with_a_Convergence_Guarantee.txt',\n",
       " '2004.00478v1.Distance_and_Equivalence_between_Finite_State_Machines_and_Recurrent_Neural_Networks_Computational_results.txt',\n",
       " '2004.05290v1.Convex_Sets_of_Robust_Recurrent_Neural_Networks.txt',\n",
       " '2004.08013v1.How_recurrent_networks_implement_contextual_processing_in_sentiment_analysis.txt',\n",
       " '2004.13838v1.How_Chaotic_Are_Recurrent_Neural_Networks.txt',\n",
       " '2005.04366v1.Compressing_Recurrent_Neural_Networks_Using_Hierarchical_Tucker_Tensor_Decomposition.txt',\n",
       " '2005.05758v1.CSB_RNN_A_Faster_than_Realtime_RNN_Acceleration_Framework_with_Compressed_Structured_Blocks.txt',\n",
       " '2005.09471v1.Comparing_Transformers_and_RNNs_on_predicting_human_sentence_processing_data.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303.5778v1.Speech_Recognition_with_Deep_Recurrent_Neural_Networks.txt\n",
      "1312.6026v5.How_to_Construct_Deep_Recurrent_Neural_Networks.txt\n",
      "1402.1128v1.Long_Short_Term_Memory_Based_Recurrent_Neural_Network_Architectures_for_Large_Vocabulary_Speech_Recognition.txt\n",
      "1402.3511v1.A_Clockwork_RNN.txt\n",
      "1412.7927v1.Polyphonic_Music_Generation_by_Modeling_Temporal_Dependencies_Using_a_RNN_DBN.txt\n",
      "1502.02367v4.Gated_Feedback_Recurrent_Neural_Networks.txt\n",
      "1504.01483v1.Transferring_Knowledge_from_a_RNN_to_a_DNN.txt\n",
      "1504.08025v2.Note_on_Equivalence_Between_Recurrent_Neural_Network_Time_Series_Models_and_Variational_Bayesian_Models.txt\n",
      "1509.00552v2.DAG_Recurrent_Neural_Networks_For_Scene_Labeling.txt\n",
      "1509.05329v1.Recurrent_Spatial_Transformer_Networks.txt\n",
      "1510.04953v1.Optimizing_and_Contrasting_Recurrent_Neural_Network_Architectures.txt\n",
      "1511.01169v5.adaQN_An_Adaptive_Quasi_Newton_Algorithm_for_Training_RNNs.txt\n",
      "1511.05552v4.Recurrent_Neural_Networks_Hardware_Implementation_on_FPGA.txt\n",
      "1511.08400v7.Regularizing_RNNs_by_Stabilizing_Activations.txt\n",
      "1512.03958v1.RNN_Fisher_Vectors_for_Action_Recognition_and_Image_Annotation.txt\n",
      "1602.01895v1.Generate_Image_Descriptions_based_on_Deep_RNN_and_Memory_Cells_for_Images_Features.txt\n",
      "1602.04335v1.Learning_Over_Long_Time_Lags.txt\n",
      "1602.07749v1.Toward_Mention_Detection_Robustness_with_Recurrent_Neural_Networks.txt\n",
      "1603.05118v2.Recurrent_Dropout_without_Memory_Loss.txt\n",
      "1603.09420v1.Minimal_Gated_Unit_for_Recurrent_Neural_Networks.txt\n",
      "1604.03640v1.Bridging_the_Gaps_Between_Residual_Learning_Recurrent_Neural_Networks_and_Visual_Cortex.txt\n",
      "1604.05358v1.Text_based_LSTM_networks_for_Automatic_Music_Composition.txt\n",
      "1605.00064v1.Higher_Order_Recurrent_Neural_Networks.txt\n",
      "1605.01988v3.LSTM_with_Working_Memory.txt\n",
      "1606.02096v1.Towards_Playlist_Generation_Algorithms_Using_RNNs_Trained_on_Within_Track_Transitions.txt\n",
      "1606.02555v1.Improving_Recurrent_Neural_Networks_For_Sequence_Labelling.txt\n",
      "1606.06630v2.On_Multiplicative_Integration_with_Recurrent_Neural_Networks.txt\n",
      "1608.04080v1.Dynamic_Hand_Gesture_Recognition_for_Wearable_Devices_with_Low_Complexity_Recurrent_Neural_Networks.txt\n",
      "1609.07724v1.The_RNN_ELM_Classifier.txt\n",
      "1609.08209v1.Automatic_Construction_of_a_Recurrent_Neural_Network_based_Classifier_for_Vehicle_Passage_Detection.txt\n",
      "1609.09171v2.Empirical_Evaluation_of_RNN_Architectures_on_Sentence_Classification_Task.txt\n",
      "1611.05490v1.Semantic_Regularisation_for_Recurrent_Image_Annotation.txt\n",
      "1611.06668v2.MV_RNN_A_Multi_View_Recurrent_Neural_Network_for_Sequential_Recommendation.txt\n",
      "1611.07065v2.Recurrent_Neural_Networks_With_Limited_Numerical_Precision.txt\n",
      "1611.07485v2.Scene_Labeling_using_Gated_Recurrent_Units_with_Explicit_Long_Range_Conditioning.txt\n",
      "1612.04687v2.Real_time_interactive_sequence_generation_and_control_with_Recurrent_Neural_Network_ensembles.txt\n",
      "1702.01923v1.Comparative_Study_of_CNN_and_RNN_for_Natural_Language_Processing.txt\n",
      "1702.07805v4.Analyzing_and_Exploiting_NARX_Recurrent_Neural_Networks_for_Long_Term_Dependencies.txt\n",
      "1703.07841v1.Classification_based_RNN_machine_translation_using_GRUs.txt\n",
      "1703.10089v2.Position_based_Content_Attention_for_Time_Series_Forecasting_with_Sequence_to_sequence_RNNs.txt\n",
      "1704.02581v2.Modeling_Temporal_Dynamics_and_Spatial_Configurations_of_Actions_Using_Two_Stream_Recurrent_Neural_Networks.txt\n",
      "1704.05420v2.Diagonal_RNNs_in_Symbolic_Music_Modeling.txt\n",
      "1705.01020v1.Modeling_Source_Syntax_for_Neural_Machine_Translation.txt\n",
      "1705.08052v1.Compressing_Recurrent_Neural_Network_with_Tensor_Train.txt\n",
      "1705.08131v1.Black_Box_Attacks_against_RNN_based_Malware_Detection_Algorithms.txt\n",
      "1705.08639v2.Fast_Slow_Recurrent_Neural_Networks.txt\n",
      "1706.01740v1.Label_Dependencies_Aware_Recurrent_Neural_Networks.txt\n",
      "1706.02222v1.Gated_Recurrent_Neural_Tensor_Network.txt\n",
      "1706.02761v3.Gated_Orthogonal_Recurrent_Units_On_Learning_to_Forget.txt\n",
      "1706.03542v1.Exploring_the_Syntactic_Abilities_of_RNNs_with_Multi_task_Learning.txt\n",
      "1706.07506v1.Inter_Session_Modeling_for_Session_Based_Recommendation.txt\n",
      "1707.01265v2.Multiple_Range_Restricted_Bidirectional_Gated_Recurrent_Units_with_Attention_for_Relation_Classification.txt\n",
      "1707.07631v1.Deep_Architectures_for_Neural_Machine_Translation.txt\n",
      "1708.01009v1.Revisiting_Activation_Regularization_for_Language_RNNs.txt\n",
      "1708.02043v2.What_is_the_Role_of_Recurrent_Neural_Networks_RNNs_in_an_Image_Caption_Generator.txt\n",
      "1709.02232v1.RNN_based_Early_Cyber_Attack_Detection_for_the_Tennessee_Eastman_Process.txt\n",
      "1709.04005v2.Addressee_and_Response_Selection_in_Multi_Party_Conversations_with_Speaker_Interaction_RNNs.txt\n",
      "1709.04057v2.Parallelizing_Linear_Recurrent_Neural_Nets_Over_Sequence_Length.txt\n",
      "1709.06404v1.Interactive_Music_Generation_with_Positional_Constraints_using_Anticipation_RNNs.txt\n",
      "1709.07626v1.BreathRNNet_Breathing_Based_Authentication_on_Resource_Constrained_IoT_Devices_using_RNNs.txt\n",
      "1709.08907v2.Input_to_Output_Gate_to_Improve_RNN_Language_Models.txt\n",
      "1710.02603v2.Low_Rank_RNN_Adaptation_for_Context_Aware_Language_Modeling.txt\n",
      "1710.03414v1.Network_of_Recurrent_Neural_Networks.txt\n",
      "1710.07706v1.Low_Precision_RNNs_Quantizing_RNNs_Without_Losing_Accuracy.txt\n",
      "1710.10197v1.Advanced_LSTM_A_Study_about_Better_Time_Dependency_Modeling_in_Emotion_Recognition.txt\n",
      "1711.02809v2.A_New_Hybrid_parameter_Recurrent_Neural_Networks_for_Online_Handwritten_Chinese_Character_Recognition.txt\n",
      "1711.05734v2.Chipmunk_A_Systolically_Scalable_0_9_mm_2_3_08_Gop_s_mW_1_2_mW_Accelerator_for_Near_Sensor_Recurrent_Neural_Network_Inference.txt\n",
      "1711.06788v2.MinimalRNN_Toward_More_Interpretable_and_Trainable_Recurrent_Neural_Networks.txt\n",
      "1712.05134v2.Learning_Compact_Recurrent_Neural_Networks_with_Block_Term_Tensor_Decomposition.txt\n",
      "1712.07316v1.A_Flexible_Approach_to_Automated_RNN_Architecture_Generation.txt\n",
      "1801.04340v4.Predicting_Future_Lane_Changes_of_Other_Highway_Vehicles_using_RNN_based_Deep_Models.txt\n",
      "1801.06831v1.Dense_Recurrent_Neural_Networks_for_Scene_Labeling.txt\n",
      "1801.08322v3.Phonocardiographic_Sensing_using_Deep_Learning_for_Abnormal_Heartbeat_Detection.txt\n",
      "1802.10410v2.Tensor_Decomposition_for_Compressing_Recurrent_Neural_Network.txt\n",
      "1803.04687v1.Multimodal_Recurrent_Neural_Networks_with_Information_Transfer_Layers_for_Indoor_Scene_Labeling.txt\n",
      "1803.05383v1.Use_of_recurrent_infomax_to_improve_the_memory_capability_of_input_driven_recurrent_neural_networks.txt\n",
      "1803.11138v1.Colorless_green_recurrent_networks_dream_hierarchically.txt\n",
      "1804.06511v1.Fast_Weight_Long_Short_Term_Memory.txt\n",
      "1805.02983v1.Augmenting_Recurrent_Neural_Networks_with_High_Order_User_Contextual_Preference_for_Session_Based_Recommendation.txt\n",
      "1805.04908v1.On_the_Practical_Computational_Power_of_Finite_Precision_RNNs_for_Language_Recognition.txt\n",
      "1805.07869v1.Learning_Device_Models_with_Recurrent_Neural_Networks.txt\n",
      "1805.12098v1.Context_aware_Cascade_Attention_based_RNN_for_Video_Emotion_Recognition.txt\n",
      "1806.00526v1.Multi_Step_Prediction_of_Dynamic_Systems_with_Recurrent_Neural_Networks.txt\n",
      "1807.01705v1.Transfer_Learning_for_Clinical_Time_Series_Analysis_using_Recurrent_Neural_Networks.txt\n",
      "1808.01591v1.LISA_Explaining_Recurrent_Neural_Network_Judgments_via_Layer_wIse_Semantic_Accumulation_and_Example_to_Pattern_Transformation.txt\n",
      "1808.02608v1.End_to_end_Speech_Recognition_with_Word_based_RNN_Language_Models.txt\n",
      "1808.06170v1.Linked_Recurrent_Neural_Networks.txt\n",
      "1809.00042v1.What_do_RNN_Language_Models_Learn_about_Filler_Gap_Dependencies.txt\n",
      "1809.02836v1.Context_Free_Transductions_with_Neural_Stacks.txt\n",
      "1810.10999v1.Reversible_Recurrent_Neural_Networks.txt\n",
      "1810.12563v1.Shorten_Spatial_spectral_RNN_with_Parallel_GRU_for_Hyperspectral_Image_Classification.txt\n",
      "1811.01866v1.Do_RNNs_learn_human_like_abstract_word_order_preferences.txt\n",
      "1811.04778v1.Scene_Parsing_via_Dense_Recurrent_Neural_Networks_with_Attentional_Selection.txt\n",
      "1811.09961v4.Deep_RNN_Framework_for_Visual_Sequential_Applications.txt\n",
      "1812.07609v2.RNNFast_An_Accelerator_for_Recurrent_Neural_Networks_Using_Domain_Wall_Memory.txt\n",
      "1812.11527v2.Comparison_between_DeepESNs_and_gated_RNNs_on_multivariate_time_series_prediction.txt\n",
      "1901.02358v1.FastGRNN_A_Fast_Accurate_Stable_and_Tiny_Kilobyte_Sized_Gated_Recurrent_Neural_Network.txt\n",
      "1901.04281v1.RNNSecureNet_Recurrent_neural_networks_for_Cyber_security_use_cases.txt\n",
      "1901.05574v1.Visual_Reasoning_of_Feature_Attribution_with_Deep_Recurrent_Neural_Networks.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901.07859v1.How_do_Mixture_Density_RNNs_Predict_the_Future.txt\n",
      "1901.10400v1.Predicting_Individual_Responses_to_Vasoactive_Medications_in_Children_with_Septic_Shock.txt\n",
      "1902.01739v2.An_RNN_based_IMM_Filter_Surrogate.txt\n",
      "1902.02390v2.Investigating_Recurrent_Neural_Network_Memory_Structures_using_Neuro_Evolution.txt\n",
      "1902.02627v2.Fast_Transient_Simulation_of_High_Speed_Channels_Using_Recurrent_Neural_Network.txt\n",
      "1902.03455v1.Contextual_Recurrent_Neural_Networks.txt\n",
      "1902.10297v1.Representing_Formal_Languages_A_Comparison_Between_Finite_Automata_and_Recurrent_Neural_Networks.txt\n",
      "1902.10858v1.Cascaded_Recurrent_Neural_Networks_for_Hyperspectral_Image_Classification.txt\n",
      "1903.01341v1.Using_stigmergy_as_a_computational_memory_in_the_design_of_recurrent_neural_networks.txt\n",
      "1903.05609v2.Realization_theory_of_recurrent_neural_networks_and_rational_systems.txt\n",
      "1903.11703v2.Recurrent_Neural_Networks_For_Accurate_RSSI_Indoor_Localization.txt\n",
      "1904.00291v1.Two_phase_flow_regime_prediction_using_LSTM_based_deep_recurrent_neural_network.txt\n",
      "1904.03302v1.Measuring_scheduling_efficiency_of_RNNs_for_NLP_applications.txt\n",
      "1904.12933v1.Recurrent_Neural_Networks_in_the_Eye_of_Differential_Equations.txt\n",
      "1905.08527v1.CNNs_found_to_jump_around_more_skillfully_than_RNNs_Compositional_generalization_in_seq2seq_convolutional_networks.txt\n",
      "1905.09691v1.Population_based_Global_Optimisation_Methods_for_Learning_Long_term_Dependencies_with_RNNs.txt\n",
      "1905.12340v1.Rethinking_Full_Connectivity_in_Recurrent_Neural_Networks.txt\n",
      "1907.03329v1.Fast_ES_RNN_A_GPU_Implementation_of_the_ES_RNN_Algorithm.txt\n",
      "1907.03907v1.Latent_ODEs_for_Irregularly_Sampled_Time_Series.txt\n",
      "1907.11848v1.Recurrent_Neural_Networks_with_Long_Term_Temporal_Dependencies_in_Machine_Tool_Wear_Diagnosis_and_Prognosis.txt\n",
      "1908.07062v3.Recurrent_Neural_Networks_An_Embedded_Computing_Perspective.txt\n",
      "1908.08976v1.MASR_A_Modular_Accelerator_for_Sparse_RNNs.txt\n",
      "1909.00021v1.A_single_layer_RNN_can_approximate_stacked_and_bidirectional_RNNs_and_topologies_in_between.txt\n",
      "1909.02279v1.Accelerating_Transformer_Decoding_via_a_Hybrid_of_Self_attention_and_Recurrent_Neural_Network.txt\n",
      "1909.03082v1.One_Size_Does_Not_Fit_All_Multi_Scale_Cascaded_RNNs_for_Radar_Classification.txt\n",
      "1909.05414v1.Time_weighted_Attentional_Session_Aware_Recommender_System.txt\n",
      "1910.02558v2.Pushing_the_limits_of_RNN_Compression.txt\n",
      "1911.07806v2.Action_Anticipation_with_RBF_Kernelized_Feature_Mapping_RNN.txt\n",
      "2001.00058v1.Towards_Improving_the_Performance_of_the_RNN_based_Inversion_Model_in_Output_Tracking_Control.txt\n",
      "2002.02805v1.Short_Term_Blood_Glucose_Prediction_based_on_Continuous_Glucose_Monitoring_Data.txt\n",
      "2002.05615v1.Verifiable_RNN_Based_Policies_for_POMDPs_Under_Temporal_Logic_Constraints.txt\n",
      "2002.07422v1.Assessing_the_Memory_Ability_of_Recurrent_Neural_Networks.txt\n",
      "2002.11474v1.RTMobile_Beyond_Real_Time_Mobile_Acceleration_of_RNNs_for_Speech_Recognition.txt\n",
      "2003.03601v1.RNN_based_Online_Learning_An_Efficient_First_Order_Optimization_Algorithm_with_a_Convergence_Guarantee.txt\n",
      "2004.00478v1.Distance_and_Equivalence_between_Finite_State_Machines_and_Recurrent_Neural_Networks_Computational_results.txt\n",
      "2004.05290v1.Convex_Sets_of_Robust_Recurrent_Neural_Networks.txt\n",
      "2004.08013v1.How_recurrent_networks_implement_contextual_processing_in_sentiment_analysis.txt\n",
      "2004.13838v1.How_Chaotic_Are_Recurrent_Neural_Networks.txt\n",
      "2005.04366v1.Compressing_Recurrent_Neural_Networks_Using_Hierarchical_Tucker_Tensor_Decomposition.txt\n",
      "2005.05758v1.CSB_RNN_A_Faster_than_Realtime_RNN_Acceleration_Framework_with_Compressed_Structured_Blocks.txt\n",
      "2005.09471v1.Comparing_Transformers_and_RNNs_on_predicting_human_sentence_processing_data.txt\n"
     ]
    }
   ],
   "source": [
    "for file in text_files:\n",
    "    curr_file = codecs.open(TEXTDIR+file,\"r\",\"utf-8\")\n",
    "    curr_file_text = curr_file.read()\n",
    "    curr_file_text = curr_file_text.lower()\n",
    "    start_of_abstract =curr_file_text.index(\"abstract\")\n",
    "    end_of_abstract = curr_file_text.index(\"introduction\")\n",
    "    abstract = curr_file_text[start_of_abstract+9 : end_of_abstract]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #write abstract file\n",
    "    abstract_file=codecs.open(ABSTRACTDIR+file,\"wb\",\"utf-8\")\n",
    "    abstract_file.write(abstract)\n",
    "    \n",
    "    \n",
    "    #clean references\n",
    "    print(file)\n",
    "    start_of_references= curr_file_text.rindex(\"references\")\n",
    "    curr_file_text = curr_file_text[end_of_abstract:start_of_references]\n",
    "    curr_file_text = re.sub(\"[^a-zA-Z.]\", \" \",curr_file_text)\n",
    "    cleaned_file = codecs.open(CLEANEDDIR+file,\"wb\",\"utf-8\")\n",
    "    cleaned_file.write(curr_file_text)\n",
    "    \n",
    "    \n",
    "    #cloasing files\n",
    "    cleaned_file.close()\n",
    "    abstract_file.close()\n",
    "    curr_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'introduction    creative machine learning is an extremely relevant research area today  generative models form the basis of creative learning  and for this reason  a high level  of sophistication is required from these models  also  identifying features in the  subjective fields of art  literature and music is an arduous task  which is only  made more difficult when more elaborate learning is desired  deep architectures   therefore  present themselves as an ideal framework for generative models  as  they are inherently stochastic and support increasingly complex representations  with each added layer  recurrent neural networks  rnns  have also used with  great success as regards generative models  particularly handwriting generation   where they have been used to achieve the current state of the art results  the  internal feedback or memory state of these neural networks is what makes them  a suitable technique for sequence generation in tasks like polyphonic music composition   there have been many attempts to generate polyphonic music in the past   and a variety of techniques have been applied  some of which will be discussed  here  matic et al      used neural networks and cellular automata to generate          kratarth goel  raunaq vohra and j  k  sahoo    melodies  however  this is dependent on a feature set based on emotions and  further requires specialized knowledge of musical theory  a similar situation is  observed with the work done by maeda and kajihara      who used genetic algorithms for music generation  elman networks with chaotic inspiration were  used by     to compose music  while rnns are an excellent technique to model  sequences  they used chaotic inspiration as an external input instead of real  stochasticity to compose original music  a deep belief network with a sliding  window mechanism to create jazz melodies was proposed by      however  due  to lack of temporal information  there were many instances of repeated notes  and pitches  most recently  boulanger lewandowski et al      used rnn rbms  for polyphonic music generation and obtained promising results  we propose  a generic technique which is a combination of a rnn and a deep belief network for sequence generation  and apply it to automatic music composition  our  technique  the rnn dbn  effectively combines the superior sequence modeling  capabilities of a rnn with the high level data modeling that a dbn enables  to produce rich  complex melodies which do not feature significant repetition   moreover  the composition of these melodies does not require any feature selection from the input data  this model is presesnted as a generic technique  i  e   it does not make any assumptions about the nature of the data  we apply our  technique to a variety of datasets and have achieved excellent results which are  on par with the current state of the art   the rest of this paper is organized as follows  section   discusses various deep  and neural network architectures that serve as the motivation for our technique   described in section    we demonstrate the application of rnn dbns to the task  of polyphonic music generation in section   and present our results  section    discusses possible future work regarding our technique and concludes the paper               preliminaries  restricted boltzmann machines    restricted boltzmann machines  rbms  are energy based models with their  energy function e v  h  defined as   e v  h     b  v   c  h   h  w v           where w represents the weights connecting hidden  h  and visible  v  units  and b  c are the biases of the visible and hidden layers respectively   this translates directly to the following free energy formula   x  x  f  v     b  v    log  ehi  ci  wi v          i    hi    because of the specific structure of rbms  visible and hidden units are conditionally independent given one another  using this property  we can write   y  p hi  v        p h v     i     polyphonic music generation using a rnn dbn    p v h       y    p vj  h                  j    samples can be obtained from a rbm by performing block gibbs sampling   where visible units are sampled simultaneously given fixed values of the hidden  units  similarly  hidden units are sampled simultaneously given the visible unit  values  a single step in the markov chain is thus taken as follows   h n        w   v  n    c   v  n        w h n      b             where   represents the sigmoid function acting on the activations of the   n     th hidden and visible units  several algorithms have been devised for  rbms in order to efficiently sample from p v  h  during the learning process  the  most effective being the well known contrastive divergence  cd   k  algorithm        in the commonly studied case of using binary units  where vj and hi             we obtain  from eqn       a probabilistic version of the activation function   p  hi     v      ci   wi v   p  vj     h      bj   wj  h            the free energy of an rbm with binary units thus further simplifies to   x  log     e ci  wi v           f  v     b  v    i    we obtain the following log likelihood gradients for an rbm with binary  units         log p v    i     ev  p hi  v    vj     vj     wi   v  i    ci     wij   log p v        ev  p hi  v       wi   v  i      ci   log p v    i      ev  p vj  h     vj      bj           where   x         e x     is the element wise logistic sigmoid function          recurrent neural network    recurrent neural networks  rnns  are a particular family of neural networks  where the network contains one or more feedback connections  so that activation  of a cluster of neurons can flow in a loop  this property allows for the network to  effectively model time series data and learn sequences  an interesting property of  rnns is that they can be modeled as feedforward neural networks by unfolding          kratarth goel  raunaq vohra and j  k  sahoo    them over time  rnns can be trained using the backpropogation through time   bptt  technique  if a network training sequence starts at a time instant t   and ends at time t    the total cost function is simply the sum over the standard  error function esse ce at each time step   etotal      xt     t t     esse ce  t            and the gradient descent weight update contributions for each time step are  given by    wij          etotal  t    t    xt   esse ce  t      t t    wij   wij             e    sse ce  now have contributions  the partial derivatives of each component  w  ij  from multiple instances of each weight wij    wv t    h t      w ht    h t    and are  dependent on the inputs and hidden unit activations at previous time instants   the errors now must be back propagated through time as well as through the  network            deep belief network    rbms can be stacked and trained greedily to form deep belief networks  dbns    dbns are graphical models which learn to extract a deep hierarchical representation of the training data      they model the joint distribution between observed  vector x and the   hidden layers hk as follows             p  x  h           h             y    k      k    p  h  h    k             p  h      h               where x   h    p  hk    hk   is a conditional distribution for the visible units  conditioned on the hidden units of the rbm at level k  and p  h      h    is the  visible hidden joint distribution in the top level rbm   the principle of greedy layer wise unsupervised training can be applied to  dbns with rbms as the building blocks for each layer      we begin by training  the first layer as an rbm that models the raw input x   h    as its visible  layer  using that first layer  we obtain a representation of the input that will  be used as data for the second layer  two common solutions exist here  and  the representation can be chosen as the mean activations p h        h      or  samples of p h     h       then we train the second layer as an rbm  taking the  transformed data  samples or mean activations  as training examples  for the  visible layer of that rbm   in the same vein  we can continue adding as many  hidden layers as required  while each time propagating upward either samples  or mean values      polyphonic music generation using a rnn dbn                recurrent temporal restricted boltzmann machine    the recurrent temporal restricted boltzmann machine  rtrbm      is a sequence of conditional rbms  one at each time instant  whose parameters  btv   bth    w t   are time dependent and depend on the sequence history at time t  denoted  by a t     v        u          t   where u t  is the mean field value of h t   as seen  in      the rtrbm is formally defined by its joint probability distribution   p  v  t    h t        t  y    p  v  t    h t   a t               t      where p  v  t    h t   a t    is the joint probability of the tth rbm whose parameters are defined below  from eqn       and eqn        while all the parameters  of the rbms may usually depend on the previous time instants  we will consider  the case where only the biases depend on u t        t     bh   bh   wuh u t                t     b t   v   bv   wuv u                 which gives the rtrbm six parameters  w  bv   bh   wuv   wuh   u    the more  general scenario is derived in similar fashion  while the hidden units h t  are binary during inference and sample generation  it is the mean field value u t  that  is transmitted to its successors  eqn         this important distinction makes  exact inference of the u t  easy and improves the efficiency of training       t     u t      wvh v  t    bh       wvh v  t    wuh u t      bh              observe that eqn       is exactly the defining equation of a rnn  defined  in section    with hidden units u t            rnn dbn    the rtrbm can be thought of as a sequence of conditional rbms whose parameters are the output of a deterministic rnn      with the constraint that  the hidden units must describe the conditional distributions and convey temporal information for sequence generation  the use of a single rbm layer greatly  constricts the expressive power of the model as a whole  this constraint can be  lifted by combining a full rnn having distinct hidden units u t  with a rtrbm  graphical model  replacing the rbm structure with the much more powerful  model of a dbn  we call this model the rnn dbn   in general  the parameters of the rnn dbn are made to depend only on  u t    given by eqn       and eqn       along with    t     bh    bh    wuh  u t               for the second hidden layer in an rnn dbn with   hidden layers  the joint  probability distribution of the rnn dbn is also given by eqn        but with          kratarth goel  raunaq vohra and j  k  sahoo    u t  defined arbitrarily  as given by eqn        for simplicity  we consider the   t    t    t   rnn dbn parameters to be  wvh t    bv   bh    bh    for a   hidden layer rnndbn  shown in fig      i e  only the biases are variable  and a single layer rnn   whose hidden units u t  are only connected to their direct predecessor u t    and  to v  t  by the relation   u t      wvu v  t    wuu h t      bu               fig     a rnn dbn with   hidden layers   the dbn portion of the rnn dbn is otherwise exactly the same as any  general dbn  this gives the   hidden layer rnn dbn twelve parameters     wvh   wh  h    bv   bh    bh    wuv   wuh    wuh    u      wvu   wuu   bu     the training algorithm is based on the following general scheme      propagate the current values of the hidden units u t  in the rnn portion of  the graph using eqn            calculate the dbn parameters that depend on the u t   eqn             and        by greedily training layer by layer of the dbn  each layer as an rbm   train the first layer as an rbm that models the raw input as its visible  layer and use that first layer to obtain a representation of the input that will  be used as data for the second layer and so on       use cd k to estimate the log likelihood gradient  eq       with respect to  w   bv and bh for each rbm composing the dbn      repeat steps   and   for each layer of the dbn    t    t    t      propagate the estimated gradient with respect to bv   bh and bh  backward  through time  bptt       to obtain the estimated gradient with respect to  the rnn  for the rnn dbn with   hidden layers      polyphonic music generation using a rnn dbn              implementation and results    table    log likelihood  ll  for various musical models in the polyphonic music  generation task   model    jsb chorales musedata   ll    ll   random                  rbm                nade                 note n gram                 rnn rbm                rnn   hf                 rtrbm                 rnn rbm                 rnn nade                 rnn nade   hf                rnn dbn                  nottingham   ll                                                                                   pianomidi de  ll                                                                                     we demonstrate our technique by applying it to the task of polyphonic music  generation  we used a rnn dbn with   hidden dbn layers   each having      binary units   and     binary units in the rnn layer  the visible layer has     binary units  corresponding to the full range of the piano from a  to c   we  implemented our technique on four datasets   jsb chorales   musedata     nottingham   and piano midi de  none of the preprocessing techniques mentioned  in     have been applied to the data  and only raw data has been given as input  to the rnn dbn  we evaluate our models qualitatively by generating sample  sequences and quantitatively by using the log likelihood  ll  as a performance  measure  results are presented in table    a more comprehensive list can be  found in        the results indicate that our technique is on par with the current state of theart  we believe that the difference in performance between our technique and the  current best can be attributed to lack of preprocessing  for instance  transposing  the sequences in a common tonality  e g  c major minor  and normalizing the  tempo in beats  quarternotes  per minute as preprocessing can have the most  effect on the generative quality of the model  it also helps to have as pretraining  the initialization the wvh    wh  h    bv   bh    bh  parameters with independent  rbms with fully shuffled frames  i e  wuh    wuh    wuv   wuu   wvu        initializing the wuv   wuu   wvu   bu parameters of the rnn with the auxiliary  cross entropy objective via either stochastic gradient descent  sgd  or  preferably  hessian free  hf  optimization and subsequently finetuning significantly               these marked results are obtained after various preprocessing  pretraining methods  and optimization techniques described in the last paragraph of this section   http   www musedata org  ifdo ca  seymour nottingham nottingham html          kratarth goel  raunaq vohra and j  k  sahoo    helps the density estimation and prediction performance of rnns which would  otherwise perform worse than simpler multilayer perceptrons      optimization  techniques like gradient clipping  nesterov momentum and the use of nade for  conditional density estimation also improve results          conclusions and future work    we have proposed a generic technique called recurrent neural network deep  belief network  rnn dbn  for modeling sequences with generative models and  have demonstrated its successful application to polyphonic music generation  we  used four datasets for evalutaing our technique and have obtained results on par  with the current state of the art  we are currently working on improving the  results this paper  by exploring various pretraining and optimization techniques   we are also looking at showcasing the versatility of our technique by applying  it to different problem statements     '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
