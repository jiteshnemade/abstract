introduction  human action recognition     has become an active area  in computer vision and there are many important research  problems  such as event recognition       group based activities recognition       human object interactions      and  activities in egocentric videos         . most approaches  have been proposed to recognize actions in rgb videos    joints    recently  skeleton based action recognition gains more  popularity due to cost effective depth sensors coupled with  real time skeleton estimation algorithms. traditional approaches based on handcrafted features are limited to represent the complexity of motion patterns. recent methods  that use recurrent neural networks  rnn  to handle raw  skeletons only focus on the contextual dependency in the  temporal domain and neglect the spatial configurations of  articulated skeletons. in this paper  we propose a novel  two stream rnn architecture to model both temporal dynamics and spatial configurations for skeleton based action  recognition. we explore two different structures for the temporal stream  stacked rnn and hierarchical rnn. hierarchical rnn is designed according to human body kinematics. we also propose two effective methods to model the  spatial structure by converting the spatial graph into a sequence of joints. to improve generalization of our model   we further exploit  d transformation based data augmentation techniques including rotation and scaling transformation to transform the  d coordinates of skeletons during  training. experiments on  d action recognition benchmark  datasets show that our method brings a considerable improvement for a variety of actions  i.e.  generic actions  interaction activities and gestures.    joints  time    arxiv     .     v   cs.cv     apr              temporal rnn    rnn    time    rnn    softmax  score    spatial rnn    rnn    rnn    softmax    figure  . a two stream rnn architecture for skeleton based action  recognition. here softmax denotes a fully connected layer with a  softmax activation function.    recorded by  d cameras. however  it still remains a challenging problem for three reasons. first  it is hard to well  extract useful information from the high dimensional and  low quality input data. second  the rgb video is highly  sensitive to some factors like illumination changes  occlusion and background clutter. third  the identification of  actions is related to high level visual clues such as human  poses and objects  which are very difficult to obtain from  rgb videos directly.  humans can recognize actions with a few spots describing motions of the main joints of skeletons       and experiments show that a large set of actions can be recognized  solely from skeletons     . in contrast to rgb based action  recognition  skeleton based action recognition can avoid the  awful task of feature extraction from videos and explicitly  model the dynamics of actions. there are three ways to obtain skeletons  motion capture systems  rgb images and  depth maps. sophisticated motion capture systems are very  expensive and require the user to wear a motion capture suit  with markers. extracting reliable skeletons from monocular rgb images or videos  i.e.  pose estimation  is still an  unsolved problem. fortunately  with the recent advent of  affordable depth sensors  it is much easier and cheaper to  obtain  d skeletons from depth maps. for example  shot      ton et al.      propose a method to quickly and accurately  predict  d positions of body joints from a single depth image. these advances excite considerable interest for skeleton based action recognition and various algorithms have  been proposed recently.  traditional skeleton based action recognition approaches  are mainly divided into two categories  joint based approaches and body part based approaches. joint based approaches consider the human skeleton as a set of points and  use various positions based features such as joint positions           and pairwise relative joint positions          to  characterize actions. while body part based approaches regard the human skeleton as a connected set of segments  and  then focus on individual or connected pairs of body parts       and joint angles     . based on handcrafted low level  features  both approaches employ relatively simple time series models  e.g.  hidden markov model           to recognize actions. however  human engineered features are  limited to represent the complexity of the intrinsic characteristics of actions and the subsequent time series models do  not unleash the full potential of the sequential data.  inspired by the great success of deep learning for rgb  based action recognition               there is a growing  trend of using deep neural networks for skeleton based action recognition. different structures of recurrent neural  networks  rnn   e.g.  hierarchical rnn      rnn with  regularizations       differential rnn      and part aware  long short term memory  lstm        have been used to  learn motion representations from raw skeletons. however   considering an action is a continuous evolution of articulated rigid segments connected by joints       these rnnbased methods only model the contextual information in  the temporal domain by concatenating skeletons for each  frame. in fact  different actions are performed with different spatial configurations of joints of skeletons. the dependency in the spatial domain also reflects the characteristics  of actions and should not be neglected for skeleton based  action recognition.  to this end  we introduce a novel two stream rnn architecture which incorporates both spatial and temporal networks for skeleton based action recognition. figure   shows  the pipeline of our method. the temporal stream uses a  rnn based model to learn the temporal dynamics from the  coordinates of joints at different time steps. we employ two  different rnn models  stacked rnn and hierarchical rnn.  compared with stacked rnn  hierarchical rnn is designed  according to human body kinematics and has fewer parameters. at the same time  the spatial stream learns the spatial  dependency of joints. we propose a simple and effective  method to model the spatial structure that first casts the spatial graph of articulated skeletons into a sequence of joints   then feeds this resulting sequence into a rnn structure.  different methods are explored to turn the graph structure    into a sequence for the purpose of better maintaining the  spatial relationships. the two channels are then combined  by late fusion and the whole network is end to end trainable. finally  to avoid overfitting and improve generalization  we exploit data augmentation techniques by using  d  transformation  i.e.  rotation transformation  scaling transformation and shear transformation to transform the  d coordinates of skeletons during training.  in summary  the main contributions of this paper are  listed as follows. first  we propose a two stream rnn architecture to utilize both spatial and temporal relations of  joints of skeletons. second  we exploit and compare different architectures of both streams. third  we propose  data augmentation techniques based on  d transformation  and demonstrate the effectiveness for skeleton based action  recognition. finally  our method obtains the state of theart results on three important benchmarks for a variety of  actions  i.e.  generic actions  ntu rgb d   interaction activities  sbu interaction  and gestures  chalearn .     . related work  in this section  we briefly review action recognition approaches related to ours. the two aspects are as follows.     . . action recognition with deep networks  deep neural networks have made great progress in the  area of action recognition.  d convolutional neural networks  cnn  is proposed and different architectures are  studied to take advantage of local spatio temporal information         . to capture complementary information between appearance and motion  a two stream cnn architecture is developed for rgb based action recognition     .  recently  recurrent neural networks  rnn  have been  widely used for action recognition. srivastava et al.      use  multilayer long short term memory  lstm  networks to  learn representations of video sequences. donahue et al.      develop an end to end trainable long term recurrent convolutional networks  lrcn  architecture which can simultaneously learn temporal dynamics and convolutional perceptual representations from rgb videos. deep convolutional and recurrent neural networks has also been proposed and applied for activity recognition         .  prior to our work  several models have been proposed  based on rnn for skeleton based action recognition. du et  al.        first design an end to end hierarchical rnn architecture for skeleton based action recognition. zhu et al.       propose a fully connected deep lstm network with regularization terms to learn co occurrence features of joints.  veeriah et al.      present differential rnn that extends  lstm structure by modeling the dynamics of states evolving over time. shahroudy et al.      propose a part aware  extension of lstm to utilize the physical structure of the     human body. these methods only model the motion dynamics in the temporal doamin and neglect the spatial configurations of articulated skeletons. recently  liu et al.       extend lstm to spatial temporal domain for the purpose of  modeling the dependencies between joints. as temporal dynamics and spatial configurations are separate visual pathways       we employ a two stream architecture to model  them accordingly.     . . features based on skeletons  previous skeleton based action recognition methods  mainly focus on handcrafted features    . to get representations of postures  one straightforward feature is the pairwise  joint location difference  which can be simply concatenated        or casted into  d cone bins to build a histogram of  d  joints locations      for action recognition.  joint orientation is another good feature as it is invariant to the human body size. for example  sempena et al.       apply dynamic time warping based on the feature vector built from joint orientation along time series. bloom  et al.     use adaboost to combine five types of features   i.e.  pairwise joint position difference  joint velocity  velocity magnitude  joint angle velocity and  d joint angle to  recognize gaming actions  for real time action recognition.  there are some work that groups the joints of skeletons to construct planes from joints and then measures the  joint to plane distance and motion. yun et al.      capture  the geometric relationship between the joint and the plane  spanned by three joints. sung et al.      compute the joint s  rotation matrix w.r.t. the person s torso  hand position w.r.t.  the torso and joint rotation motion as features.     . overview of rnn  different from feedforward neural networks that map  from one input vector matrix to one output vector matrix   recurrent neural networks  rnn  map an input sequence x  to another output sequence y .  rnn architectures are naturally suitable for the sequence  classification  where each input sequence is assigned with a  single class. layers of rnn can be stacked to build a deep  rnn by considering the output sequence of the previous  layer as the input sequence of the current layer. a typical  structure of rnn for sequence classification is shown in  figure   a   which contains a stack of rnn layers with a  softmax classification layer on top of the last hidden layer.  due to the vanishing gradient and error blowing up problems       the standard rnn cannot store information for  long periods of time or access the long range of context.  long short term memory  lstm       addresses this problem by using additional gates to determine when the input  is significant enough to remember  when it should continue  to remember or forget the value  and when it should output  the value. the lstm unit has been shown to be capable of    input gate    rnn  rnn    xt    xt    sequence    it    output gate    ot    cell    xt    softmax   a  rnn for sequence  classification.    ht    ct  feedb ack    ft    forget gate    xt   b  lstm neuron.    figure  .  a  a two layer stacked rnn for sequence classification.   b  a lstm block with input  output  and forget gates     .    storing and accessing information over very long timespans      . figure   b  depicts a lstm unit   it     wxi xt   whi ht     wci ct     bi    ft     wxf xt   whf ht     wcf ct     bf    ct   ft ct     it tanh wxc xt   whc ht     bc    ot     wxo xt   who ht     wco ct   bo    ht   ot tanh ct             where i  f  o correspond to the input gate  forget gate and  output gate  respectively. all the matrices w are the connection weights and all the variables b are biases.     . two stream rnn  the sequence of skeletons determines the evolution of  actions  which has both spatial and temporal structures. the  spatial structure displays a spot of the pictorial form of  joints while the temporal structure tracks and represents the  movement of joints. accordingly  we devise an end to end  two stream architecture based on rnn  which is shown in  figure  . here the fusion is performed by combining the  softmax class posteriors from the two nets.     . . temporal rnn  we begin with the description of the temporal channel  of rnn  which models the temporal dynamics of skeletons.  similar to the previous work                  it concatenates  the  d coordinates of different joints at each time step and  handles the generated sequence with a rnn architecture.  we focus on the following two model structures.  stacked rnn. this structure feeds the rnn network with  the concatenated coordinates of all joints at each time step.  here we stack two layers of rnn and find that adding more  layers would not considerably improve the performance.  as the length of skeleton sequences is relatively long  e.g.            we adopt lstm neurons for all layers. although  simple  stacked rnn has been widely used to process and  recognize sequences of variable lengths.  hierarchical rnn. the human skeleton can be divided  into five parts  i.e.  two arms  two legs and one trunk. we                     rnn. the central problem is how to convert a graph into a  sequence. we provide two alternative methods below.    rnn                                                                                               rnn    rnn                                   concatenation                           rnn    softmax    rnn                       rnn    figure  . hierarchical rnn for skeleton based action recognition.    observe that an action is performed by either an independent  part or a combination of several parts. for example  kicking  depends on legs and running involves both legs and arms.  thus  a hierarchical structure of rnn is used to model the  motions of different parts as well as the whole body. figure    shows the proposed structure. to be consistent with the  stacked rnn structure  our hierarchical rnn also has two  layers vertically.  in the first layer  we use a corresponding rnn to model  the temporal movement of each body part based on its concatenated coordinates of joints at each time step. in the second layer  we concatenate the outputs of the rnn of different parts and adopt another rnn to model the movement of  the whole body. compared with the pioneered hierarchical  structure in      our structure is more succinct and straightforward  and does not use additional fully connected layers  before the logistic regression classifier with softmax activation. compared with the stacked structure  the hierarchical  structure has relatively fewer parameters and is less likely  to overfit.     . . spatial rnn  human body can be considered as an articulated system  of rigid segments connected by joints. take the msr action d dataset      as an example  the physical structure of  the    joints is represented by an undirected graph in figure    a . nodes denote the joints and edges denote the physical  connections. when an action takes place  this undirected  graph displays some varied patterns of spatial structures.  for example  clapping is performed with the joints of the  two palms striking together  and bending is acted when the  joints of the trunk shape into a curve.  to model the spatial dependency of joints  we cast the  graph structure into a sequence of joints and exactly develop  a relevant rnn architecture. the input of the rnn architecture at each step corresponds to the vector of coordinates  of a certain joint. as a joint has only three coordinates   we select a temporal window centered at the time step and  concatenate the coordinates inside this window to represent  this joint. this rnn architecture models the spatial relationships of joints in a graph structure and is called spatial    chain sequence. we assume the joints are arranged in a  chain like sequence with the order of arms  trunk and legs.  the trunk is placed in the middle as it connects both arms  and legs. for example  the    joints graph of the msr action d dataset is arranged in a chain sequence in figure    b . the chain sequence maintains the physical connections of joints of each body part  arms  trunk and legs   and  the joints are placed in a sequence without duplication. one  of the drawbacks is that there is no physical connections at  the boundary of joints between hands  trunk and legs. for  instance  the joint whose index is    is not connected with  the joint whose index is   . but the two joints are adjacent  in the generated chain like sequence.  traversal sequence. to address the limitation of the chain  sequence  we propose a graph traversal method to visit the  joints in a sequence in the light of the adjacency relations   partly inspired by the tree structure based traversal method      .as illustrated in figure   c   we first select the central  spine joint as the starting point  and visit the joints of the  left arm. while reaching an end point  it goes back. then  we visit the right arm  the upper trunk  etc. after visiting  all joints  it finally returns to the starting point. we arrange  the graph into a sequence of joints according to the visiting  order. the traversal sequence guarantees the spatial relationships in a graph by accessing most joints twice in both  forward and reverse directions.  different from the temporal rnn  spatial rnn could  recognize actions by a glimpse of one frame  when the size  of temporal window equals   . here  we do not use a hierarchical structure based on body parts  as the number of  joints is limited  e.g.     for the ntu rgb d dataset .     . .  d transformation of skeletons  for skeleton based action recognition  the input data is a  sequence  d coordinates of joints. as neural networks often require a lot of data to improve generalization and prevent overfitting  we exploit several data augmentation techniques based on  d transformation to make the best use of  limited supply of training data. note that the  d transformation techniques are only used during training.  rotation. based on euler s rotation theorem  any  d rotation can be given as a composition of rotations about three  axes. the three basic rotation matrices in terms of rotate  angles         about the x  y  z axis in a counterclockwise  direction are represented as below           rx                    cos    sin              sin      cos                        sin              cos      cos       ry            sin                                      cos    rz         sin           sin    cos                                  where r is the general rotation matrix in the  d coordinate  system.  for the  d coordinates of joints  we randomly rotate the  input sequence of skeletons within a certain range for the  x  y axis  as the rotation plane of the camera is perpendicular to the z axis. the rotation transformation simulates the  viewpoint changes of the camera and improves the robustness of our model for cross view experimental settings. we  find the recent work     also uses the rotation transformation for cross view recognition of actions.  scaling. scaling transformation is used to change the size  of skeletons. the transformation matrix can be formulated  as         sx           s       sy          sz  where sx   sy   sz are scaling factors along with the three  axes  respectively.  the scaling transformation can either expand or compress the dimensions of skeletons by using random scaling  factors. as different action performers have varied heights  and body sizes  the dimensions of their skeletons may be  different. thus the scaling transformation is beneficial for  cross subject experimental settings.  shear. shear transformation is a linear map that displaces  each point in a fixed direction. it slants the shape of the  coordinates of joints and changes the angles between them.  the transformation matrix can be represented as below           sh     shxy  shxz    shyx     shyz       shzx  shzy                                        where shyx   shzx   shxy   shzy   shxz   shyz are shear factors.               a  undirected  graph of joints.                                                                      general rotations can be obtained from these three basic  rotation matrices using matrix multiplication   r   rz    ry    rx                                                                                                                    b  chain sequence  of joints.                                                                                   c  traversal  sequence of joints.    figure  .  a  the physical structure of    joints.  b  convert the  joints graph into a sequence. the joints of arms come first  then  that of body  finally is that of legs.  c  use a traversal method  to transform the joints graph into a sequence. the order of the  sequence is the same as the visiting order of the arrow.     . . datasets  ntu rgb d dataset. currently  this is the largest depthbased action recognition dataset  providing  d coordinates  of    joints collected by kincet v . it contains more than     thousand sequences and   million frames  captured in various background conditions. the dataset has    different  action classes including daily  mutual  and health related  actions. the actions are performed by    different human  subjects  whose age range is from    to   . numerous variations in subjects and views  and large amount of samples  make it highly suitable for deep learning methods. we follow the cross subject and cross view evaluations      and  report the classification accuracy in percentage.  sbu interaction dataset. this is a complex human activity dataset depicting two person interactions captured with  kinect. each skeleton has    joints. it includes     skeleton sequences in      frames. all videos are recorded in the  same laboratory environment with   activities performed by    participants. the dataset is very challenging because the  interactions are non periodic  and have very similar body  movements. following the   fold cross validation       we  split the    sets of this dataset into   folds and give the average recognition accuracy.  chalearn gesture recognition dataset. this dataset  contains    italian gestures performed by    different persons. there are    hours of kinect data  consisting of rgb   depth  foreground segmentation and skeletons. the dataset  has     videos in total. each video lasts   to   minutes and  contains   to    noncontinuous gestures. here  we only use  skeletons for gesture recognition. as done in the literature           we report the precision  recall and f  score measures on the validation set.     . . implementation details     . experiments  the proposed model is evaluated on three datasets  ntu  rgb d dataset       sbu interaction dataset       and  chalearn gesture recognition dataset       .    we normalize skeletons by subtracting the central joint   which is the average of  d coordinates of the hip center  hip  left and hip right. the sequences are converted to a fixed  length t by sampling and zero padding to allow for batch     learning. t should be larger than the length of most sequences to reduce loss of information caused by sampling.  the ntu rgb d dataset has a variable  one or two   number of persons performing actions. for samples with  two persons  we only process one sequence each time  and  average the predicted scores of the two. we set t       for  this dataset  as most sequences are less than     in length.  for the sbu interaction dataset with a pair of skeletons representing interactions of two persons  we concatenate the  two  d coordinates for each joint at each time step and regard it as one sequence of  d coordinates. we set the normalized sequence length t      for this dataset. for the  chalearn gesture recognition dataset  we set t     .  for the ntu rgb d dataset  the number of neurons of  each layer of stacked rnn is    . for hierarchical rnn   the number of neurons of the body part and the whole body  are     and      respectively. for the chalearn gesture  recognition dataset  the networks structures are the same  as those of the ntu rgb d dataset. compared with  the above two datasets  the sbu interaction dataset has  less number of training samples and the sequence length  is shorter. so we reduce the number of neurons of stacked  rnn of the temporal rnn to      and set the number of  neurons of the body part and the whole body to    and       respectively. for all the datasets  the structure of the spatial  rnn is the same as that of stacked rnn of the temporal  rnn. we adopt lstm neurons for all layers due to its excellent performance for sequence recognition.  to demonstrate the effectiveness of the two stream  rnn  we simply adopt stacked rnn for the temporal channel and chain sequence for the spatial channel. the weight  of predicted scores of the temporal rnn is  .   and the  temporal window size of the spatial rnn is one fourth of  the fixed length t   both are determined by cross validation.  the networks are trained using stochastic gradient descent.  the learning rate  initiated with  .    is reduced by multiplying it by  .  every    epochs during training. the implementation is based on theano      and lasagne   . one  nvidia titan x gpu is used to run all experiments.     . . experimental results  comparison between models. the comprehensive results  of our two stream rnn on three datasets are shown in  table  . we can see that the two stream rnn consistently outperforms the individual temporal rnn and spatial  rnn  which confirms that the spatial and temporal channels are both effective and complementary. in addition   for two activity recognition datasets  the  d transformation  techniques bring significant performance improvement for  skeleton based recognition  especially for cross view evaluation. for example  on the ntu rgb d dataset  the twostream rnn with  d transformation outperforms that with  https   github.com lasagne lasagne    out  d transformation by  .   for cross view evaluation   much higher than the outperformed value of  .   for cross  subject evaluation. the explanation is straightforward that  rotation transformation randomly generates new skeletons  from different views  thus making our two stream rnn robust to the viewpoint changes.  generally  the results of the temporal rnn are much better than those of the spatial rnn. this observation is consistent with the fact that most previous rnn based methods adopt the temporal rnn to recognize actions. for  the temporal rnn  the hierarchical structure generally performs better than the stacked structure. for example  on  the ntu rgb d dataset  hierarchical rnn outperforms  stacked rnn by an average of  .  . for the spatial rnn   the results of the traversal sequence are better than those of  the chain sequence as the traversal method maintains better  spatial relationships of the graph structure by visiting most  joints twice in both forward and reverse directions.  comparison between structures. in section  .  we manually define the structures of both stacked rnn and hierarchical rnn. here we empirically study the effects of the  number of stacked layers and the number of neurons for  each layer on the performance. due to the limited space   we only give results on the ntu rgb d dataset by cross  view protocol in table  .  for stacked rnn  we observe that two stacked layers   r         performs better than one layer  r      and three  stacked layers  r             performs even better than  two stacked layers. for the number of neurons of rnn layers  decreasing it to      r         reduces the accuracy  and increasing it to       r           does not necessarily improve the result. as adding more layers and increasing hidden neurons result more parameters and increase the  computational complexity of our model  we adopt r       as the default structure for stacked rnn.  for hierarchical rnn  using two stacked rnn layers for  the part  p         b     and increasing the number of  neurons of the part from     to      p     b     improve  the performances. the accuracy can be further improved  by increasing the number of neurons of both the part and  the whole body  p     b     . to make a fair comparison  with the stacked structure  r         and reduce the computational cost  we keep the structure with two layers and  choose     as the number of neurons for the part  which is  one fourth of the number of neurons for the whole body.     . . two stream rnn versus temporal rnn  as previous rnn based methods merely use the temporal rnn  here we aim to show the superiority of our twostream rnn over the temporal rnn.  we plot and compare the confusion matrices of our twostream rnn and the temporal rnn on the sbu interaction  dataset in figure  . we can observe that there are three pairs     table  . comprehensive evaluation results of two stream rnn on three datasets.  channel           temporal rnn  spatial rnn  two stream rnn    stacked  hierarchical  chain  traversal  no transform   d transform    ntu rgb d  cross subject cross view    .     .     .     .     .     .     .     .     .     .     .     .     sbu interaction    .     .     .     .     .     .     chalearn gesture  precision recall f  score    .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .        temporal rnn    two stream rnn     .      .      .      .      .      .      .     touch his pocket  handshaking  walking towards  walking apart    wipe face  salute  put palms together  cross hands  sneeze  staggering  falling  touch head  touch chest  touch back  touch neck  nausea  use a fan  punching  kicking person  pushing person  pat on person  point finger  hugging  giving something    take selfie  check time  rub hands  nod head  shake head    jump up  answer phone  playing with phone  type keyboard  point with finger    cheer up  hand waving  kicking something  put inside pocket  hopping    pickup  throw  sitting down  standing up  clapping  reading  writing  tear up paper  wear jacket  take off jacket  wear a shoe  take off a shoe  wear on glasses  take off glasses  put on a hat  take off hat    drink water  eat meal  brushing teeth  brushing hair  drop     .     figure  . accuracy for each action on the ntu rgb d dataset.  table  . empirical study of networks structures. for stacked rnn   r        denotes two stacked layers of rnn with     hidden  neurons. similarly  r     denotes one rnn layer with      hidden neurons. for hierarchical rnn  p         b    denotes two  stacked rnn layers with     hidden neurons for the body part and  one rnn layer with     hidden neurons for the whole body. and  so on for the other symbols. the default structures of stacked rnn  and hierarchical rnn are r        and p     b     respectively.  stacked rnn  r           .   r              .   r       .   r             .   r           .     hierarchical rnn  p     b       .   p         b      .   p     b       .   p     b        .   p     b        .     of misclassified actions for the temporal rnn  but only one  pair for our two stream rnn. moreover  for pushing  the  samples are     misclassified as punching by the temporal  rnn  while our two stream rnn can correctly recognize  all the samples.  we also depict the accuracy of each action. figure    shows the results of cross subject evaluation on the ntu  rgb d dataset. for most actions  the accuracy of our twostream rnn is higher than that of the temporal rnn. for  example  for brushing teeth  shaking head  and walking towards  the accuracy of the two stream rnn is more than     a  temporal rnn     a  two stream rnn    figure  . comparison of confusion matrices on the sbu interaction dataset.       higher than that of the temporal rnn.     . . parameter sensitivity  in this section  we evaluate the impact of parameters on  the performance. our two stream rnn has two parameters   i.e.  the size of temporal window of the spatial channel  and  the weight of the temporal channel  denoted by   and      respectively. figure   shows the evaluation results on the  sbu interaction dataset. it should be noted that similar results are observed for other datasets.  figure   a  shows the accuracy of the two stream rnn  w.r.t. the parameter             .            .     . we can  see the best performance is reached when    .  or    . .         accuracy        accuracy                                  .      .           .      .      a  weight of temporal rnn                                                                                 b  temporal window size    figure  . parameter sensitivity analysis on the sbu interaction  dataset. here           and         t   where t      is the  sequence length after preprocessing.    when      .   the accuracy decreases with a smaller value  of  . the best result is much higher than the two extreme  points where             which correspond to the spatial  and temporal rnn  respectively.  we choose                       t   and plot the accuracy  of the spatial rnn in figure   b . we find that when              i.e.  t          t     the temporal rnn obtains  the best result. the performance drops when   is not in this  range. we conclude that our result is not sensitive to   for a  wide range.     . . comparison with the state of the art  we compare our two stream rnn method with the recent methods in the literature. table   shows the results  on the ntu rgb d dataset. we first compare our method  with three traditional methods  i.e.   d skeletons representation in a lie group       fisher vector encoding of skeletal quads      and ftp dynamic     . we observe that our  performances are significantly higher  which shows the superiority of deep learning methods over the methods based  on handcrafted features. then our method is compared with  other deep learning methods based on rnn. our results are  much better than the reported results of hbrnn     and  part aware lstm       both of which only model temporal  dynamics of actions. moreover  our method outperforms  the newest spatio temporal lstm with trust gates      by   .   and  .   for both cross subject evaluation and cross  view evaluation  respectively.  the results on the sbu interaction dataset are shown in  table  . our result is  .   higher than the best result based  on handcrafted features  joint feature      . in addition   our approach is superior than recent rnn based approaches  by outperforming the existing best result by  .  . this experiment demonstrates our two stream rnn model can recognize interactions performed by two persons very well.  the results on the chalearn gesture recognition dataset  are summarized in table  . here our two stream rnn is  only compared with the methods solely based on skeletons. for precision  recall and f  score  our approach  yields state of the art performance  outperforming the recently proposed videodarwin      by more than    .    table  . comparison of the proposed approach with the state ofthe art methods on the ntu rgb d dataset.  method  cross subject cross view  lie group         .     .   skeletal quads         .     .   ftp dynamic         .     .   hbrnn        .     .     .     .   part aware lstm       trust gate st lstm         .     .   two stream rnn    .     .   table  . comparison of the proposed approach with the state ofthe art methods on the sbu interaction dataset.  method  accuracy  joint feature         .     .   joint feature       hbrnn        .     .   deep lstm       co occurrence lstm         .   trust gate st lstm         .   two stream rnn    .   table  . comparison of the proposed approach with the state ofthe art methods on the chalearn gesture recognition dataset.  method  skeleton feature       portfolios       gesture spotting       hivideodarwin       cnn for skeleton      videodarwin       two stream rnn    precision    .        .     .     .     .     .     recall    .        .     .     .     .     .     f  score    .     .     .     .     .     .     .      . conclusion  in this paper  we have proposed an end to end twostream rnn architecture for skeleton based action recognition  with the temporal stream modeling temporal dynamics and the spatial stream processing spatial configurations.  we explore two structures to model the sequence of joints of  skeletons for the temporal stream. for the spatial stream  we  also devise two methods to convert the structure of skeleton into a sequence before using a rnn to handle the spatial dependency. moreover  to improve generalization and  prevent overfitting for deep learning based methods  we  employ rotation transformation  scaling transformation and  shear transformation as data augmentation techniques based  on  d transformation of skeletons. our experiments have  shown that two stream rnn outperforms existing state ofthe art skeleton based approaches on datasets for generic  actions  ntu rgb d   interaction activities  sbu interaction  and gestures  chalearn . in the future  we will consider to learn the structure patterns for the spatial channel  and further improve the results.     acknowledgement  this work is jointly supported by national key research  and development program of china      yfb           national natural science foundation of china                                    and beijing natural science  foundation          . this work is also supported by  grants from nvidia and the nvidia dgx   ai supercomputer.    