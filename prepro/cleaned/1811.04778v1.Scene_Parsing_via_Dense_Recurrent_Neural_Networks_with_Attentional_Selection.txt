introduction  scene parsing or scene labeling  aiming to assign one  of predefined labels to each pixel in an image  is usually  formulated as a pixel level classification problem. inspired  by the success of convolutional neural networks  cnns  in  image classification               cnns have drawn increasing interests in scene labeling and demonstrated promising  performance                    . a potential issue  however   for cnn based methods is that only limited contextual cues  from a local region  i.e.  receptive field  in cnns are explored for classification  which is prone to cause ambiguities for visually similar pixels of different categories. for  example  the  sand  pixels can be visually indistinguishable  from  road  pixels even for human with limited context. to  alleviate this issue  a natural solution is to use rich context  to discriminate locally ambiguous pixels                . in  these methods  nevertheless  the long range contextual de      a  undirected cyclic graph     b  directed acyclic graph     c  dense undirected cyclic graph     d  dense directed acyclic graph    figure  . image  a  shows the image of ucg structure as in        and  b  demonstrates one of four dag decompositions. unlike       we represent an image with dense ucg  d ucg  as  shown in  c   and  d  displays one of four dense dags  d dags .  compared to plain ucg and dag  our d ucg and d dag capture richer dependencies in an image. best viewed in color.    pendencies among different image regions are still not effectively explored  which are crucial in scene parsing.  motivated by the ability of capturing long range dependency among sequential data  recurrent neural networks   rnns       have recently been employed to model semantic dependencies in images for scene labeling                               allowing us to perform long range inferences to  discriminate ambiguous pixels.  to model the dependencies among image units  an effective way         is to represent the image with an undirected  cyclic graph  ucg  in which the image units are vertices  and their interactions are encoded by undirected edges  see  fig.   a  . due to the loopy structure of ucg  however  it  is hard to directly apply rnns to model dependencies in  an image. to handle this problem  a ucg is approximated     with several directed acyclic graphs  dags   see fig.   b  .  then several dag structured rnns are adopted to model  the dependencies in these dags.     . . motivation  though these dag structured rnns can model dependencies in images  some useful information may be discarded. for instance in fig.   a   to correctly distinguish a   sand  unit  marked in red region  from a  road  one  dagstructured rnns can use the dependencies of  water  units   marked in pink region  from its adjacent neighbors. however  the  water  information may be decaying because it  needs to pass through conductors  i.e.  the adjacent neighbors of this  sand  unit . instead  a better way is to directly  use dependencies from  water  units to recognize the  sand   unit. to such end  we propose dense rnns to fully explore  abundant dependencies in images for scene parsing.  analogous to cnns  dag structured rnns can be unfolded to a feed forward network where each vertex is a  layer and a directed edge between two layers represents information flow  i.e.  dependency relationship between two  vertexes . the dependency information in an image flows  from the first layer  i.e.  the start vertex at top left corner  in fig.   b   to the last layer  i.e.  the end vertex at bottomright corner in fig.   b  . inspired by the superior performance of recently proposed densenet      in image recognition  which introduces dense connections among layers  to improve information flow in cnns  we propose to add  more connections into the rnn feed forward network as  well  see fig.   d    to incorporate richer dependency information among image units.  despite abundant dependencies from dense connections   we argue that not all dependencies are equally helpful to  recognize a specific image region. for example in fig.   d    the  sky  units in blue region are not useful to distinguish  the  sand  unit in the red region from the  road  unit. in contrast  the dependencies from  water  units in the pink region  are more crucial to infer its label. therefore  more importance should be assigned to the dependencies from  water   units  which motivates us to integrate an attention model  into dense rnns to select more useful dependencies.     . . contribution  the first contribution of this work is the dense rnns   which capture richer dependencies for image units from  various abundant connections. unlike previous approaches  representing an image as a ucg  we formulate each image  with a dense ucg  d ucg   which is a complete graph. in  d ucg  each pair of vertexes are connected with an undirected edge  see fig.   c  . by decomposing the d ucg  into several dense dags  d dags   we propose the dagstructured dense rnns  dd rnns  to model dependencies  in an image  see fig.   d  . compared with plain dag     structured rnns  our dd rnns can gain richer dependencies from various levels. for instance in fig.   c   to correctly recognize the  sand  unit in the red region  in addition  to the dependencies from its neighbors  dd rnns enable  the firsthand use of dependencies from  water  units in the  pink region to improve its discriminability.  although dd rnns are capable of capturing vast dependencies through dense connections  for a specific image unit  certain dependencies are irrelevant to help improve discriminative power. to tackle this issue  we make  the second contribution by introducing a novel attention  model into dd rnns. the attention model is able to automatically select relevant and meanwhile restrain irrelevant  dependency information for image units  further enhancing  their discriminative power.  last but not least  the third contribution is to implement  an end to end labeling system based on our dd rnns. for  validation  we test our method on three benchmarks  pascal context       mit ade  k      and cityscapes     .  in these experiments the proposed approach significantly  improves the baselines and outperforms other state of theart methods.     . related work  scene parsing. scene parsing has drawn extensive attentions in recent decades. early efforts mainly focus on the  graphical model with hand crafted features                 .  despite great progress  these methods are restricted due to  the use of hand crafted features.  inspired by the success in image recognition                cnns have been extensively explored for scene parsing.  long et al.      propose a scene labeling method by transforming standard cnns for classification into fully convolutional networks  fcn   resulting in significant performance gains. to generate desired full resolution predictions  various methods are proposed to upsample lowresolution feature maps to high resolution feature maps for  final prediction            . in order to remit boundary problem in predictions  graphical models such as conditional  random field  crf  or markov random field  mrf  are  introduced into cnns            . as a pixel level classification problem  contexts are crucial role in scene labeling to distinguish visually similar pixels of different categories. the work of      introduces the dilated convolution  into cnns to aggregate multi scale context. liu et al.       suggest an additional branch in cnns to incorporate global  context for scene parsing. in       zhao et al. propose a  spatial pyramid pooling module to fuse contexts from different levels  showing superior performance in scene parsing. zhang et al.      introduce an context encoding module  into cnns to improve parsing performance.  rnns on computer vision. with the capability of model      ing spatial dependencies in images  rnns      have been  applied to many computer vision tasks such as image completion       handwriting recognition       image classification       visual tracking       skin detection      and so  forth. considering the importance of spatial dependencies  in an image to distinguish ambiguous pixels  there are attempts to applying rnns for scene labeling.  the work of     explores the two dimensional long short  term memory  lstm  networks for scene parsing by taking  into account the spatial dependencies of pixels in images.  stollenga et al.      introduce a parallel multi dimensional  lstm for image segmentation. liang et al.      propose a  graph based lstm to model the dependencies among different superpixels. the work of      applies a local global  lstm model on object parsing. visin et al.      suggest to  utilize multiple linearly structured rnns to model horizontal and vertical dependencies among image units for scene  labeling. li et al.      extend this method by substituting  rnns with lstm and apply it to rgb d scene labeling.  qi      proposes the gated recurrent units  grus  to model  long range context. especially  to exploit more spatial dependencies in images  shuai et al.      propose to represent  an image with a ucg. by decomposing ucg into several  dags  they then propose to use dag structured rnns to  model dependencies among image units.  attention model. the attention model  being successfully  applied in natural language processing  nlp  such as machine translation     and sentence summarization       has  drawn increasing interest in computer vision. xu et al.       propose to leverage an attention model to find out regions  of interest in images which are relevant in generating next  word. in      chen et al. propose a scale attention model  for semantic segmentation by adaptively merging outputs  from different scales. in      the attention model is utilized  to assign importance to different regions for context modeling in images. the work of      introduces a co attention  model to combine question and image features for question  answering. chu et al.      utilize attention model to fuse  multi context for human pose estimation.  our approach. in this paper  we focus on how to effectively exploit abundant dependencies in images and introduce the dense rnns module. our approach is related to  but different from previous rnn approaches  e.g.  dagstructured rnns      and linearly structured rnns      or  lstm        in which each image unit only receives dependency information from its limited neighbors and considerable useful dependencies are thrown away. in contrast  we  propose to add dense paths into rnns to enable immediate  long range dependencies. consequently  each image unit  can directly  see  dependencies in the whole image  leading to more discriminative representation. it is worth noting that the idea of dense connections can not only used for  graphical rnns      but also easily applied to other linearly    structured rnns         .  furthermore  we introduce an attention model into dense  rnns. to the best of our knowledge  this work is the first  to use attention mechanism in rnns for scene parsing. our  attention model automatically selects relevant and restrains  irrelevant dependencies for image units from dense connections  further improving their discriminabilities.     . the proposed approach   . . review of dag structured rnns  the linear rnns in      are designated to deal with sequential data related tasks. specifically  a hidden unit ht in  rnns at time step t is represented with a non linear function over current input xt and hidden layer at previous time  step ht     and the output yt is connected to the hidden unit  ht . given an input sequence  xt  t          t   the hidden unit  and output at time step t can be computed with  ht    u xt   w ht     b            yt    v ht   c            where u   v and w represent transformation matrices  b and  c are bias terms  and      and      are non linear functions   respectively. since the inputs  xt  t          t are progressively stored in the hidden layers as in eq.      rnns are  able to preserve the memory of entire sequence and thus  capture the long range contextual dependencies.  for an image  the interactions among image units can be  formulated as a graph in which the dependencies are forwarded through edges. the solution in      utilizes a standard ucg to represent an image  see again fig.   a  . to  break the loopy structure of ucg       further proposes to  decompose the ucg into four dags along different directions  see fig.   b  for a southeast example .  let g    v  e  denote the dag as shown in fig.   b    where v    vi  n  i   represents the vertex set of n vertexes   e    eij  n  i j   represents the edge set  and eij indicates  a directed edge from vi to vj . a dag structured rnn resembles the identical topology of g  with a forward pass  formulated as traversing g from start vertex. in such modeling  the hidden layer of each vertex relies the hidden units  of its adjacent predecessors  see fig.   b  . for vertex vi    its hidden layer hvi and output yvi are computed with  x  hvi    u xvi   w  hvj   b        vj  pg  vi      yvi    v hvi   c            where xvi denotes the local feature at vertex vi and pg  vi    represents the predecessor set of vi in g. by storing local  inputs into hidden layers and progressive forwarding among  them with eq.      the discriminative power of each image  unit is improved with dependencies from other units.      . . dense rnns  in dag structured rnns  each image unit receives the  dependencies from other units through recurrently forwarding information between adjacent units. nevertheless  the  useful dependency information may be potentially degraded  after going through many conductors  resulting in a dependency decaying problem. for instance in fig.   b   the  most useful contextual cues from  water  units have to pass  through conductors to arrive at the  sand  unit covered in  the red region. a natural solution to remedy the problem  of dependency decaying is to add additional paths between  hidden layers of distant units and current image unit.  inspired by the recently proposed densenet      that introduces dense connections into cnns  we propose dagstructured dense rnns  dd rnns  to model richer dependencies in an image. we first view a dag structured rnns  as unfolded to get a feed forward network  where the dependency information in an image flows from start to end  vertexes. then  to capture richer dependencies in images   e.g.  forthright dependencies among non adjacent units in  fig.   b    we introduce more connections in the rnn feedforward network  resulting in the proposed dd rnns.  to achieve dense connections  we represent each image  with a dense ucg  d ucg   which is equivalent to a complete graph  see fig.   c  for illustration . compared to  standard ucg  d ucg allows each image unit to connect  with all of other units. because of the loopy property of ducg  we adopt the strategy as in      to decompose the ducg to four d dags along four directions. one of the four  d dags along the southeast direction is shown in fig.   d .  let d represent the d dag in fig.   d . the structure of  dd rnns resembles the identical topology of d as in fig.    c . in dd rnns  the hidden layer of each vertex relies  on the hidden units of all its adjacent and non adjacent predecessors  which fundamentally differs from      in which  the hidden unit of each vertex only relies on hidden units of  its adjacent predecessors  see fig.   b  . the forward pass  at the vertex vi in dd rnns is expressed as  x  h vi    hvj       vj  pd  vi      hvi    u xvi   w h vi   b            yvi    v hvi   c            where pd  vi   is the dense predecessor set of vi in d dag  d  and it contains both adjacent and non adjacent predecessors  see fig.   d  . compared to the dag structured  rnns in       our dd rnns are able to capture richer dependencies in an image through various dense connections.  a concern arisen naturally from the dense model is the  complexity. in fact  it is unrealistic to directly apply ddrnn to pixels of an image. fortunately  neither is it necessary. as described in section  .   we apply dd rnn to                           a  dag structured rnns     b  predecessors for      in dag rnns                         c  dag structured dense rnns  d  predecessors for      in dd rnns    figure  . the illustration of difference between dag structured  rnns      and our dd rnns. image  a  shows the dagstructured rnns along southeast direction  and in  b  the hidden  layer of vertex vi relies on its three adjacent predecessors  see the  red region in  b  . image  c  is our dd rnns  and in  d  the hidden layer of vi is dependent on all its adjacent and non adjacent  predecessors  see the red region in  d  . best viewed in color.    a high layer output of existing cnn models. such strategy  largely reduces the computational burden   as summarized  in table    our final system runs faster than many state ofthe arts while achieving better labeling accuracies.     . . attention model in dd rnns  for the hidden layer at vertex vi   it receives various  dependency information from predecessors through dense  connections. however  the dependencies from different predecessors are not always equally helpful to improve the discriminative representation  see fig.   d  . for example  to  distinguish the  sand  units from visually alike  road  units  in a beach scene  the most important contextual cues are  probably the dependencies from  water  units instead of  other units such as  sky  or  tree . in this case  we term the  relation from  water  units as relevant dependencies while  the information from  sky  or  tree  units as irrelevant ones.  to encourage relevant dependencies and meanwhile restrain irrelevant ones for each image unit  we introduce a  soft attention model     into dd rnns. in      the attention model is employed to softly assign importance to input  words in a sentence when predicting a target word for machine translation. in this paper  we leverage attention model  to select more relevant and useful dependencies for each image unit. to this end  we do not directly use eq.     and      to model the relationships between hvi and its predecessors.     prediction    cnns features    cnns features    dd rnns prediction  features    prediction    upsampling x      upsampling x      dd rnns    cnns features  input    upsampling x      conv    pooling    conv    pooling    conv    pooling    conv    pooling    conv    pooling    prediction    prediction  labeling    figure  . the architecture of our full system. the dd rnns are placed on the top of feature maps obtained from the last convolutional  block to model long range dependencies in an image  and the deconvolution is used to upsample the predictions. low level and high level  features are combined through skip strategy for final labeling  see the green arrows . best viewed in color.    instead  we employ the following expression to model the  dependency between hvi and one of its predecessors hvj  hvi  vj     u xvi   w hvj   b            mathematical formulation for this process is expressed as  hlvi  vj    u l xvi   w l hlvj   bl    x  hlvi    hlvi  vj wvl i  vj                  vj  pdl  vi      where hvj represents the hidden layer of a predecessor vj    pd  vi   of vi . the hvi  vj in eq.     models dependency  information from hvj for hvi . the final hidden unit hvi  at vi is obtained by summarizing all hvi  vj with attentional  weights  as computed by  hvi      x    hvi  vj wvi  vj           vj  pd  vi      where the attention weight wvi  vj for hvj reflects the relevance of the predecessor vj to vi   calculated by  exp z t hvi  vj    wvi  vj   p  exp z t hvi  vk              vk  pd  vi      where z t represents a transformation matrix.  with the above attention model  we replace eq.     and      with eq.     and     for a forward pass at vi in ddrnns. by using stochastic gradient descent  sgd  method   the attentional dd rnns can be trained in an end to end  manner.     . . full labeling system  before showing the full labeling system  we first introduce the decomposition of d ucg. as in       we decompose the d ucg u into a set of d dags represented with   dl  l  l     where l is the number of d dags. since equation     only computes the hidden layer at vertex vi in one  of l d dags  the final output y vi at vi is derived by aggregating the hidden layers at vi from all d dags. the    xl  y vi      v l hlvi   c   l              with the equations above  the proposed dd rnns can be  used to capture abundant dependencies among image units.  we develop an end to end scene labeling system by integrating our approach with cnns for scene parsing as shown  in fig.  . the proposed dd rnns are placed on the top of  feature maps obtained after the last convolutional block to  model long range dependencies in the input image  and the  deconvolution operations are used to upsample the predictions. to produce the desired input size of labeling result   we utilize the deconvolution      to upsample predictions.  taking into account both spatial and semantic information  for scene labeling  we adopt the skip strategy      to combine low level and high level features. the whole system is  trained end to end with the pixel wise cross entropy loss.     . experimental results  implementation details. in order validate the effectiveness of the proposed dd rnns  we develop two labeling  systems by integrating our dd rnns with two different architectures  the vgg         and the resnet         . the  dd rnns are employed to model dependencies among image units in output of the last convolutional block  fig.   .  the network takes           images as inputs  and outputs  the labeling results with the same resolution. when evaluating  the labeling results are resized to the original input size.  the dimension of input  hidden and output units for ddrnns is set to    . the two non linear activations   and    are relu and softmax functions  respectively. the full networks are end to end trained with standard sgd method.  for convolutional blocks  the learning rate is initialized to     table  . baseline comparisons of miou     with different backbones on pascal context       mit ade  k  validation set       and  cityscapes  validation set      .    baseline fcn  fcn crf  fcn dag rnn  fcn dd rnn    pascal context       vgg     resnet        .     .     .     .     .     .     .     .     be      and decays exponentially with the rate of  .  after     epochs. for d rnns  the learning rate is initialized to  be      and decays exponentially with the rate of  .  after    epochs. the batch sizes for both training and testing  phases are set to  . the results are reported after    training epochs. the networks are implemented in matlab using  matconvnet      on a single nvidia geforce titan gpu  with   gb memory.  datasets. we test our method on the large scale pascal  context       mit ade  k      and cityscapes     .  the pascal context contains        images annotated  into     classes  where       images are used for training  and the rest for testing. similar to other literatures  we only  consider the most frequent    classes for evaluation.  the recent mit ade  k consists of        images in  training set and       images in validation set. there are  total     semantics classes in the dataset.  the cityscapes contains      images of street traffic  scene  where      images are used for training      images  for validation  and the rest for testing. in total     classes  are considered for training and evaluation.  evaluation metrics. as in       we utilize mean intersection over union  miou   for evaluation.     . . baseline comparisons  to better analyze our method  we develop several baselines to prove its effectiveness   baseline fcn is implemented by removing our attentional dd rnns from networks. note that the baseline  fcn differs from fcn  s      because we discard two  fully connected layers. other settings remain the same as  in fcn  s     .  fcn crf is implemented by applying crf      to perform post processing on the results of baseline fcn.  fcn dag rnn is implemented by substituting the  attentional dd rnns with plain dag rnn. note that  fcn dag rnn varies from      because we do not use  class weighting strategy and larger conventional kernel in  our labeling system.  fcn dd rnns represents the proposed scene labeling  method.  table   shows the quantitative results between different  baselines and our approach with two backbones. all crf     mit ade  k       vgg     resnet        .     .     .     .     .     .     .     .     cityscapes       vgg     resnet        .     .     .     .     .     .     .     .     dag rnn and dd rnns can improve the performance  of baseline fcn. more specific  our method obtains miou  gains of  .     .   and  .   with vgg    and of  .      .   and  .   with resnet     on three datasets  and outperforms other two baselines using crf and dag rnn.     . . comparison results on pascal context  table  . quantitative comparisons on pascal context           classes .    algorithm  camn      pixelnet      fcn  s       ho crf      boxsup       parsenet       convpp         cnn crf       crf rnn       dag rnn       dag rnn crf       deeplab v  crf      gce       refinenet       dd rnns  dd rnns    backbone  vgg     vgg     vgg     vgg     vgg     vgg     vgg     vgg     vgg     vgg     vgg     resnet      resnet      resnet      vgg     resnet        miou        .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     the quantitative comparisons to state of the art methods are summarized in table  . benefiting from deep  cnns  fcn  s      achieves promising result with miou  of   .  . in order to alleviate boundary issue in fcn  s   crf rnn      and deeplab v  crf     use probabilistic  graphical model such as crf in cnns  and obtain mious  of   .   and   .    respectively. other approaches such  as camn      parsenet      and gce      suggest to improve performance by incorporating global contextual information and obtain mious of   .      .   and   .  .  despite improvements  these methods ignore long range  dependencies in images  which are crucial for inferring ambiguous pixels. the method in      employs rnns to capture contextual dependencies among image units for scene  labeling and shows outstanding performance with miou of    .   with vgg   . moreover  they use crf to improve     table  . quantitative comparisons on mit ade  k  validation  set      .    algorithm  segnet      fcn  s       dilatednet       cascade segnet       cascade dilated       gce       refinenet       dd rnns  dd rnns    input    groundtruth    fcn  s    plain dag rnn    dd rnns    figure  . qualitative labeling results with vgg    on the pascal context     . best viewed in color.    backbone  vgg     vgg     vgg     vgg     vgg     resnet      resnet      vgg     resnet        miou        .     .     .     .     .     .     .     .     .     obtain the miou of   .   with vgg     and achieve better  performance with miou of   .   when using resnet      as backbone.     . . comparison results on cityscapes  the result to   .  . different from       we propose ddrnns to capture richer dependencies. without any class  weighting strategy and post processing  our dd rnns with  vgg    obtain the miou of   .    which outperforms the  method in      by  .    showing the advantage of ddrnns. with deeper resnet      we achieve the miou of    .    outperforming the state of the art refinenet     .  fig.   shows qualitative results obtained with vgg     on pascal context     . without considering long range  contextual dependencies in images  fcn  s      is prone  to cause misclassification  see the third column in fig.   .  our baseline can help alleviate this situation using rnns  to capture dependencies in images. for example  in the  first two rows in fig.    the  water  can be correctly recognized with the dependencies from  boat . however  the  plain rnns fail in more complex scenes  see the last three  rows in fig.   . for example  in the fourth row in fig.     most of  road  pixels are mistakenly classified into  ground   pixels without full use of dependencies from  bus . by contrast  the proposed dd rnns are capable of recognizing  most of  road  pixels by taking advantages of richer dependencies from  bus  in images.     . . comparison results on mit ade  k  table   summarizes the quantitative results and comparisons to other algorithms. the fcn  s      achieves the  miou of   .  . to incorporate multi scale contexts        proposes the dilated convolution and improves the miou to    .  . to same end  hung et al.      embed global context into cnns to obtain improvements  and improve the  performance to   .   with resnet    . though the aforementioned methods take the global context of image into  account  they ignore long range contextual dependencies in  images. in this work  we employ dd rnns to model this  dependency information for scene labeling. in specific  we    table   summarizes the quantitative comparison results  with state of the art approaches on cityscapes     . since  the resolution of image is too large  we divide each image  into multiple patches. after obtaining the parsing result of  each patch  we combine them to derive the labeling of original image. among the compared algorithms  fcn  s       achieves the miou of   .  . liu et al.      adopt markov  random field  mrf  to model high order cnns and obtain a miou of   .  . the approach of      utilizes crf  to capture contextual information for scene parsing and improves the miou to   .  . deeplabv      combines both  crf and atrous convolution to incorporate more contexts  and achieves a miou of   .  . in this work  we propose  dense rnns to capture richer dependencies from the whole  image for each image unit. with the resnet backbone  we  achieve the miou of   .    outperforming other context  aggregation methods.  table  . quantitative comparisons on cityscapes  test set      .    algorithm  segnet      fcn  s       dpn       lrr  x       cnn crf       dilatednet       deeplab v  crf      lc       refinenet       pearl       sac       dd rnns  dd rnns    backbone  vgg     vgg     vgg     vgg     vgg     vgg     resnet      resnet      resnet      resnet      resnet      vgg     resnet        miou        .     .     .     .     .     .     .     .     .     .     .     .     .      table  . analysis of miou     with and without attention model  in dd rnns using vgg   .    pascal context  mit ade  k  cityscapes    dd rnns w o  attention model    .     .     .     dd rnns w   attention model    .     .     .     table  . analysis of computation complexity and accuracy of ddrnns on pascal context      dataset.    algorithm  cfm       camn      fcn  s       parsenet       crf rnn       deeplab      baseline fcn  vgg      baseline dag rnn  vgg      dd rnns  vgg      dd rnns  resnet         inference miou       .   s    .    .   s    .    .   s    .    .   s    .    .   s    .    .   s    .    .   s    .    .   s    .    .   s    .    .   s    .     highlights these regions. in the third column  we can see  that our model pays more attention to the relevant  bus  dependencies to correctly recognize the  road  region.     . . study on model complexity  figure  . visualization of the learned attentional weight map for a  specific region  marked in red rectangle in the first row . first row   input image. second row  groundtruth. third row  attentional  weight map. best viewed in color.     . . ablation study on attention model  in this paper  we propose the dd rnns to model richer  dependencies in images  which significantly enhances discriminability for each image unit. however  different dependencies are not always equally helpful. to activate relevant and restrain irrelevant dependencies  we introduce an  attention model into dd rnns. to demonstrate the effectiveness of attention model  we conduct experiment by removing attention model from dd rnns. note that in these  two groups of experiments  the only difference is the attention model  while other settings  e.g.  parameters for all  other layers  are exactly the same. table   summarizes the  results on three benchmarks with vgg     and shows that  the attention model helps to further improve performance.  in order to better understand the attention model  we  show the learned attentional weight map for a specific region as shown in fig.  . from fig.    we can see that relevant dependencies are enhanced while irrelevant information are restrained. for example in the first column  the  most helpful contextual dependencies for the  water  region  come from its surrounding and the  boat  instead of  tree   or  sky   and our attention model learns to pay more importance to the relevant dependencies  i.e.  surrounding region and  boat   in the weight map. in the second column  in fig.    to recognize  sign  region  the useful information  comes from surrounding and the  bus   our attention model    as a practical application  both efficiency and accuracy  are crucial for scene labeling. to better analyze the proposed approach  we demonstrate the inference time of one  forward pass and accuracy on the pascal context     .  table   reports the efficiency and accuracy of our baseline and other scene labeling algorithms. compared to its  baseline fcn  vgg      our algorithm dd rnns  vgg    obtains miou gain of  .   while the inference time  only increase by  .  s  showing the advantage of our ddrnns module. moreover  when replacing the vgg     with resnet     as our backbone  the miou is further improved to   .  . in comparison with approaches including  camn      fcn  s       crf rnn      and deeplab       our method runs efficiently while achieving better accuracy.     . conclusion  this paper proposes dense rnns for scene labeling. unlike existing methods exploring limited dependencies  our  dag structured dense rnns  dd rnns  exploit abundant  contextual dependencies through dense connections in an  image  which better improves the discriminative power of  image units. in addition  considering that different dependencies are not always equally helpful to recognize each image unit  we propose an attention model to assign more importance to relevant dependencies. integrating with cnns   we develop an end to end labeling system. extensive experiments on pascal context  mit ade  k and cityscapes  demonstrate that our dd rnns significantly improve the  baselines and outperform other state of the art algorithms   evidencing the effectiveness of proposed dense rnns.  acknowledgements. this work is supported in part by us  nsf grants                   and        .     