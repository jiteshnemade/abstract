introduction  scene labeling refers to associating one of the semantic  classes to each pixel in a scene image. it is usually defined  as a multi class classification problem based on their surrounding image patches. however  some classes may be indistinguishable in a close up view. as an example in figure    equal    contribution          rnns model the contextual dependencies of local features   and output the improved context aware representation. the  deconvolution layer upsamples the feature maps to match  the dimensionality of the desired outputs. overall  the full  labeling network accepts variable size images and generates the corresponding dense label prediction maps in a single feed forward network pass. furthermore  considering  that the class frequency distribution is highly imbalanced in  natural scene images  we propose a novel class weighting  function that attends to rare classes.  we test the proposed labeling network on three popular and challenging scene labeling benchmarks  siftflow        camvid     and barcelona     . on these datasets  we  show that our dag rnns are capable of greatly enhancing the discriminative power of local representations  which  leads to dramatic performance improvements over baselines   cnns  even the vgg verydeep    network      . meanwhile  the proposed class weighting function is able to boost  the recognition accuracy for rare classes. most importantly   our full labeling network significantly outperforms current  state of the art methods.  next  related work are firstly reviewed  compared and  discussed in section  . section   elaborates the details of  the dag rnns and how they are applied to image labeling.  besides  it presents the details of the full labeling network  and the class weighting function. the detailed experimental  results and analysis are presented in section  . in the end   section   concludes the paper.     . related work  scene labeling  also termed as scene parsing  semantic  segmentation  is one of the most challenging problems in  computer vision. it has attracted more and more attention  in recent years. here we would like to highlight and discuss  three lines of works that are most relevant to ours.  the first line of work is to explore the contextual modeling. one attempt is to encode context into local representation. for example  farabet et al.     stacks surrounding  contextual windows from different scales  pinheiro et al.       increases the size of input windows. sharma et al.       adopts recursive neural networks to propagate global context to local regions. however  they do not consider any  structure for image units  thus their correlations are not effectively captured. in contrast  we interpret the image as an  ucg  within which the connections allow the dag rnns  to explicitly model the dependencies among image units.  another attempt is to pass context to local classifiers by  building probabilistic graphical models  pgm . for example  shotton et al.      formulates the unary and pairwise  features in a  nd order conditional random field  crf .  zhang et al.     and roy et al.      build a fully connected  graph to enforce higher order labeling coherence. shuai  et al.     models the global order dependencies in a non     parametric framework to disambiguate the local confusions.  our work also differs from them. first  the label dependencies are defined in terms of compatibility functions in pgm   while such dependencies are modeled through a recurrent  weight matrix in rnns. moreover  the inference of pgm is  inefficient as the convergence of local beliefs usually takes  many iterations. in contrast  rnns only need a single forward pass to propagate the local information.  some of the previous work exploit  recurrent  ideas in  a different way. they generally refer to applying the identical model recurrently at different iterations  layers . for  example  pinheiro et al.     attachs the rgb raw data with  the output of the convolutional neural network  cnn  to  produce the input for the same cnn in the next layer. tu  et al.     augments the patch feature with the output of the  classifier to be the input for the next iteration  and the classifier parameters are shared across different iterations. zheng  et al.     transforms conditional random fields  crf  to  a neural network  so the inference of crf equals to applying the same neural network recurrently until some fixed  point  convergence  is reached. our work differs from them  significantly. they model the context in the form of intermediate outputs  usually local beliefs   which implicitly encodes the neighborhood information. in contrast  the contextual dependencies are modeled explicitly in dag rnns  by propagating information via the recurrent connections.  recurrent neural networks  rnns  have achieved great  success in temporal dependency modeling for chainstructured data  such as natural language and speeches. zuo  et al.      applies  d rnn to model weak contextual dependencies in image classification. graves et al.     generalizes  d rnn to multi dimensional rnn  mdrnn  and  applies it to offline arabic handwriting recognition. shuai  et al.     also adopts  d rnn to real world image labeling. recently  tai et al.     and zhu et al.     demonstrate that considering tree structure  constituent   parsing  trees for sentences  is beneficial for modeling the global  representation of sentences. our proposed dag rnn is a  generalization of chain rnns          tree rnns           and  d rnns          and it enables the network to model  long range semantic dependencies for graphical structured  images. the most relevant work to ours is     . in comparison with which       we generalize  d rnn to dag rnn  and show benefits in quantitative labeling performance        we integrate the convolution layer  deconvolution layer with  our dag rnns to a full labeling network  and      we  adopt a novel class weighting function to address the extremely imbalanced class distribution issue in natural scene  images. to the best of our knowledge  our work is the first  attempt to integrate the convolution layers with rnns in an  end to end trainable network for real world image labeling.  moreover  the proposed full network achieves state of theart on a variety of scene labeling benchmarks.      . approach  to densely label an image i  the image is processed by  three different functional layers sequentially       convolution layer produces the corresponding feature map x. each  feature vector in x summarizes the information from a local  region in i.      dag rnns model the contextual dependency among elements in x  and generates the intermediate  feature map h  whose element is a feature vector that implicitly embeds the abstract gist of the image.      deconvolution layer      upsamples the feature maps. from which   the dense label prediction maps are derived. we start by introducing the proposed dag rnns  and the details of the  full network are elaborated in the following sections.    dag  gse     ucg    neighborhood   sky    sand    sea    figure    an   neighborhood ucg and one of its induced dag in the  southeastern  se  direction.     . . rnns revisited  a recurrent neural network  rnn  is a class of artificial  neural network that has recurrent connections  which equip  the network with memory. in this paper  we focus on the  elman type network    . specifically  the hidden layer h t   in rnns at time step t is expressed as a non linear function  over current input x t  and hidden layer at previous time  step h t    . the output layer y  t  is connected to the hidden  layer h t  .  mathematically  given a sequence of inputs  x t   t   t    an elman type rnn operates by computing the following  hidden and output sequences   h t    f  u x t    w h t      b   y  t    g v h t    c            where u  w are weight matrices between the input and  hidden layers  and among the hidden units themselves   while v is the output matrix connecting the hidden and output layers  b  c are corresponding bias vectors and f      g     are element wise nonlinear activation functions. the initial  hidden unit h    is usually assumed to be  . the local information x t  is progressively stored in the hidden layers by  applying equation  . in other words  the contextual information  the summarization of past sequence information  is  explicitly encoded into local representation h t    which improves their representative power dramatically in practice.  training a rnn can be achieved by optimizing a discriminative objective with a gradient based method. back  propagation through time  bptt       is usually used to  calculate the gradients. this method is equivalent to unfolding the network in time and using back propagation in  a very deep feed forward network except that the weights  across different time steps  layers  are shared.     . . dag rnns  the aforementioned rnn is designed for chainstructured data  e.g. sentences or speeches   where temporal dependency is modeled. however  interactions among    image units are beyond chain. in other words  traditional  chain structured rnns are not suitable for images. specifically  we can reshape the feature tensor x   rh w d to  x    r h w  d   and generate the chain representation by  connecting contiguous elements in x . such a structure loses  spatial relationship of image units  as two adjacent units in  image plane may not necessarily be neighbors in the chain.  the graphical representations that respect the   d neighborhood system are more plausible solutions  and they are pervasively adopted in probabilistic graphical models  pgm .  therefore in this work  undirected cyclic graphs  ucg   an  example is shown in figure    are used to model the interactions among image units.  due to the loopy structure of ucgs  they are unable  to be unrolled to an acyclic processing sequence. therefore  rnns are not directly applicable to ucg structured  images. to address this issue  we approximate the topology of ucg by a combination of several directed acyclic  graphs  dags   each of which is applicable for our proposed dag rnns  one of the induced dags is depicted  in figure   . namely  an ucg structured image is represented as the combination of a set of dag structured images. we now start introducing the detailed mechanism of  our dag rnns here  and later elaborate how they are applied to ucg structured images in the next section.  we first assume that an image i is represented as a dag  g    v  e   where v    vi  i   n is the vertex set and  e    eij   is the arc set  eij denotes an arc from vi to vj  .  the structure of the hidden layer h follows the same topology as g. therefore  a forward propagation sequence can be  generated by traversing g  on the condition that one node  should not be processed until all its predecessors are processed. the hidden layer h vi   is represented as a nonlinear  function over its local input x vi   and the summarization  of hidden representation of its predecessors. the local input x vi   is obtained by aggregating  e.g. average pooling   from constituent elements in the feature tensor x. in detail   the forward operation of dag rnns is calculated by the     following equations    vi      h          x    convolution  layer     vj      h    dag recurrent  neural network    deconvolution  layer    vj  pg  vi             h vi     f  u x vi     w h  vi     b   o vi     g v h vi     c     where x vi     h vi     o vi   are the representations of input   hidden and output layers located at vi respectively  pg  vi    is the direct predecessor set of vertex vi in the graph g  h  vi    summarizes the information of all the predecessors of vi .  note that the recurrent weight w in equation   is shared  across all predecessor vertexes in pg  vi  . we may learn a  specific recurrent matrix w for each predecessor when vertexes  except source and sink vertex  in the dag g have a  fixed number of predecessors. in this case  a finer grained  dependency may be captured.  the derivatives are computed in the backward pass  and  each vertex is processed in the reverse order of forward  propagation sequence. specifically  to derive the gradients  at vi   we look at equations  besides equation    that involve  h vi   in the forward pass   h vk     f  u x vk     w h vi     w h  vk     b   x  v    h  vk      h j           where sg  vi   is the direct successor set for vertex vi in  the graph g. it can be inferred from equation      that  the errors backpropagated to the hidden layer  dh vi     at vi   o vi    have two sources  direct errors from vi    h   vi      and summation over indirect errors propagated from its successors  p  o vk    h vk      vk  h   vk    h vi    . the derivatives at vi can then be computed by the following equations      v  vi     g    o vi     h vi    t  x  dh vi     v t g    o vi        w t dh vk     f    h vk      vk  sg  vi       w         dh     vk        f    h vk     h vi    t            u     vi      hd    x      f  ud x vi        vj  pg  vi    d    x     vi      vd hd     vj      wd hd      bd             c     where ud   wd   vd and bd are weight matrices and bias vector for the dag gd   pgd  vi   is the direct predecessor set  of vertex vi in gd . this strategy is reminiscent of the treereweighted max product algorithm  trw        which represents the problem on the loopy graphs as a convex combination of tree structured problems.  we consider the following criterions for the decomposition. topologically  the combination of dags should be  equivalent to the ucg u  so any two vertexes can be reachable. besides  the combination of dags should allow the  local information to be routed to anywhere in the image. in  our experiment  we use the four context propagation directions  southeast  southwest  northwest and northeast  suggested by         to decompose the ucg. one example of  the induced dag of the   neighborhood ucg in the southeast direction is shown in figure  .     . . full labeling network    vk  sg  vi     vi      we decompose the ucg u to a set of dags g u     g    . . .   gd   . . . . hence  the ucg structured image is represented as the combination of a set of dag structured images. next  dag rnns are applied independently to each  dag structured image  and the corresponding hidden layer  hd is generated. the aggregation of the independent hidden  layers yields the output layer o. these operations can be  mathematically expressed as follows     gd  g u    vj  pg  vk    vi      x     . . decomposition    o vi     g      vk   sg  vi       vi      figure    the architecture of the full labeling network  which consists of  three functional layers       convolution layer  it produces discriminative  feature maps       dag rnn  it models the contextual dependency among  elements in the feature maps       deconvolution layer  it upsamples the  feature maps to output the desired sizes of label prediction maps.      dh vi     f    h vi     x vi    t   l  o      o     g    where   denotes the hadamard product  g          is the derivative of loss function l with respect to the output function g  and f          h   f . it is the second term of   vi    dh  in equation   that enables dag rnns to propagate  local information  which behaves similarly to the message  passing      in probabilistic graphic models.    to save space  we omit the expression for  b and  c here as they can  be inferred trivially from equation  .    the skeleton architecture of the full labeling network is  illustrated in figure  . the network is end to end trainable   and it takes input as raw rgb images with any size. it outputs the label prediction maps with the same size of inputs.  the convolution layer is used to produce compact yet  highly discriminative features for local regions. next  the  proposed dag rnn is used to model the semantic contextual dependencies of local representations. finally  the  deconvolution layer      is introduced to upsample the feature maps by learning a set of deconvolution filters  and it                .              weight    frequency     .      .               .         .           b sk  mouildiny  un g  tain  tre  roae  d  se  fie a  gra ld  s  riv s  plaer  nt  c  sa ar  nd  sid roc  e k  winwalk  do  de w  se  d rt  bri oor  pe dge  rs  fe on  ba nce  cro lco  s n  sta swa y  irc lk  aw ase  nin  str sigg  ee n  tlig  h  bo t  a  po t  le  bu  s  su  co n  w  b  moird  on         b sk  mouildiny  un g  tain  tre  roae  d  se  fie a  gra ld  s  riv s  plaer  n  c t  sa ar  n  sid rocd  e k  winwalk  do  de w  se  d rt  bri oor  pe dge  rs  fenon  b  c  cro alco e  s n  sta swa y  irc lk  aw ase  nin  str sig g  ee n  tlig  boht  poat  le  bu  su s  n  co  w  b  moird  on         figure    graphical visualization of the class frequencies  left  and weights   right  on the siftflow datasets     . the classes are sorted in the descending order based on their occurrence frequencies in training images.    a frequent class. k is a constant that controls the importance  of rare classes  k     in our experiments . the proposed  weighting function has the following properties       it attends to rare classes by assigning them higher weights        the degree of attention for rare classes grows exponentially  based on their ratio magnitudes w.r.t the threshold    the  following criterion is used to determine the value of    the  accumulated frequency of all the non rare classes is    .  we call it         rule  and      uses a similar rule.     . experiments  enables the full labeling network to produce the desired size  of label prediction maps.  to train the network  we adopt the average weighted  cross entropy loss. it is formally written as   l      c    xx   v    v    wj log oj i yj i    n v  i j              . . baselines    i    where n is the number of image units in image i  w is the  class weight vector  in which wj stands for the weight for  class j  y vi   is the binary label indicator vector for the image unit located in vi   and o vi   stands for the corresponding  class likelihood vector. the errors propagated from dagrnns to the convolution layer for image unit vi are calculated based on the following equations    x vi        x     vi      udt dhd      f    hd     vi                  gd  g u     . . attention to rare classes  in scene images  the class distribution is extremely imbalanced. namely  very few classes account for large percentage of pixels in images. an example is demonstrated  in figure  . it s therefore common to put more attention to  rare classes  in order to boost their recognition precisions.  in the patch based cnn training  farabet et al.     and  shuai et al.      oversample the rare class pixels to address  this issue. it s however inapplicable to adopt this strategy in  our network training  which is a complex structure learning  problem. meanwhile  as the classes are distributed severely  unequally in scene images  it s also problematic to weigh  classes according to their inverse frequencies. as an example  the frequency ratio between the most frequent  sky   and the most rare class  moon  on the siftflow dataset is   .        . if the above class weighting criterion is adopted  like in       the frequent classes will be under attended.  hence  we define the weighting function w as follows   wj   k dlog     fj  e    we justify our method on three popular and challenging real world scene image labeling benchmarks  siftflow        camvid     and barcelona     . two types of scores  are reported  the percentage of all correctly classified pixels   global   and average per class accuracy  class .           where d e is the integer ceiling operator  fj is the occurrence frequency of the class j    denotes the threshold that  discriminates the rare classes. specifically  a class is identified as rare if its frequency is smaller than    otherwise  it is    the convolution neural network  cnn   which jointly  learn features and classifiers is used as our first baseline. in  this case  the parameters are optimized to maximize the independent prediction accuracy for local patches. another  baseline is the network that shares the same architecture  with our dag rnns  while removes the recurrent connections. mathematically  the wd and bd in equation   are  fixed to   . in this case  the dag recurrent neural network  degenerates to an ensemble of four plain two layer neural  networks  cnn enn . the performance disparity between  the baselines and dag rnns clearly illuminates the efficacy of our dependency modeling method.     . . implementation details  we use the following two networks to be the convolution  layers in our experiments     cnn     the network consists of five convolutional  layers  the kernel sizes of which are                                                                          and            respectively. each of the first three  convolutional layers are followed by a relu and nonoverlapping       max pooling layer. the parameters  of this network is learned from image patches          of the target dataset only  setting   .    vgg conv   the network borrows its architecture  and parameters from vgg verydeep    net     . in  detail  we discard all the layers after the  th pooling  layer to yield the desired convolution layer. the network is pre trained on imagenet dataset and fine tuned  on the target dataset.      setting   .  in dag rnns  the adopted non linear functions  refer  to equation    are relu      for hidden neurons  f  x     max    x  and sof tmax for output layer g. in practice  we                                                                                                                                                                                         ucg          dag    gnw    ucg       methods  byeon et al.      liu et al.      farabet et al.      pinheiro et al.       tighe et al.      sharma et al.      shuai et al.      yang et al.      cnn     cnn    enn  cnn    dag rnn     cnn    dag rnn     long et al.      vgg conv  enn  vgg conv  dag rnn          dag    gnw    figure    two ucgs  with      neighborhood system  and their induced  dags in the northwestern  nw  direction.    apply the function g after the deconvolution layer. the dimensionality of hidden layer h is empirically set to    for  cnn    and     for vgg conv  respectively.   in our  experiments  we consider two ucgs with   and   neighborhood systems. their induced dags in the northwestern direction are shown in figure  . in comparison with  dag     dag    enables information to be propagated in  shorter paths  which is critical to prevent the long range information from vanishing. as exampled in figure    the     length of propagation path from v  to v  in gnw  is halved to     that in gnw        steps .  the full network is trained by stochastic gradient descent  with momentum. the parameters are updated after one image finishes its forward and backward passes. the learning  rate is initialized to be        and decays exponentially with  the rate of  .  after    epoch. the reported results are based  on the model trained in    epoches. we tune the parameters  and diagnoses the network performance based on cnn   .  we also include the results of vgg conv  to see whether  our proposed dag rnns are beneficial for the highly discriminative representation from the state of the art vggverydeep    net     .     . . siftflow dataset  the siftflow dataset has      images generally captured  from   typical outdoor scenes. every image has            pixels  which belong to one of the    semantic classes. we  adopt the training testing split protocol           images   provided by      to perform our experiments. following the          criterion  the class frequency threshold      .  .  statistically  out of    classes     of them are regarded as  infrequent class. the graphical visualization of the weights  for different classes are depicted in figure  .  the quantitative results are listed in table    within  which the upper part presents the performance of methods under setting  . our baseline cnn    achieves very  promising results  which proves the effectiveness of the  convolution layer. we also notice that results of cnn   fall behind cnn    enn on the average class accuracy. this phenomenon is also observed on the camvid and    based    on our preliminary results  we didn t observe too much performance improvement by using larger h  e.g.     in cnn     and     in  vgg conv   on the siftflow dataset. in addition  the networks with larger  capacity incur much heavier computation burdens.    global    .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      class    .    n a    .      .      .      .      .      .      .      .      .      .      .      .      .      table    quantitative performance of our method on the siftflow dataset.  the numbers  in brackets  following the dag rnn denote the neighborhood system of the ucg.    barcelona benchmarks  as shown by table   and   respectively. this result indicates that the proposed class weighting function significantly boosts the recognition accuracy  for rare classes. by adding dag rnn     our full network reaches   .      .    on the global  class  accuracy       which outperforms the baseline  cnn    enn  by        .   . meanwhile  we observe promising accuracy gain   global   .     class   .     by switching dag rnn     to  dag rnn      in which we believe that long range dependencies are better captured as information propagation paths  in dag    are shorter than those in dag   . such performance benefits can be observed consistently on the camvid    .      .    and barcelona   .      .    datasets  as evidenced in table   and   respectively. moreover  in comparison with other representation learning nets  which are fed  with much richer contextual input          patch in          scale       patches in       our dag rnns outperform  theirs by a large margin. importantly  our results match the  state of the art under this setting.  furthermore  we initialize our convolution layers with  vgg verydeep          which has been proven to be the  state of the art feature extractor. the quantitative results  under setting   are listed in the lower body of table  .  our baseline vgg conv  enn surpasses the best performance of methods under setting  . this result indicates  the significance of large scale data in deep neural network  training. interestingly  our dag rnn    is still able to  further improve the discriminative power of local features  by modeling their dependencies  thereby leading to a phenomenal   .    average class accuracy boost. note that  fully convolution networks  fcns       uses activations    if    we disassemble the full labeling network to two disjoint parts cnn    and dag rnn     and they are optimized independently  the  corresponding accuracies are   .   and   .  . the performance discrepancy indicates the importance of the joint optimization for the full network.     methods  tighe et al.      sturgess et al.      zhang et al.      bulo et al.     ladicky et al.      tighe et al.       cnn     cnn    enn  cnn    dag rnn     cnn    dag rnn     vgg conv  enn  vgg conv  dag rnn        global    .      .      .      .      .      .      .      .      .      .      .      .      class    .      .      .      .      .      .      .      .      .      .      .      .      table    quantitative performance of our method on the camvid dataset.     feature maps  from multiple convolution layers  whereas  our vgg conv  enn only use feature maps from conv   layer. hence  there is a slight performance gap between  our vgg conv  enn and fcns. nonetheless  our vggconv  dag rnn    still performs comparably with fcns  on global accuracy  and significantly outperforms it on the  class accuracy. importantly  our full labeling network also  achieves new state of the art performance under this setting. the detailed per class accuracy is listed in table  .     . . camvid dataset  the camvid dataset     contains     high resolution images            pixels  from   driving videos at daytime  and dusk    daytime and   dusk video sequence . images  are densely labelled with    semantic classes. we follow  the usual split protocol                    to obtain training testing images. similar to other works                  we only report results on the most common    categories.  according to the         rule    classes are identified as  rare  and   is  . .  the quantitative results are given in table  . our baseline networks  cnn     cnn    enn  achieve very competitive results. by explicitly modeling contextual dependencies among image units  our cnn    dag rnn     brings phenomenal performance benefit   .   and   .    for the global and class accuracy respectively . moreover   in comparison with state of the art methods                    our cnn    dag rnn    outperforms theirs by a  large margin   .      .     demonstrating the profitability of adopting high level features learned from cnn and  context modeling with our dag rnns. furthermore  the  vgg conv  enn alone performs excellently. even though  the performance starts saturating  our dag rnn    is able  to consistently improve the labeling results.     . . barcelona dataset  the barcelona dataset      consists of       training and      testing images. the size of the images varies across different instances  and each pixel is labelled as one of the        methods  tighe et al.      farabet et al.      farabet et al.      cnn     cnn    enn  cnn    dag rnn     cnn    dag rnn     vgg conv  enn  vgg conv  dag rnn       global    .      .      .      .      .      .      .      .      .      class   .      .     .      .      .      .      .      .      .      table    quantitative performance of our method on the barcelona dataset.    semantic classes. the training images range from indoor  to outdoor scenes  whereas the testing images are only captured from the barcelona street scene. these issues pose  barcelona as a very challenging dataset. based on the        rule      classes are identified as rare classes  and the  class frequency threshold   is  .   .  table   presents the quantitative results. from which   we clearly observe that our baseline networks  cnn    and  cnn    enn  achieve very competitive results  which has  already matched the state of the art results. the introduction of dag rnn    leads to promising performance improvement  therefore the full labeling network clinches the  new state of the art under setting  . more importantly  under setting    even though the vgg conv  enn is extraordinarily competitive  the dag rnn    is still able to enhance its labeling performance significantly.     . . effects of dag rnns to per class accuracy  in this section  we investigate the effects of our dagrnns for each class. the detailed per class accuracy for the  siftflow dataset is listed in table  . under setting    we find  that the contextual information encoded through our dagrnn    is beneficial for almost all classes. in this case  the  local representations from cnn    are not strong  so their  discriminative power can be greatly enhanced by modeling  their dependencies. in line with it  we observe remarkable  performance benefit     .    for almost all classes. under  setting    the vgg conv  net is pre trained on the imagenet  dataset      and it recognizes most classes excellently. even  though the local representations are highly discriminative in  this situation  our dag rnn    further tremendously improves their representative power for rare classes. statistically  we observe a phenomenal  .   accuracy gain for rare  classes. under both settings  modeling the dependencies  among local features enables the classification to be contextual aware. therefore  the local ambiguities are mitigated  to a large extent. however  we fail to observe commensurate accuracy improvements for extremely small size and  rare  object  classes  e.g. bird and bus   we conjecture that  the weak local information may have been overwhelmed by  context  e.g. a small bird is swallowed by the broad sky in  figure   .       .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .    .    .    .   .   .     .   .    .     .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .    .   .     .             vgg conv  enn    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vgg conv  dag rnn      .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .     class      .    .    .    .   .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .       cnn    enn  cnn    dag rnn       global    bird    sun    streetlight    bus    balcony    pole    boat    crosswalk    sign    awning    staircase    person    fence    door    bridge    rock    sidewalk    window    grass    plant    river    sand    car    field    sea    mountain    road    tree    building    sky  frequency               .     .   .    .        .   .     .               .    .     .    .         .               .    .     .    .       .     .      .    .       .     .     table    per class accuracy comparison on the siftflow dataset. all the numbers are displayed in the percentage scale. the statistics for class frequency is  obtained in test images. for reading convenience  the frequent and rare classes are placed in the same block.      .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .         .      .       desert    river    field    building    tree    sky    road    mountain    rock    sidewalk    plant    person unlabled    figure    qualitative labeling results  best viewed in color . we show input images  local prediction maps  cnn    enn   contextual labeling maps   cnn    dag rnn     and their ground truth respectively. the numbers outside and inside the parentheses are global and class accuracy respectively.     . . discussion of modeled dependency     . conclusion    we show a number of qualitative labeling results in figure  . by looking into them  we can have some interesting  observations. the dag rnns are capable of      enforcing  local consistency  neighborhood pixels are likely to be assigned to the same labels. in figure    the left panel examples show that confusing regions are smoothed by using our  dag rnns.      ensuring semantic coherence  the pixels  that are spatially far away are usually given labels that could  co occur in a meaningful scene. for example  the  desert   and  mountain  classes are usually not seen together with   trees  in a  open country  scene  so they are corrected to   stone  in the second example of the right panel. more examples of this kind are shown in the right panel. these results illuminate that short range and long range contextual  dependencies may have been captured by our dag rnns.    in this paper  we propose dag rnns to process dagsstructured data  where the interactions among local features  are considered in a graphical structure. our dag rnns  are capable of encoding the abstract gist of images into local representations  which tremendously enhance their discriminative power. furthermore  we propose a novel class  weighting function to address the imbalanced class distribution issue  and it is experimentally proved to be effective  towards the recognition enhancement for rare classes. integrating with the convolution and deconvolution layers  our  dag rnns achieve state of the art results on three challenging scene labeling benchmarks. we also demonstrate  that useful long range contextual dependencies are captured  by our dag rnns  which is helpful for generating smooth  and semantically sensible labeling maps in practice.     