introduction  the variety of sensors embedded in smartphones  wearables  and other iot devices are increasingly being used to  support both  a  fine grained monitoring of a user s activities  and ambient context  and  b  richer forms of cyber physical  interaction  e.g.  via gestures or natural language interfaces .  illustrative scenarios include the monitoring of a user s steps  to estimate daily calorie expenditure  tracking of eating gestures to capture food intake and use of microphone equipped  devices at home for voice based home automation control.  as these personal and edge devices increasingly come in  non traditional form factors  as well as learn and store  individual specific information  it is important to develop  novel and natural user authentication techniques. in recent  work  we have introduced the breathprint     system  which  utilizes acoustic features of a user s breathing  captured  by a commodity microphone  to support ubiquitous user  authentication on mobile and iot devices.  in this paper  we investigate whether rnn based  deep learning models can be effectively used in resourceconstrained devices for breathprint. the original work on  breathprint     was cloud based and used a conventional  gmm based machine learning model with manually curated  features. this work is motivated by two main objectives  a   state of the art speech recognition and speaker identifi          school of information systems  smu     cation methods are rnn based and significantly outperform classical methods such as svms and gmm hmms  especially in noisy environments      thus it is important  to evaluate the performance of breathprint using rnn  models to boost the performance  b  for unobtrusive and  ubiquitous authentication applications  breathprint needs  to be implemented in resource constrained devices and  must be able to authenticate users without cloud access   thus it is important to obtain an idea about the accuracy  vs. resource trade off for breathprint. to this end  in this  paper we conduct a performance evaluation of an end toend rnn based breathprint authentication system on three  representative hardware platforms  iot  raspberry pi      wearable  smartwatch  and mobile  smartphone . to the best  of our knowledge this is the first work  which shows the  feasibility  and performance of rnn based deep models for  acoustics in limited resource footprint devices.  we make the following key contributions      we present performance evaluation results of an endto end authentication based on lstm  a variant of  rnn  using breathing acoustics on three representative iot devices  a smartphone  a smartwatch  and  a raspberry pi.     we show that rnn based models for acoustic classification are smaller in size and lightweight than  previously reported results with cnn based models   and thus can be adopted to iot devices. specifically   an unoptimized rnn model is only  .  mb in size   for relevant breathing gestures  and can run on  smartphones and smartwatches with approx.        ms and     m latencies  respectively.     we also show how a layer quantization based model  compression technique can help to reduce the memory footprint of rnn models  by a factor of    to  approx         kb  without suffering any consequential drop in accuracy.     . related work  motivated by the breakthroughs in training deep neural  networks and the impressive performance gains achieved   deep networks have not only outperformed conventional  machine learning models  but in several cases  even human  experts   a variety of recent work has focused on the challenges  such as higher memory requirement or excessive     computational latency  of executing deep learning models on  resource constrained devices. table   summarizes some of  these notable efforts and the techniques employed. broadly  speaking  these efforts utilize one or more of the following  three approaches   i  offloading neural network processing to  gpus  which are more efficient in vectorized computations    ii  reducing the time and memory requirements to load  the fully connected layers  and  iii  faster execution of the  convolutional layers.  early work by lane et al.     investigated the performance characteristics  resource requirements and the execution bottlenecks for deep learning models  cnn and dnn   on mobile  wearable  and iot devices  to support audio and  vision based apps. results indicated that although smaller  deep learning models work without issues on these devices   more complex cnn models such as alexnet do not work  well under the resource constraints. to address this problem   bhattacharya et al.     proposed sparsesep  which focuses  primarily on finding a sparse representation of the fully  connected layers and on using separate filters to separate  the convolutional kernels. these techniques reduce the number of parameters and convolutional operations required to  execute a deep learning model  and can thus significantly  reduce the computational and space complexity on resourceconstrained devices.  several papers have focused on optimizing deep networks for audio and image sensing applications. deepear      is an audio sensing application for smartphones based on  dnns. deepear was implemented in the dsp of the smartphone  and imposed only    additional overhead in daily  energy consumption. deepeye     deployed cnns on wearables for continuous vision applications. deepeye avoids  resource bottlenecks by using interleaving to orchestrate  the execution of computation heavy convolutional layers  with memory heavy fully connected layers. deepeye also  employs caching to load the fully connected layers faster  and utilizes a singular value decomposition  svd  based  layer factorization approach to compress the fully connected  layer. deepmon     focused on reducing the processing  latency of convolutional layers  via multiple optimization  techniques  for continuous vision applications. first  deepmon employs a caching mechanism to take advantage of the  likely significant similarities between consecutive images.  secondly  deepmon perform faster matrix multiplication by  model decomposition and unfolding. model decomposition  decomposes a convolutional layer into multiple smaller convolutional layers such that that the total computation of the  decomposed layers is smaller than that of the original layer.  finally  deepmon offloads convolutional layers to mobile  gpus for faster processing. more recently  mobirnn      applied gpu offloading to execute rnns faster on smartphones  to support activity recognition tasks.  as evident from the table    most of the work to  date has focused on cnns and dnns. for example  even  audio analysis and speaker identification tasks have been  performed using cnn and dnns. in general  cnns are  good at exploiting features defined on spatial data  e.g.   images   whereas rnns are more appropriate for identifying    table    deep learning on resource constrained devices  name  sparsesep    type of dl  cnn  dnn    architecture  multiple  layers    deepear  deepeye    dnn  cnn    five layers  multiple  layers    application  image  classification   speaker  identification   scene  analysis  audio sensing  continuous  vision    deepmon    cnn    sixteen  layers    continuous  vision    mobirnn    rnn    two layers    activity  recognition    techniques  sparsification  and separation    na  interleaving   caching and  compression  gpu  offloading   caching and  decomposition  gpu offloading    and using temporal features  defined over data streams  such  as audio or text. compared to cnn  rnn based models  are also less complex as they deal with less complex data   images vs. text  audio  and do not use convolutional filters.  hence  compared to cnns  rnn based models require  comparatively lower computational power and memory          .  as discussed earlier  breathprint proposed a technique  to authenticate users based on their breathing acoustics  on mobile and iot devices. breathprint is based on the  hypothesis that each individual s breathing pattern is unique   the proposed approach is also highly usable  as it merely  requires the user to perform a small number of breathing  gestures. our interest in rnns is thus driven by our belief  that this uniqueness is manifested via temporal variations  in a user s breathing pattern  and that rnns are more  capable in identifying and exploiting such temporal features.  however  breathprint s full potential can only be realized  if the user identification can be performed locally  on the  device   with minimal latency. accordingly  in this work  we  investigate the central question   can breathprint be practically realized  using an rnn based model  on resourceconstrained devices       . experimental setup  to evaluate the feasibility of rnn driven breathingbased authentication  we utilize the breathing acoustics  dataset collected in our previous work    . the dataset  consists of acoustics samples of three breathing gestures   deep breathing  normal breathing  and sniffing  two quick  inhalations  of    users collected over three sessions. for  each gesture the dataset contains        and    samples  collected on first day  session     fourth day  session    and  seventh eighth day  session    respectively. in this paper   we focus only on two breathing gestures deep and sniff  as  our earlier investigations revealed that those two perform  better in authentication applications compared to normal  breathing. for further details on the dataset  please refer to  our original paper     that details the data collection process  and the dataset.  for each user  we selected the first    samples for model  training and tuning purpose. as deep learning requires larger     table    hardware configuration of the used devices  device  nexus      os  android  .     pixel    android  .     lg g watch r    android wear  .     raspberry pi      android things  .     cpu   .   ghz  quad core   .   ghz  quad core   .  ghz  quad core   .  ghz  quad core    gpu  adreno       adreno       adreno       videocore  iv    memory    gb    gb      mb    gb    sample sizes for training  we applied two commonly used  data augmentation techniques to increase the number of  data samples. in particular  we used a combination of the  frequency wrapping technique      and the amplitude scaling  method    . each sample was scaled    times along the time  axis and the amplitude by selecting two separate values from  a uniform distribution   u  .    .  . overall  we obtain  a    fold boost in the number of training examples       training samples per participant   consisting of both original  samples and their augmented versions. the remaining      original  samples each  from session   and session    were  kept intact for testing.  we performed experimental evaluation on using four  devices  belonging to three distinct types  listed in table  .  the three types of devices include two smartphones   mobile   a smartwatch  wearable  and a raspberry pi   iot . all the devices run different variant of android  based oses  and representative of popular commercial  mobile  wearable and embedded platforms.     . methodology  our overall goal is user authentication   i.e.  deciding  whether a sample belongs to one of n pre registered possible users. this is effectively a problem of closed set user  identification that can be mapped as a multi class classification problem  where a single class represents one user .  our approach is to do some pre processing of the original  acoustics signal so that it can be fed into an rnn model.  for a comparative baseline that uses a shallow classifier   we also train a svm model. we discuss the details of these  steps below.     . . feature extraction    if a larger window size is selected  some testing samples  may be missed from users with relatively short breathing  durations. to balance these considerations  we ended up  with window sizes              for sniff and             for deep breathing gestures  respectively. to further augment  the training dataset we created overlapping windows for a  given breathing sample. we chose three overlap sizes            and     of the window size. for each window size  and overlap value pair  we trained the classifiers as discussed  below.     . . training and testing datasets  we used the first    samples from session   and session   during the training phase. more specifically we created the windows from these samples and randomly shuffle  them and used     of the windows as the training set  and the rest of the     as the validation set to tune hyper  parameters. we refer to the windows created from the rest  of the    audio samples in session   as the intra set and  windows created from    audio samples from session   as  inter set.     . . rnn model  we used an rnn architecture that is similar to hammerla et al.       this architecture is illustrated in figure  .  the hidden unit size of the lstm units was     and we  used two lstm layers. we implement the model using  tensorflow     . we used    as batch size and trained the  network over     iterations. as a baseline classifier we also  trained a multi class svm classifier with linear kernel using  libsvm.  softmax  prediction  fc layers  lstm    lstm    lstm    lstm    lstm    lstm    lstm    lstm    fc layers       gfcc  features  window size    we divided each audio file into    ms non overlapping  frames with hamming window based smoothing. for each  frame we calculated    mfcc features     mfcc     delta  mfcc  and    double delta mfcc  using jstk  java  speech toolkit . then we used windowing to combine these  frames so that temporal information between the frames is  retained. for sniff and deep breathing gestures  we tried  window sizes of length                  and                       respectively. there are two factors to consider when  selecting a suitable window size. on the one hand  each  window must be large enough to retain a significant part of  a breathing gesture. on the other hand  the duration of a  single breath varies significantly across users  consequently     figure    rnn architecture     . . model selection  we used early termination to select the best model. this  was because we observed after some iterations the model  accuracy reaches to the maximum and stays approximately  in the same region for the validation set whilst the accuracy  in intra set and inter set shows a slight declining trend  as shown in figure  a. figure  b shows how the l  loss  improved over the training iterations.     l  loss  sniff  window size       overlap         .      .       .      .       .      .     .     .     .     .     .       validation set accuracy  intra set accuracy  inter set accuracy     .    .                                              .   validation set accuracy  intra set accuracy  inter set accuracy                  accuracy         .      accuracy         .     l  loss    accuracy    accuracy  sniff  window size       overlap         .       .           .          training epoch                   a  accuracy progress     .                           training epoch           nexus      pixel  rnn           smartwatch  rnn quant         pi    nexus      svm     a  accuracy   sniff     b  l  loss improvement    pixel  rnn    smartwatch  rnn quant    pi     b  accuracy   deep    figure    training progress of the rnn over iterations                         . results  we utilize four performance metrics for our experimental  evaluation   i  accuracy  the percentage of correct user identifications.  ii  feature extraction time  time taken to extract mfcc  features from an audio file.  iii  model loading time  time to load the machine learning model into the memory.  iv  inference time  time to predict the user label once  the feature extraction has been done and learning model is  loaded to memory.     . . performance of lstm  we report average values of the execution times for  different phases of the classification process. the feature    time  ms                                            nexus      pixel  rnn    smartwatch  rnn quant    pi    nexus      svm    pixel  rnn    smartwatch  rnn quant    pi     c  model loading time   sniff  d  model loading time   deep                       time  ms     time  ms     to approximately select the elbow point of the accuracy  graphs  we first applied    point moving averaging to the  validation set accuracy graph and then selected the point   elbow point  from which the accuracy does not improve by     for next four consecutive points. the moving average  window and the improvement threshold was decided empirically. once the elbow point is decided we selected    models   five previous models and the five next models including  the model at the elbow point . to present the performance  results in the next section we selected the models that gave  the highest average accuracy over all three datasets. the  window and overlap configurations that gave the highest  accuracy were   a  for sniffing  a window size     with      overlap  and  b  for deep breathing  a window size      also  with    . for svm  we picked the model providing the best  cross validation accuracy.  model reduction  to empirically study the computational overhead vs. latency accuracy tradeoffs  we compressed the selected rnn models using the in built       level quantization function      provided in tensorflow. this  function extracts the minimum and maximum for each layer   and then compresses each float value to an eight bit integer.  note that this option will save space in zipped formats that  are usually used inside android applications. we executed  the original as well as quantized models.    time  ms                                                nexus      pixel  rnn    smartwatch  rnn quant    pi  svm     e  inference time   sniff    nexus      pixel  rnn    smartwatch  rnn quant    pi     f  inference time   deep    figure    metrics for different breathing gestures    extraction time was in the range         ms for sniff  and  in the range           ms for deep  across the four devices.  as expected  the pixel  the most powerful platform with the  highest memory  and the smartwatch  impose the least and  highest feature extraction times  respectively. figure   plots  the results for other three metrics. note that the time scale  on y axis is in log scale. we can see that        model loading time decreases linearly with the ram  of the device. loading lstm model to pixel takes  around     ms    gb ram  while the same model  takes roughly twice the time      ms  on nexus       gb ram   four times      ms  on pi    gb ram   and seven times      ms  on smartwatch      mb  ram  for the sniff breathing gesture with lstm.  the same observation holds for the deep breathing  gesture.         inference time depends on the processing power of  the devices. the inference time  using the lstm  model  for sniff breathing gesture is on average     ms for nexus       ms for pixel  and around      ms for smartwatch and pi for lstm model.  in contrast  the inference time for deep breathing  gesture is approx.     ms for nexus        ms for     pixel      ms for pi and      ms for smartwatch.       the accuracy of the system was around     for both  deep and sniff breathing gesture for the intra set.  we also observe that the accuracy of lstm models  were slightly than svm. this indicates that the deep  learning model can perform at least as well as the  alternative svm approach  even though the volume  of training data was fairly small. note also  that the  accuracy of user identification drops to     and      for sniff and deep breathing gestures  respectively when applied to the inter set data  which was  excluded entirely from the training set. this result  is consistent with our prior results      and suggests  that a larger training corpus will be needed to a wider  range of context dependent variations in breathing  patterns.    only robust  but is also lightweight enough to be effectively  executed on a variety of resource constrained embedded devices. in particular  an appropriately quantized  lstm based  deep learning model can authenticate users  using just  deep   and  sniff  breathing gestures  with accuracies higher than       and utilizes models that are modestly sized  a couple  of hundred kb . the resulting user authentication latency is  not only small        ms  for representative smartphones   but is within acceptable bounds       second  even for  the highly resource limited smartwatch platform. note that  these performance numbers are achieved using cpu only  computation  and should be significantly improved using  gpu offloading approaches proposed by other researchers.  our investigations suggest that rnns offer a compelling  lightweight alternative to cnns for many sensor driven  pervasive applications  especially if the application utilizes  temporal features of the underlying sensor data.     . . benefit of quantized operation    