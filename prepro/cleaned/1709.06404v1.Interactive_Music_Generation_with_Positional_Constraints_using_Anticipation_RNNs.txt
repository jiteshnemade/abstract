introduction    recently  a number of powerful generative models on symbolic music have been proposed. if they now perform well  on a variety of different musical datasets  from monophonic folk music      to polyphonic bach chorales       these  models tend to face similar limitations  they do not provide musically interesting ways for a user to interact with them.  most of the time  only an input seed can be specified in order to condition the model upon  once the generation is  finished  the user can only accept the result or regenerate another musical content. we believe that this restriction  hinders creativity since the user do not play an active part in the music creation process.  generation in these generative models is often performed from left to right  recurrent neural networks  rnns       are generally used to estimate the probability of generating the next musical event  and generation is done by  iteratively sampling one musical event after another. this left to right modeling seems natural since music unfolds  through time and this holds both for monophonic         and polyphonic         music generation tasks. however   this does not match real compositional principles since composition is mostly done in an iterative and non sequential  way    . as a simple example  one may want to generate a melody that ends on a specific note  but generating such  melodies while staying in the learned style  the melodies are sampled with the correct probabilities  is in general a non  trivial problem when generation is performed from left to right. this problem has been solved when the generative  model is a markov model          but remains hard when considering arbitrary rnns.  in order to solve issues raised by the left to right sampling scheme  approaches based on mcmc methods have  been proposed  in the context of monophonic sequences with shallow models      or on polyphonic musical pieces  using deeper models        . if these mcmc methods allow to generate musically convincing sequences while enforcing many user defined constraints  the generation process is generally order of magnitudes longer than the simpler  left to right generation scheme. this can prevent for instance using these models in real time settings.        the problem of generating sequences while enforcing user defined constraints is rarely considered in the machine  learning literature but it is of crucial importance when devising interactive generative models. in this paper  we  propose a neural network architecture called anticipation rnn which is capable of generating in the style learned  from a database while enforcing user defined positional constraints. this architecture is very general and works with  any rnn implementation. furthermore  the generation process is fast as it only requires two function calls per musical  event. in sect.    we precisely state the problem we consider and sect.   describes the proposed architecture together  with an adapted training procedure. finally  we demonstrate experimentally the efficiency of our approach on the  dataset of the chorale melodies by j.s. bach in sect.  . in sect.    we discuss about the generality of our approach and  about future developments.         statement of the problem    we consider an i.i.d. dataset d     s    s    . . .   sn     an   of sequences of tokens st   a of arbitrary length n  over a vocabulary a. we are interested in probabilistic models over sequences p s  such that  y  p s     p st  s t          t    where s t    s    . . .   st     for t     and   if    . this means that the generative model p s  over sequences  is defined using the conditional probabilities p st  s t   only. generation with this generative model is performed  iteratively by sampling st from p st  s t   for t    ..n where n is arbitrary. due to their simplicity and their  efficiency  recurrent neural networks  rnns  are used to model the conditional probability distributions p st  s t     they allow to reuse the same neural network over the different time steps by introducing a hidden state vector in order  to summarize the previous observations we condition on. more precisely  by writing f the rnn  int its input  outt    its output and ht its hidden state at time t  we have  outt     ht     f  int   ht             for all time indices t. when int   st   the vector outt   is used to define p st    s t     for all time indices t without  the need to take as an input the entire sequence history s t   .  if this approach is successful on many applications  such a model can only be conditioned on the past which  prevents some possible creative use for these models  we can easily fix the beginning s t of a sequence and generate  a continuation s t    st   . . .   sn   but it becomes more intricate to fix the end s t of a sequence and ask the model to  generate a beginning sequence.  we now write punconstrained  s  the probability of a sequence s when no constraint is set. for simplicity of notation   we will suppose that we only generate sequences of fixed length n and denote by s    an the set of all sequences  over a. the aim of this paper is to be able to enforce a set of positional constraints  c     i  ci   i i             where i is the set of constrained time indexes and ci   a the value of the constrained note at time index i. ideally  we  want to sample constrained sequences  sconstrained  s   s       i  ci     c     si   ci           with the  correct  probabilities. this means that  if we denote by pconstrained  s  the probability of a sequence s in the  constrained model     pconstrained  s          pconstrained  s        s      sconstrained         punconstrained  s       s   s          with         p    s sconstrained    punconstrained  s .           to put it in words  the set of constraints c defines a subset sconstrained of s from which we want to sample from  using the probabilities  up to a normalization factor  given by punconstrained . however  sampling from sconstrained using                            figure    anticipation rnn architecture. the aim is to predict  s    . . .   sn   given  c    . . .   cn   and  s    . . .   sn     .  the acceptance rejection sampling method is not efficient due to the arbitrary number of constraints. exact sampling  from sconstrained is possible when the conditional probability distributions are modeled using models such as markov  models but is intractable in general. this problem in the case of markov models can in fact be exactly solved when  considering more complex constraints on the space of sequences such as imposing the equality or the difference  between two sequences symbols si and sj . generalizations of this problem to other types of constraints are discussed  in sect.  .         the model    the problem when trying to enforce a constraint c     i  ci   is that imposing such a constraint on time index i  twists   the conditional probability distributions p st  s t   for t   i. however  the direct computation of p st  s t   si   ci     using bayes rule when only p st  s t   is known  is computationally expensive.  the idea to overcome this issue is to introduce a neural network in order to summarize the set of constraints c. to  this end  we introduce an additional token nc  no constraint  to a indicating that no positional constraint is set at a  given position. by doing this  we can rewrite the set c as a sequence c    c    . . .   cn   where ci   a    nc . we  then introduce a rnn called constraint rnn in order to summarize the sequence of all constraints. this rnn goes  backward  from cn to c    and all its outputs are used to condition a second rnn called token rnn.  this architecture  called anticipation rnn since the token rnn is conditioned on what may come next  is depicted in fig.  . we notated by  o    . . .   on   the output sequence of the constraint rnn  for notational simplicity  we  reversed the sequence numbering  the first output of the constraint rnn is on in our notation . the aim of the output  vector ot is to summarize all information about constraints from time t up to the end of the sequence. this vector is  then concatenated to the input st   of the token rnn at time index t whose aim is to predict st .  our approach differs from the approaches using markov models in the sense that we directly take into our conditional probability distributions rather than trying to sample sequences in sconstrained using punconstrained   we want our  probabilistic model to be able to directly enforce hard constraints.  the anticipation rnn thus takes as an input both a sequence of tokens  s    . . .   sn      and a sequence of constraints  c    . . .   cn   and has to predict the shifted sequence  s    . . .   sn  . the only requirement here is that the  constraints have to be coherent with the sequence  ci   si if ci    nc. since we want our model to be able to deal with  any positional constraints  we consider the dataset of couples of token sequences and constraint sequences dconstraint  such that     dconstraint     s  m s      s   d   m         n                 d     e     a           g     f      e            figure    melodico rhythmic encoding of the first bar of the melody of fig.  a.     a      b      c     figure    examples of generated sequences in the style of the soprano parts of the j.s. bach chorales. all examples  are subject to the same set of positional constraints indicated using green notes.  where       n is the set of all binary masks  the sequence of constraints m s  is then defined as the sequence   c    . . .   cn   where ci   si if mi     and ci   nc otherwise.  the sampling procedure is fast since it only needs two rnn passes on the sequence.         experimental results    we evaluated our architecture on the dataset of the melodies from the four part chorale harmonizations by j.s. bach.  this dataset is available in the music   python package     and we extracted the soprano parts from all     chorales.  in order to encode these monophonic sequences  we used the melodico rhythmic encoding described in    . the advantage with this encoding is that it allows to encode a monophonic musical sequence using only one sequence of  tokens. this consists in adding an additional token     which indicates that the current note is held. furthermore   we do not use the traditional midi pitch encoding but used the real note names  among other benefits  this allows to  generate music sheets which are immediately readable and understandable by a musician and with no spelling mistakes. time is quantized using a sixteenth note as the smallest subdivision  each beat is divided into four equal parts .  an example of an encoded melody using this encoding is displayed in fig.  . we also perform data augmentation by  transposing all sequences in all possible keys as long as the transposed sequence lies within the original voice range.  we used a   layer stacked lstm      for both the constraint rnn and the token rnn using the pytorch      deep learning framework and added a     dropout on the input of the token rnn. sequences are padded with start  and end symbols.  fig.   shows examples of the enforcement and the propagation of the constraints  even if generation is done from  left to right  the model is able to generate compelling musical phrases while enforcing the constraints. in particular   we see that the model is able to  anticipate  the moment when it has to  go  from a low pitched note to a high pitched  one and vice versa. the use of the melodico rhythmic encoding allows to only impose that a note should be played at  a given time  without specifying its rhythm. it is interesting to note that such a wide melodic contour  going from a  d  to a d  and then going back to a d  in only two bars  is unusual for a chorale melody. nonetheless  the proposed  model is able to generate a convincing bach like chorale melody.  we now check how the constraints propagate backwards in time and how the constrained model deviates from  the unconstrained model. for this  we compare the constrained model pconstrained on the same set of constraints as in  fig.   with its unconstrained counterpart punconstrained . the latter is obtained by conditioning the model of fig.   on        beat index   a  constrained case  p   pconstrained    beat index   b  unconstrained case  p   punconstrained    figure    plot of p st  s t   as a function of t during the generation of the melody displayed in fig.  a in the constrained  and unconstrained cases.          beat index    figure    difference between pconstrained  st  s t   and punconstrained  st  s t   as a function of t during the generation of the  melody displayed in fig.  a.  a sequence of constraints in the special case where no constraint is set  the sequence of constraints is  nc  . . .   nc .  figure   shows the evolution of pconstrained  st  s t   and punconstrained  st  s t   during the generation of the example in  fig.  a. it is interesting to note that the conditional probability distributions returned by pconstrained  st  s t   are more  concentrated on specific values than the ones returned by punconstrained  st  s t  . the concentration of the all probability  mass of pconstrained  st  s t   on constrained notes confirms  on this specific example  that the proposed architecture has  learned to enforce hard positional constraints. this assertion is experimentally verified on all constrained sequences  we generated.  we also display in fig.   the difference between the two distributions of fig.   for each time step. this highlights  the fact that the probability mass distribution of pconstrained is  shifted upwards  when the next positional constraint is  higher than the current note  and  downwards  in the opposite case.  we can quantify how the probability distributions pconstrained  st  s t   differ from punconstrained  st  s t   by computing  how dissimilar they are. in fig.   we plot the evolution of the square root of their divergence       d pconstrained  st  s t    punconstrained  st  s t              for different divergences. the divergences      we considered are        p    the kullback leibler divergence dkl  p  q    i pi log pqii      the reversed kullback leibler divergence dreversed kl  p  q    dkl  q  p      the jeffreys divergence djeffreys  p  q    dkl  p  q    dkl  q  p      the  symmetric  jensen shannon divergence djs  p  q       dkl  p  m       dkl  q  m   where m      p q    .    this plot indicates how the constraints are propagated backwards in time. the oscillation between high values of the  divergences and the zero value is due to the encoding we chose as well as to the singularity of the musical data we        kl    reversed kl    je reys    jensen shannon    beat index    figure    square root of the divergence d punconstrained  st  si t    pconstrained  st  si t    for the kullback leibler  reversed  kullback leibler  jeffreys and jensen shannon divergences during the left to right generation of the example shown  in fig.  a. the highest peaks correspond to the user defined constraints  particularly clear when using the reversed  kullback leibler divergence  while the smaller ones demonstrate how the constraints tweaked the probability distributions in comparison with the unconstrained model.    figure    point plot of pconstrained  s   y axis  versus punconstrained  s   x axis  on a set of       generated  using  pconstrained   sequences of length       bars . the set of constraints is the one used in for the generations in fig.  .  a logarithmic scale is used. the identity map is displayed in blue and the linear regression of the data points in green.  the lines are closed to being parallel indicating the proportionality between the two distributions  as desired.          considered. as can be seen in fig.    the     symbol concentrates most of the probability mass one time out of two  since the soprano parts in bach chorales are mostly composed of half notes  quarter notes and eighth notes. this  is independent of the presence or absence of constraints so the constrained and unconstrained models make similar  predictions on these time steps.  we now evaluate that the sampling using pconstrained fulfills the requirements     and    . for a given set of constraints c  we generated       sequences and verified that the requirement     is fulfilled for all of these sequences   all constraints are enforced . in order to check the fulfillment of the requirement      we plot for each sequence s its  probability in the constrained model pconstrained  s   defined as in eq.      as a function of punconstrained  s  in logarithmic  space. the resulting plot is shown in fig.  . the translation in logarithmic space indicates the proportionality between  the two distributions as desired.         conclusion    we presented the anticipation rnn  a simple but efficient way to generate sequences in a learned style while enforcing  positional constraints. this method is general and can be used to improve many existing rnn based generative  models. contrary to other approaches  we teach the model to learn to enforce hard constraints at training time. we  believe that this approach is a first step towards the generation of musical sequences subjected to more complex  constraints.  the constrained generation procedure is fast since it requires only  n rnn calls  where n is the length of the  generated sequence  as it does not require extensive computational resources and provides an interesting user machine  interaction  we think that this architecture paves the way to the development of creative real time composition software.  we also think that this fast sampling could be used jointly with mcmc methods in order to provide fast initializations.  future work will aim at studying how to improve the training of the model by carefully choosing the amount of  masked notes  similarly to what is addressed in       handling other types of constraints  imposing the rhythm of the  sequences  enforcing the equality between two notes or introducing soft constraints  and developing responsive user  interfaces so that the possibilities offered by this architecture can be used by a wide audience.    