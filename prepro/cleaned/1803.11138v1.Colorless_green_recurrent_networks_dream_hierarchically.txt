introduction    recurrent neural networks  rnns  elman         are general sequence processing devices that do  not explicitly encode the hierarchical structure  that is thought to be essential to natural language   everaert et al.       . early work using artificial languages showed that they may nevertheless be able to approximate context free languages  elman       . more recently  rnns have     the work was conducted during the internship at facebook ai research  paris.    achieved impressive results in large scale tasks  such as language modeling for speech recognition  and machine translation  and are by now standard  tools for sequential natural language tasks  e.g.   mikolov et al.        graves        wu et al.        . this suggests that rnns may learn to track  grammatical structure even when trained on noisier natural data. the conjecture is supported by the  success of rnns as feature extractors for syntactic parsing  e.g.  cross and huang        kiperwasser and goldberg        zhang et al.       .  linzen et al.        directly evaluated the extent to which rnns can approximate hierarchical structure in corpus extracted natural language  data. they tested whether rnns can learn to  predict english subject verb agreement  a task  thought to require hierarchical structure in the general case   the girl  are   .  girl the boys like. . . is  is or are  are  their experiments confirmed that rnns can  in  principle  handle such constructions. however  in  their study rnns could only succeed when provided with explicit supervision on the target task.  linzen and colleagues argued that the unsupervised language modeling objective is not sufficient  for rnns to induce the syntactic knowledge necessary to cope with long distance agreement.  the current paper reevaluates these conclusions. we strengthen the evaluation paradigm of  linzen and colleagues in several ways. most importantly  their analysis did not rule out the possibility that rnns might be relying on semantic or collocational frequency based information   rather than purely on syntactic structure. in  dogs  dogs  bark an rnn might  in the neighbourhood often bark  bark    get the right agreement by encoding information     about what typically barks  dogs  not neighbourhoods   without relying on more abstract structural  cues. in a follow up study to linzen and colleagues   bernardy and lappin        observed  that rnns are better at long distance agreement  when they construct rich lexical representations of  words  which suggests effects of this sort might  indeed be at play.  we introduce a method to probe the syntactic  abilities of rnns that abstracts away from potential lexical  semantic and frequency based confounds. inspired by chomsky s        insight that   grammaticalness cannot be identified with meaningfulness   p.       we test long distance agreement both in standard corpus extracted examples  and in comparable nonce sentences that are grammatical but completely meaningless  e.g.   paraideas i  phrasing chomsky    the colorless green ideas  ate with the chair sleep  sleep furiously .  we extend the previous work in three additional ways. first  alongside english  which has  few morphological cues to agreement  we examine  italian  hebrew and russian  which have richer  morphological systems. second  we go beyond  subject verb agreement and develop an automated  method to harvest a variety of long distance number agreement constructions from treebanks. finally  for italian  we collect human judgments for  the tested sentences  providing an important comparison point for rnn performance.   we focus on the more interesting unsupervised  setup  where rnns are trained to perform generic   large scale language modeling  lm   they are not  given explicit evidence  at training time  that they  must focus on long distance agreement  but they  are rather required to track a multitude of cues that  might help with word prediction in general.  our results are encouraging. rnns trained  with a lm objective solve the long distance agreement problem well  even on nonce sentences. the  pattern is consistent across languages  and  crucially  not far from human performance in italian. moreover  rnn performance on language  modeling  measured in terms of perplexity  is a  good predictor of long distance agreement accuracy. this suggests that the ability to capture  structural generalizations is an important aspect of  what makes the best rnn architectures so good     the code to reproduce our experiments and the data  used for training and evaluation  including the human judgments in italian  can be found at https   github.com   facebookresearch colorlessgreenrnns.    at language modeling. since our positive results  contradict  to some extent  those of linzen et al.          we also replicate their relevant experiment using our best rnn  an lstm . we outperform their models  suggesting that a careful architecture hyperparameter search is crucial to obtain  rnns that are not only good at language modeling  but able to extract syntactic generalizations.         constructing a long distance  agreement benchmark    overview. we construct our number agreement  test sets as follows. original sentences are automatically extracted from a dependency treebank.  they are then converted into nonce sentences by  substituting all content words with random words  with the same morphology  resulting in grammatical but nonsensical sequences. an lm is evaluated on its predictions for the target  second  word  in the dependency  in both the original and nonce  sentences.  long distance  agreement  constructions.  agreement relations  such as subject verb agreement in english  are an ideal test bed for the  syntactic abilities of lms  because the form of  the second item  the target  is predictable from  the first item  the cue . crucially  the cue and  the target are linked by a structural relation   where linear order in the word sequence does  not matter  everaert et al.       . consider the  following subject verb agreement examples   the  thinks.  thinks.  girl  girl thinks  thinks . .     the girl  girl  you met  thinks  thinks . .     the  girl  thinks.  girl  you met yesterday  thinks  thinks . .     the girl  girl  you  thinks  met yesterday through her friends  thinks.  thinks . .  .  in all these cases  the number of the main verb   thinks  is determined by its subject   girl    and  this relation depends on the syntactic structure of  the sentence  not on the linear sequence of words.  as the last sentence shows  the word directly  preceding the verb can even be a noun with the  opposite number   friends    but this does not  influence the structurally determined form of the  verb.  when the cue and the target are adjacent   the  girl  thinks.  girl thinks  thinks . .     an lm can predict the target without access to syntactic structure  it can simply  extract the relevant morphosyntactic features of  words  e.g.  number  and record the co occurrence  frequencies of patterns such as np lur vp lur   mikolov et al.       . thus  we focus here on  long distance agreement  where an arbitrary num       a      b     nsubj    amod  nmod    advmod    acl    adj  noun    the    girl    the boys    cue    verb    adv    like    often    context    verb    goes    most    target     c     noun    noun                                          deep    at that    moment    sign    context    target    cue  conj    obj    verb    cc    noun    prometteva interessi del     al mese sui soldi versati nella sua piramide  promised    interests    of     by month on the money put in his pyramid    cue    context    cconj    verb    e    continuava    and    continued  target    figure    example agreement constructions defined by a dependency and the separating context  in  a  en     glish   b  russian and  c  italian.  ber of words can occur between the elements of  the agreement relation. we limit ourselves to number agreement  plural or singular   as it is the only  overt agreement feature shared by all of the languages we study.  identifying candidate constructions. we  started by collecting pairs of part of speech   pos  tags connected by a dependency arc.  independently of which element is the head of the  relation  we refer to the first item as the cue and  to the second as the target. we additionally refer  to the pos sequence characterizing the entire  pattern as a construction  and to the elements in  the middle as context.  for each candidate construction  we collected  all of the contexts in the corpus that intervene between the cue and the target  we define contexts as  the sequence of pos tags of the top level nodes  in the dependency subtrees . for example  for  the english subject verb agreement construction  shown in fig.  a  the context is defined by verb   head of the relative clause  and adv  adverbial  modifier of the target verb   which together dominate the sequence  the boys like often . for the  russian adjective noun agreement construction in  fig.  b  the context is noun  because in the dependency grammar we use the noun  moment  is  the head of the prepositional phrase  at that moment   which modifies the adjective  deep . the  candidate agreement pair and the context form a  construction  which is characterized by a sequence  of pos tags  e.g.  noun verb adv verb or  verb noun cconj verb  fig.  c .    our constructions do not necessarily correspond  to standard syntactic structures. the english  subject verb agreement construction noun verb  verb   for example  matches both object and subject relative clause contexts  e.g.   girl  girl the boys  is  is  girls  girls  were  like is  and    who stayed at home were  were .  conversely  standard syntactic structures might be  split between different constructions  e.g.  relative clause contexts occur in both noun verb  verb and noun verb adv verb constructions   the latter is illustrated by the english example in  fig.  a .  construction contexts can contain a variable  numbers of words. since we are interested in challenging cases  we only considered cases in which  at least three tokens intervened between the cue  and the target.  excluding non agreement constructions. in  the next step  we excluded constructions in which  the candidate cue and target did not agree in number in all of the instances of the construction in  the treebank  if both the cue and the target were  morphologically annotated for number . this step  retained english subject verb constructions  for  example  but excluded verb object constructions   since any form of a verb can appear both with singular and plural objects. to focus on robust agreement patterns  we only kept constructions with  at least    instances of both plural and singular  agreement.  when applied to the treebanks we used  see  section     this step resulted in between two  english  and     russian  constructions per lan      guage. english has the poorest morphology and  consequently the lowest number of patterns with  identifiable morphological agreement. only the  vp conjunction construction  fig.  c  was identified in all four languages. subject verb agreement  constructions were extracted in all languages but  russian  russian has relatively flexible word order  and a noun dependent preceding a head verb is not  necessarily its subject. the full list of extracted  constructions in english and italian is given in tables   and    respectively. for the other languages   see the supplementary material  sm .   original sentence test set. our  original  sentence test set included all sentences from each construction where all words from the cue and up to  and including the target occurred in the lm vocabulary  section     and where the singular plural  counterpart of the target occurred in the treebank  and in the language model vocabulary  this is required by the evaluation procedure outlined below . the total counts of constructions and original sentences in our test sets are provided in table  . the average number of context words separating the cue and the target ranged from  .   hebrew  to  .   italian .     e.g.   it stays the shuttle  in   b  .  evaluation procedure. for each sentence in our  test set  we retrieved from our treebank the form  that is identical to the agreement target in all morphological features except number  e.g.   finds   instead of  find  in   b  . given a sentence with  prefix p up to and excluding the target  we then  compute the probabilities p  t   p  and p  t   p  for  the singular and plural variants of the target  t   and t    based on the language model. following linzen et al.         we say that the model  identified the correct target if it assigned a higher  probability to the form with the correct number.  in   b   for example  the model should assign a  higher probability to  finds  than  find .          experimental setup    treebanks. we extracted our test sets from the  italian  english  hebrew and russian universal  dependency treebanks  ud  v .   nivre et al.        . the english and hebrew treebanks were  post processed to obtain a richer morphological  annotation at the word level  see sm for details .    generating nonce sentences. we generated  nine nonce variants of each original sentence as  follows. each content word  noun  verb  adjective  proper noun  numeral  adverb  in the sentence  was substituted by another random content word  from the treebank with matching pos and morphological features. to avoid forms that are ambiguous between several pos  which are particularly frequent in english  e.g.  plural noun and singular verb forms   we excluded the forms that appeared with a different pos more than     of the  time in the treebank. function words  determiners  pronouns  adpositions  particles  and punctuation were left intact. for example  we generated  the nonce   b  from the original sentence   a      lm training data. training data for italian  english and russian were extracted from the respective wikipedias. we downloaded recent dumps   extracted the raw text from them using wikiextractor  and tokenized it with treetagger  schmid        . we also used the treetagger lemma annotation to filter out sentences with more than     unknown words. for hebrew  we used the preprocessed wikipedia corpus made available by yoav  goldberg.  we extracted   m token subsets for  each language  shuffled them by sentence and split  them into training and validation sets    to   proportion . for lm training  we included the   k  most frequent words in each corpus in the vocabulary  replacing the other tokens with the unk  symbol. the validation set perplexity values we  report below exclude unknown tokens.    presents the case for marriage  it presents  equality and states  states.  states . .  it stays  stays the shuttle for honesty insurfinds . .  ance and finds  finds.    rnn language models. we experimented with  simple rnns  srnns  elman         and their  most successful variant  long short term memory models  lstms  hochreiter and schmidhu     note that our generation procedure is based on  morphological features and does not guarantee  that argument structure constraints are respected       obviously  in the nonce cases  the lms never assigned  the highest overall probability to either of the two candidates.  qualitatively  in such cases lms assigned the largest absolute  probabilities to plausible frequent words.     https   github.com attardi   wikiextractor     http   u.cs.biu.ac.il  yogo hebwiki            a.  b.       the sm is available as a standalone file on the project s  public repository.     ber       . we use the pytorch rnn implementation.  we trained the models with two hidden  layer dimensionalities      and     units   and a  range of batch sizes  learning rates and dropout  rates. see sm for details on hyperparameter tuning. in general  a larger hidden layer size was the  best predictor of lower perplexity. given that our  lstms outperformed our srnns  our discussion  of the results will focus on the former  we will use  the terms lstm and rnn interchangeably.     it    human experiment in italian. we presented  the full italian test set      original and       nonce sentences  to human subjects through the  amazon mechanical turk interface.  we picked  italian because  being morphologically richer  it  features more varied long distance constructions  than english. subjects were requested to be native  italian speakers. they were presented with a sentence up to and excluding the target. the singular  and plural forms of the target were presented below the sentence  in random order   and subjects  were asked to select the more plausible form.  to prevent long distance agreement patterns  from being too salient  we mixed the test set with  the same number of filler sentences. we started  from original fillers  which were random treebankextracted sentences up to a content word in singular or plural form. we then generated nonce fillers  from the original ones using the procedure outlined in section  . a control subset of     fillers  was manually selected by a linguistically trained       https   github.com pytorch examples   tree master word language model     detailed results for srnns can be found in the sm.     https   www.mturk.com     he    ru     constructions   original                                             unigram  original  nonce      .     .       .     .       .     .       .     .       gram kn  original  nonce      .     .       .     .       .     .       .     .     perplexity    baselines. we consider three baselines  first  a  unigram baseline  which picks the most frequent  form in the training corpus out of the two candidate target forms  singular or plural   second  a    gram model with kneser ney smoothing  kn   kneser and ney        trained using the irstlm  package  federico et al.        and queried using kenlm  heafield         and third  a   gram  lstm  which only had access to windows of five  tokens  chelba et al.       . compared to kn   the   gram lstm can generalize to unseen ngrams thanks to its embedding layer and recurrent  connections. however  it cannot discover longdistance dependency patterns that span more than  five words. see sm for details on the hyperparameters of this baseline.    en      gram lstm  original  nonce  perplexity  lstm  original  nonce  perplexity       .     .     .     .     .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .       .     table    experimental results for all languages av     eraged across the five best models in terms of perplexity on the validation set. original nonce rows  report percentage accuracy  and the numbers in  small print represent standard deviation within the  five best models.  italian native speaker as unambiguous cases. to  make sure we were only using data from native  or  at least highly proficient  italian speakers  we filtered out the responses of subjects who chose the  wrong target in more than     of the fillers.  we collected on average  .  judgments for each  item  minimum   judgments . to account for the  variable number of judgments across sentences   accuracy rates were first calculated within each  sentence and then averaged across sentences.         results    the overall results are reported in table  . we report results averaged across the five models with  the lowest validation perplexity  as well as standard deviations across these models. in summary      italian  english  hebrew  russian    original  nonce  original  nonce  original  nonce  original  nonce    nvv    v np conj v      .   .     .   .     .   .     .   .     .   .     .   .          .    .     .   .     .   .     .   .     .   .     .   .     .   .     .   .     table       lstm accuracy in the constructions  n v v  subject verb agreement with an intervening embedded clause  and v np conj v  agreement between conjoined verbs separated by a  complement of the first verb .  the lstm clearly outperformed the other lms.  rather surprisingly  its performance on nonce sentences was only moderately lower than on original  ones  in italian this gap was only  .  .  the kn lm performed poorly  its accuracy on  nonce sentences was comparable to that of the unigram baseline. this confirms that the number of  the target in nonce sentences cannot be captured  by shallow n gram patterns. the   gram lstm  model greatly improved over the kn baseline  its  accuracy dropped only modestly between the original and nonce sentences  demonstrating its syntactic generalization ability. still  the results are  substantially below those of the lstm with unlimited history. this confirms that our test set  contains hard long distance agreement dependencies  and  more importantly  that the more general  lstm model can exploit broader contexts to learn  about and track long distance syntactic relations.  the increase in accuracy scores across the three  lms  kn    gram lstm and unbounded context  lstm  correlates well with their validation perplexities in the language modeling task. we also  found a strong correlation between agreement accuracy and validation perplexity across all the  lstm variants we explored in the hyperparameter search     models per language   with pearson  correlation coefficients ranging from r     .    in hebrew to r     .   in english  p    .    in  all languages . this suggests that acquiring abstract syntactic competence is a natural component of the skills that improve the generic language  modeling performance of rnns.    differences across languages. english was by  far the hardest language. we conjecture that this is  due to its poorer morphology and higher pos ambiguity  which might not encourage a generic language model to track abstract syntactic configurations. there is an alternative hypothesis  however.  we only extracted two constructions for english   both of which can be argued to be linguistically  complex  subject verb agreement with an intervening embedded clause  and agreement between  two conjoined verbs with a nominal complement  intervening between the verbs. yet the results on  these two constructions  comparable across languages  with the exception of the subject verb  construction in russian  which was not extracted    confirm that english is particularly hard  table   .  a qualitative inspection suggests that the low accuracy in the verb conjunction case    .    is due  to ambiguous sentences such as  if you have  have any  need   needs    questions or need  need needs  needs where the target can be  re interpreted as a noun that is acceptable in the  relevant context.   in languages such as italian and russian  which  have richer morphology and less ambiguity at  the part of speech level than english  the lstms  show much better accuracy and a smaller gap between original and nonce sentences. these results are in line with human experimental studies  that found that richer morphology correlates with  fewer agreement attraction errors  lorimor et al.        . the pattern of accuracy rates in general   and the accuracy for the shared v np conj v construction in particular  are consistent with the finding that russian is less prone to human attraction  errors than italian  which  in turn  shows less errors than english.  the largest drop in accuracy between original  and nonce sentences occurred in hebrew. a qualitative analysis of the data in this language suggests  that this might be due to the numerical prevalence  of a few constructions that can have multiple alternative readings  some of which can license the incorrect number. we leave a more systematic analysis of this finding for future research.  human results. to put our results in context  and provide a reasonable upper bound on the lm  performance  in particular for nonce sentences  we  next compare model performance to that of human     the nonce condition has higher accuracy because our  substitution procedure in english tends to reduce pos ambiguity.     construction   adjp  noun   relc   partp  clitic verb  noun  relc   partp   verb  adj  conjoined adj s  adj  noun  adjp  relpron verb  noun  pp  adverb adj  noun  pp  verb  participial   verb  np  conj verb    det    noun     original    original  subjects  lstm                                      micro  average    nonce  subjects  lstm      .     .     .     .     .     .     .     .       .   .        .     .   .        .     .   .     .   .     .   .     .    .       .     .     .     .     .     .     .     .       .   .     .   .     .   .     .   .     .   .     .   .     .   .     .   .       .       .   .       .       .   .     table    subject and lstm accuracy on the italian test set  by construction and averaged.    subjects in italian.  table   reports the accuracy of the lstms and  the human subjects  grouped by construction.    there was a consistent gap in human accuracy between original and nonce sentences   .   on average . the gap in accuracy between the human  subjects and the model was quite small  and was  similar for original and nonce sentences   .   and   .    respectively .  in some of the harder constructions  particularly  subject verb agreement with an embedded clause   the accuracy of the lstms on nonce sentences  was comparable to human accuracy    .   .   vs.   .   . to test whether the human subjects  and the models struggle with the same sentences   we computed for each sentence     the number of  times the human subjects selected the correct form  of the target minus the number of times they selected the incorrect form  and     the difference in  model log probability between the correct and incorrect form. the spearman correlation between  these quantities was significant  for both original   p    .    and nonce sentences  p    .    . this  indicates that humans were more likely to select  the correct form in sentences in which the models  were more confident in a correct prediction.  moreover  some of the easiest and hardest constructions are the same for the human subjects and  the models. in the easy constructions det  adjp         the sm contains the results for the other languages broken down by construction. note that table   reports linguistically intuitive construction labels. the corresponding  pos patterns are  in same order as table rows   det adj  noun   noun verb pron verb   noun verb verb   adj  adj cconj adj   noun adj punct pron verb   noun  noun adv adj   noun noun verb   verb noun cconj  verb .    noun       and adj  conjoined adjs  adj  one or  more adjectives that intervene between the cue and  the target agree in number with the target  providing shorter distance evidence about its correct  number. for example  in         un film inutile  inutile ma almeno festivo  festivo e  a movie useless but at.least festive and  giovanile  giovanile  youthful     a useless but at least festive and youthful  movie   the adjective  festivo  is marked for singular number  offering a nearer reference for the target number than the cue  inutile . at the other end  noun   pp  verb  participial  and noun  pp  adverb  adj are difficult. particularly in the nonce condition  where semantics is unhelpful or even misleading  the target could easily be interpreted as a  modifier of the noun embedded in the preceding  prepositional phrase. for example  for the nonce  case          orto  di regolamenti  orto  regolamenti davvero pedonale i  pedonale i  orchard of rules  truly  pedestrian     truly pedestrian orchard of rules   both the subjects and the model preferred to treat   pedestrian  as a modifier of  rules    orchard  of truly pedestrian rules    resulting in the wrong  agreement given the intended syntactic structure.  attractors. we define attractors as words with  the same pos as the cue but the opposite number  which intervene in the linear order of the sen      the relatively low nonce lstm performance on this  construction is due to a few adjectives that could be reinterpreted as nouns.     human subjects  original                                                 .    .    .       .    .             .    .     .       .       .    .    .     accuracy      accuracy                    lstm  nonce                 models  linzen s google lm  linzen s supervised  our lstm lm                                                                               number of attractors                                       number of attractors         figure    accuracy by number of attractors in ital     figure    linzen s attractor set. our lm trained    ian. human performance is shown in red and  lstm in blue  median model among top   ranked  by perplexity . error bars show standard error.    lstm  blue   median  model  compared to their  lstm with explicit number supervision  green   and their best lm trained lstm  red .    tence between the cue and the target. attractors  constitute an obvious challenge for agreement processing  bock and miller       . we show how  their presence affects human and model behavior  in fig.  . we limit our analysis to a maximum  of two attractors  since there were only two original sentences in the test corpus with three attractors or more. both model and human accuracies  degraded with the number of attractors  the drop  in accuracy was sharper in the nonce condition.  while the model performed somewhat worse than  humans  the overall pattern was comparable.  our results suggest that the lstm is quite robust to the presence of attractors  in contrast to  what was reported by linzen et al.       . we directly compared our english lstm lm to theirs  by predicting verb number on the linzen et al.         test set. we extracted sentences where all  of the words between subject and verb were in our  lm vocabulary. out of those sentences  we sampled      sentences with      and   attractors and  kept all the sentences with   and   attractors        and     sentences  respectively . to ensure that  our training set and linzen s test set do not overlap  both are based on wikipedia texts   we filtered  out all of test sentences that appeared in our training data      sentences .  fig.   compares our results to the results of  the best lm trained model in linzen et al.          their  google lm  .   not only did our lm  greatly outperform theirs  but it approached the  performance of their supervised model.   this    difference in results points to the importance of  careful tuning of lm trained lstms  although we  must leave to a further study a more detailed understanding of which differences crucially determine our better performance.        these subject verb agreement results are in general  higher than for our own subject verb agreement construction   noun verb verb  because the latter always includes an  embedded clause  and it is therefore harder on average.      similarly high performance of lm trained rnns on         related work    early work showed that rnns can  to a certain degree  handle data generated by context free  and even context sensitive grammars  e.g.  elman               rohde and plaut        christiansen  and chater        gers and schmidhuber         cartling       . these experiments were based on  small and controlled artificial languages  in which  complex hierarchical phenomena were often overrepresented compared to natural languages.  our work  which is based on naturally occurring data  is most closely related to that of  linzen et al.        and bernardy and lappin          which we discussed in the introduction.  other recent work has focused on the morphological and grammatical knowledge that rnn based  machine translation systems and sentence embeddings encode  typically by training classifiers to  decode various linguistic properties from hidden  states of the network  e.g.  adi et al.        belinkov et al.        shi et al.         or looking at  whether the end to end system correctly translates  sentences with challenging constructions  sennrich       .  previous work in neurolinguistics and psycholinguistics used jabberwocky  or pseudo word   sentences to probe how speakers process syntactic  information  friederici et al.        moro et al.   linzen s dataset was recently reported by yogatama et al.        .           johnson and goldberg       . such sentences are obtained by substituting original words  with morphologically and phonologically acceptable nonce forms. we are not aware of work that  used nonce sentences made of real words to evaluate the syntactic abilities of models or human subjects. as a proof of concept  pereira        and   later  mikolov        computed the probability of  chomsky s famous  colorless green ideas  sentence using a class based bigram lm and an rnn   respectively  and showed that it is much higher  than the probability of its shuffled ungrammatical  variants.         conclusion    we ran an extensive analysis of the abilities of  rnns trained on a generic language modeling  task to predict long distance number agreement.  results were consistent across four languages and  a number of constructions. they were above  strong baselines even in the challenging case of  nonsense sentences  and not far from human performance. we are not aware of other collections  of human long distance agreement judgments on  nonsensical sentences  and we thus consider our  publicly available data set an important contribution of our work  of interest to students of human  language processing in general.  the constructions we considered are quite infrequent  according to a rough estimate based on  the treebanks  the language in which they are most  common is hebrew  and even there they occur  with average  .   sentence frequency . moreover  they vary in the contexts that separate the cue  and the target. so  rnns are not simply memorizing frequent morphosyntactic sequences  which  would already be impressive  for systems learning  from raw text . we tentatively conclude that lmtrained rnns can construct abstract grammatical  representations of their input. this  in turn  suggests that the input itself contains enough information to trigger some form of syntactic learning in a  system  such as an rnn  that does not contain an  explicit prior bias in favour of syntactic structures.  in future work  we would like to better understand what kind of syntactic information rnns  are encoding  and how. on the one hand  we  plan to adapt methods to inspect information flow  across rnn states  e.g.  hupkes et al.       . on  the other  we would like to expand our empirical  investigation by focusing on other long distance    phenomena  such as overt case assignment  blake         or parasitic gap licensing  culicover and  postal       . while it is more challenging to extract reliable examples of such phenomena from  corpora  their study would probe more sophisticated syntactic capabilities  possibly even shedding light on the theoretical analysis of the underlying linguistic structures. finally  it may be  useful to complement the corpus driven approach  used in the current paper with constructed evaluation sentences that isolate particular syntactic phenomena  independent of their frequency in a natural corpus  as is common in psycholinguistics  enguehard et al.       .    acknowledgements  we thank the reviewers  germa n kruszewski  gerhard ja ger  adam lis ka  tomas mikolov  gemma  boleda  brian dillon  cristophe pallier  roberto  zamparelli and the paris syntax and semantics  colloquium audience for feedback and advice.    