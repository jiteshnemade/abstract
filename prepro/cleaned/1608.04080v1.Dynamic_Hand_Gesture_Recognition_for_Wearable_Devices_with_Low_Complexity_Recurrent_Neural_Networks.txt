introduction    recently  many wearable devices have been developed for  diverse applications  such as smart watches  google glass   and smart bands. since most wearable devices do not equip  keyboards or wide touch screens  it is very necessary to employ  speech or gesture recognition technologies. although speech  recognition can be more versatile  the gesture recognition can  also be conveniently used for issuing simple commands.  there are several studies and applications that use the  hand gesture technology in wearable devices. for example   google glass was controlled by hands and feet in      smart  watches were controlled using flexible force sensors in      and  sixthsense employed a camera and a projector for interaction  with real world    .  generally gestures can be classified into static and dynamic  ones. static gestures are usually represented by the hand  shapes  while dynamic gestures are described according to  hand movements    . gesture recognition can be conducted  using signal from a camera or a force sensor. the former needs  video processing while the latter analyzes time varying multichannel sensor output signal. when a force sensor is used   only the dynamic gesture recognition can be conducted.  recently  several hand gesture recognition algorithm have  been developed        .     adopted the correlation between  two videos which is called tensor canonical correlation analysis   tcca . a convolutional neural network  cnn  is used for  vision based static hand gesture recognition for human robot  interaction  hri     . a multimodal gesture detection and  recognition is studied using depth video  articulated pose  and    audio stream    . they applied a cnn  a hidden markov  model  hmm  based speech recognizer  and a bag of word   bow  to extract the multimodal features. for data fusion and  gesture classification  they employed an elman rnn. in       an infrared led data from leap motion controller was used   where a cnn was applied for feature extraction and an hmm  was adopted for time series recognition.  neural networks are employed to many recognition applications including object detection and speech recognition    . however  neural networks demand heavy computation  and large memory. for example  a long short term memory   lstm  rnn with the unit size of     demands a total of  approximately  .  million  m  weights     . for this reason   some of current wearable device applications such as speech  recognition operate using servers that employ graphics processing units  gpus  or multi core systems consuming quite  large power. thus  it is greatly needed for wearable devices to  operate neural network algorithms with only small power.  in this study  we have developed dynamic gesture recognition techniques using fixed point recurrent neural networks that  are suitable for hardware or embedded system based implementations and low power operation. two gesture recognition  algorithms are implemented  one uses the video signal from  a camera and the other utilizes a three axis accelerometer.  since dynamic gesture recognition needs to analyze the handmovements  we employ lstm rnns. also  a cnn is attached  in front of the rnn for video based hand gesture recognition.  the rnn is optimized to minimize the hardware complexity. in order to minimize the memory size for weight  storage  we conduct retrain based fixed point optimization and  successfully reduce most of the word length into   bits            .  this paper is organized as follows. in section ii  the  proposed hand gesture recognition models and quantization  procedure are given. experimental results are provided in  section iii and concluding remarks follow in section iv.    ii.    f ixed   point rnn optimization    we employ two different kinds of dynamic hand gesture  dataset. one is based on the image sequence      and the  other is the   axis acceleration data     . also  a fixed point  optimization scheme for these algorithms is explained.     l   s  c     s  c     s  l     l  out    input  ig    in    fg  in c     input    output    out    og    c     s     c     s     c     s     layer with n units demands a total of  n      n m    n  weights where m is the previous layer size     . therefore   the total number of weights is approximately    k  and as a  result     kb memory space is needed for the network model  when a floating point format is used.  c. retrain based weight and signal quantization    l     output    fig.  . a structure of the three layer cnn and one lstm rnn. the  prefixes  c    s  and  l  stand for convolution  subsampling and an lstm  layer  respectively. the prefixes  ig    fg    og  represent input gate  forget  gate and output gate of the lstm layer.  in c     s  c     s  c     s  l      l    and  l  out  show weight groups for sensitivity analysis. dotted lines  and solid lines represent recurrent and forward paths  respectively.    a. image sequence based dynamic hand gesture recognition  for the image sequence based dynamic hand gesture recognition task  we employed a cnn lstm rnn structure. to  generate hand shape features  three layer cnn architecture  is chosen for its translational invariance properties. our three  layer cnn is similar to the one proposed by     . the specific  network structure is depicted in fig.    which shows three  convolution and pooling layers followed by an rnn layer.  the input layer consists of                 linear units for  handling the    by    input images with rgb channels. the  first and the second convolution layers have    feature maps  and the third convolution layer has    feature maps. these  three layers have the same convolution kernel size  which is       . the three pooling layers employ       overlapping max  pooling. thus  the cnn demands   .  kilo weights. rectified  linear units are adopted as for the activation functions. we  employ the rnn layer to analyze gesture s temporal relation.  the lstm rnn can remember quite long past information in  the sequence. as a result  hmm networks are not needed in  this recognition model. the output layer consists of   softmax  units which correspond to   target gesture behaviors. the  total number of weights for the lstm rnn is approximately    .    kilo weights. therefore  a total of  .    mb    .   k and   .    k weights for cnn and rnn  respectively   memory space is required for the network model in a    bit  floating point format.  b. acceleration data sequence based dynamic hand gesture  recognition  the acceleration data sequence based dynamic hand gesture recognition model also employs the lstm rnn structure.  the standard lstm uses three gates which are called the  input gate  forget gate and output gate that can access and  modify the memory cells. the activation functions for these  three gates are the logistic sigmoid  and the input and output  layers of the lstm employ the hyperbolic tangent activation  functions. this algorithm applies the acceleration data directly  to the rnn. therefore  this application is much simpler than  the image sequence based dynamic hand gesture recognition.  the input layer contains   linear units to receive the   axis  acceleration data. one lstm hidden layer with the size of      is used  and the output layer consists of   softmax units  which correspond to   target gesture movements. an lstm    the quantization effects of signals or weights depend on  a signal flow graph  and the influence of quantization can be  represented as the sensitivity     . the weights and signals  in each layer are grouped and each group employs the same  quantization step size  . to optimize    we adopt l  error  minimization criteria as suggested in           .  based on the quantization step size    sensitivity analysis  for weights and signals is conducted layerwisely. fig.   shows  the weight and signal grouping results. in this figure   in c    is the first weight group between the input layer and the first  convolution layer   s  l   is the fourth weight group between  the last pooling layer and the lstm layer   c   is the signal  group of the first cnn layer  and  l   is the signal group of  the lstm layer.  since direct quantization does not show good performance   retraining on the quantization domain is performed. the rnn  version of the retraining algorithm is introduced in     .  in our target networks  we use three different types of  activation functions  logistic sigmoid  hyperbolic tangent and  rectified linear unit . the output range of the logistic sigmoid  function is between   and    that of the hyperbolic tangent is     and    and that of the rectified linear unit is theoretically    and  . thus  the output signals for the logistic sigmoid  and hyperbolic tangent activation functions are quantized with  a fixed size of  . however  the output value of the rectified  linear unit can be unbounded. therefore  the quantization step  size   needs to be calculated in a similar method with the  weights quantizer. the output signals of the rectified linear  units are saved all over the training set to compute the proper  quantization step size   with l  error minimization.  iii.    e xperimental r esults    the proposed algorithms are evaluated using two datasets  obtained from wearable devices. one is the image based hand  gesture recognition dataset and the other is the acceleration  dataset from a   axis accelerometer. advanced training techniques such as early stopping  adaptive learning rate  and  nesterov momentum are employed           .  a. image based dynamic hand gesture recognition  image based dynamic hand gesture recognition experiments  were performed on the cambridge gesture data base    . the  data set consists of     image sequences of   gesture classes  in qvga      by       which are defined by   primitive hand  shapes  flat  spread  and v shape  and   primitive motions  left   right  and contract . therefore  the target task for this data  set is to classify different shapes as well as different motions  simultaneously. each class contains     image sequences     different illuminations      arbitrary motions     subjects .  the dataset was divided into     for the training       sequences       for the validation      sequences   and      for the test      sequences  randomly. the ratios of the class  labels are the same for the three sets.      a  cambridge hand dataset        fig.  . layerwise weights sensitivity analysis results of the image based  dynamic hand gesture recognition example. the red line indicates the floatingpoint results  the blue line represents the direct quantization result  and the  green line shows the retraining results.     b  smartwatch gestures dataset       fig.  . dynamic hand gesture datasets for experiments   a  is the image  based dataset and  b  is the accelerometer based dataset.  table i.    l ayerwise sensitivity analysis results for signal  groups in the image sequence based model . e ach layers is  quantized in two bits for sensitivity analysis . t he numbers in  the table represent the miss classification rate     of the test  set.  d  means direct quantization results and  r  represents  the results after retraining .    d  r    in    c     s     c     s     c     s     l     all      .      .        .      .        .      .        .      .        .      .        .      .        .      .        .      .        .      .      quantized network with these two sensitivity results. all the  weight and signal groups were quantized by using only two  bits  and the miss rate was   .   . with this quantization  the  memory space saved is   .             when compared to a  floating point implementation. the total number of multiplications for each layer is   .    m  c      .  m  c     .    m   c     .    m  l   and   .   k  out   respectively  for realtime operation     hz . the memory space needed is   .     kb. therefore  our model can efficiently be implemented in  embedded systems such as cortex a       kb     mb l   cache   since the whole weights memory can be stored in the  on chip l  cache.  b. accelerometer based dynamic hand gesture recognition    the network is trained using fractal rnn library with  training parameters that are    forward steps and    backward  steps with   streams     . initial learning rate was      and  the learning rate is decreased until      during the training.  momentum was  .  and adadelta was adopted for weights  updating     . we tried to find out the proper input size of  the cnn with    by        by     and    by    images.  their floating point classification error rates were   .        .     and   .    respectively. therefore  the    by     image size is selected as the input image dimension. the  network demands approximately    .    kilo weights. all  experiments are repeated five times to consider their noise  effects.  fig.   shows the layerwise fixed point sensitivity analysis  for the weight groups. the original miss classification rate  was   .    for the test set. the results indicate that the most  sensitive weight groups are  in c   and  l  out . however  the  final fixed point network employs only   bits for all the weight  groups because their sensitivity difference is small. table i  depicts the results of the signal group sensitivity analysis. all  the signal groups also employ only two bits after retraining.  note that some layers even show better performance when  compared to the floating point results. we obtained a fully    an accelerometer based dynamic hand gesture recognition model was trained using the smartwatch gestures  dataset     . the data set has been collected to evaluate  several gesture recognition algorithms for interacting with  mobile applications using arm gestures. eight different users  performed twenty repetition of twenty different gestures for a  total of      sequences. each sequence contains acceleration  data from the   axis accelerometer of a first generation sony  smartwatch. original dataset contains    motions  but eight  motions which are depicted in fig.    b  are enough as a wearable device controller. the training  validation  and test sets are  divided randomly into           and     respectively.  the rnn training method is the same with     . initial  learning rate was      and it is decreased until      during  the training procedure. momentum was  .  and adadelta  was employed for weight updating. we tried to find out the  proper network size of the lstm layer. the network sizes  of             and     were considered. since the entire  number of the dataset is too small to training the lstm  rnn  the test set noise was very large. therefore we conduct  the experiments    times for each network size. the floating  point training results were   .     .     mean standard  deviation     .    .       .    .     and   .    .        table ii.  l ayerwise sensitivity analysis results in the  accelerometer based model . t he numbers in the table are miss  classification rates     of the test set. a ll groups are  quantized in two bits except  l   signal group.  l      and   l      represent that the signal sensitivity analysis was  performed in two and three bits   respectively.  weight  direct quantization  retrain based    in l     .      .      l     .      .      l  out    .      .      signal  direct  retrain    in    .      .      l        .      .      l        .      .      