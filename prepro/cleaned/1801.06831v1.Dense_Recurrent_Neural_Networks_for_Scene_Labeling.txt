introduction  scene labeling  or scene parsing  which aims to assign  one of predefined labels to each pixel in an image  is usually formulated as a pixel level multi classification problem. borrowing from the successes of convolutional neural  networks  cnns       in image classification                there are attempts to apply cnns on scene labeling                     . owing to the powerful feature representation of cnns  these approaches demonstrate promising  performance on scene parsing. however  a potential problem with these methods is that cnns only explore limited  contextual cues from a small local field for classification   which is prone to cause misclassifications for visually similar pixels of different categories. for example  the  sand   pixels can be visually indistinguishable from  road  pixels  even for human with limited context. to alleviate this issue  a natural solution is to leverage richer context information to discriminate locally ambiguous pixels            .  in these approaches  nevertheless  the long range contextual     a  undirected cyclic graph     b  directed acyclic graph     c  dense undirected cyclic graph     d  dense directed acyclic graph    figure  . image  a  shows the image of ucg structure as in        and image  b  is one of four dag decompositions. different from        we utilize d ucg to represent an image as shown in image   c   and image  d  displays one of the four d dags. compared  to ucg and dag  our d ucg and d dag capture richer dependency information flow in images. best viewed in color.    dependencies among image regions are still not effectively  explored  which are crucial in scene parsing.  motivated by the capacity of capturing long range dependency among sequential data  recurrent neural networks   rnns       have recently been employed to model semantic dependencies in images for scene labeling                       allowing us to perform long range inferences to discriminate ambiguous pixels.  to model the dependencies among image units  a common way          is to represent an image with an undirected cyclic graph  ucg  in which the image units are vertices and their interactions are encoded by undirected edges   see fig.   a  . due to the loopy structure of ucgs  however  it is difficult to directly apply rnns to model dependencies in images. to deal with this problem  an ucg is     approximated with several directed acyclic graphs  dags    see fig.   b  . then several dag structured rnns are  adopted to model the dependencies in these dags.  though these dag structured rnns can capture dependencies in images to some extent  quiet a bit of information  are discarded. for example in fig.   a   to correctly distinguish the  sand  unit in red region from the  road  unit   dag structured rnns can use the dependency information  of  water  units in the pink region from its adjacent neighbors. however  the  water  information may be decaying  because it needs to pass through conductors  i.e.  the adjacent neighbors of this  sand  unit . instead  a better way is  to directly leverage the dependency information from  water  units to discriminate  sand  unit from  road  unit.  recently  densenet      has demonstrated superior performance in image recognition by introducing dense connections to improve information flow in cnns. analogous to cnns  the dag structured rnns can be unfolded  to a feed forward network  the dependency information in  an image flows from the start vertex at top left corner to  end vertex at bottom right corner. to incorporate richer dependency information for each image unit  it is natural to  add more connections to the rnn feed forward network as  well  as proposed in this paper.     . . contributions  our first contribution is to propose dense rnns  which  capture richer dependencies from various abundant connections in images for each image unit. unlike existing approaches representing an image as an ucg  we formulate  each image as a dense ucg  d ucg   which is a complete  graph. in d ucg  each pair of vertexes are connected with  an undirected edge  see fig.   c  . by decomposing the ducg into several dense dags  d dags   we propose the  dag structured dense rnns  dd rnns  to model dependencies in images  see fig.   d  . compared to plain dag  structured rnns  our dd rnns are able to gain richer dependencies from various levels. for instance in fig.   c   to  correctly recognize the  sand  unit in red region  in addition  to the dependencies from its neighbors  our dd rnns enable the firsthand use of dependencies from  water  units in  the pink region to improve the discriminative power.  the dd rnns are able to capture vast dependencies for  each image unit through dense connections. for a specific  unit  however  certain dependencies are irrelevant to help  improve discriminative power. for example in fig.   d    the  sky  units in blue region are actually not useful to distinguish a  sand  unit in the red region from a  road  unit.  instead  the dependencies from  water  units in the pink region are the most crucial cues to infer its label. thus  more  importance should be assigned to dependencies from  water  units. to this end  we make the second contribution  by introducing an attention model into dd rnns. the at     tention model is able to automatically select relevant and  meanwhile restrain irrelevant dependency information for  each image unit  which further enhances their discriminative power.  last but not least  our third contribution is to implement an end to end scene labeling system by integrating  dd rnns with cnns. for validation  we test the proposed method on three popular benchmarks  pascal context       mit ade  k      and siftflow     . in these experiments the proposed method significantly improves the  baseline and outperforms other state of the art algorithms.  the code will be released upon the publication.  the rest of this paper is organized as follows. section    briefly reviews the related works of this paper. section    describes the proposed approach in details. experimental  results are demonstrated in section    followed by conclusion in section  .     . related work   . . scene parsing  as one of the most challenging problems in computer  vision  scene parsing has drawn increasing attentions in recent decades. early efforts mainly focus on the probabilistic  graphical model with hand crafted features                 .  despite great progress  these approaches are restricted due  to the use of hand crafted features.  inspired by their successes in image recognition                deep cnns have been extensively explored for scene  parsing. long et al.      propose an end to end scene labeling method by transforming standard cnns for classification into fully convolutional networks  fcn   resulting in significant improvement from conventional methods.  to generate desired full resolution predictions  various approaches are proposed to learn to upsample low resolution  feature maps to high resolution feature maps for final prediction            . in order to alleviate boundary problem  of predictions  graphical models such as conditional random field  crf  or markov random field  mrf  are introduced into cnns            . as a pixel level classification problem  context plays a crucial role in scene labeling  to distinguish visually similar pixels of different categories.  the work of      proposes to introduce the dilated convolution into cnns to gather multi scale context for scene labeling. liu et al.      suggest an additional branch in cnns  to incorporate global context for scene parsing.     . . rnns on computer vision  recently  owing to the ability to model spatial dependencies among different image regions  rnns      have  been applied to many computer vision tasks such as image  completion       handwriting recognition       image classification      and so forth. taking into consideration the     importance of spatial contextual dependencies in images to  distinguish ambiguous pixels  there are attempts to applying  rnns for scene labeling.  the work of     explores the two dimensional long short  term memory  lstm  networks for scene parsing by taking into account the complex spatial dependencies of pixels  in an image. in       stollenga et al. introduce a parallel  multi dimensional lstm for image segmentation. liang et  al.      propose a graph based lstm to model the dependencies among superpixels in images. visin et al.      suggest to utilize multiple linearly structured rnns to model  horizontal and vertical dependencies in images for scene labeling. li et al.      extend this method by replacing rnns  with lstm and apply it to rgb d scene labeling. qi       proposes to use gated recurrent units  grus  to model longrange context. especially  to exploit more spatial dependencies in images  shuai et al.      propose to represent  an image with an ucg. by decomposing ucg into several  dags  they then propose to use dag structured rnns to  model dependencies among image units.  different from the aforementioned approaches  we propose dense rnns to model richer long range dependencies  in images from dense connections  which significantly improves the discriminative power for each image unit.     . . attention model  the attention based model  being successfully applied  in natural language processing  nlp  such as machine  translation      sentence summarization      and so on  has  drawn increasing interest in computer vision. xu et al.       propose to leverage an attention model to find out regions  of interest in images which are relevant in generating next  word. in       chen et al. propose scale attention model for  semantic segmentation by adaptively merging outputs from  different scales. in      the attention model is utilized to  assign importance to different regions for context modeling  in images. the work of      introduces co attention model  for question answering. chu et al.      propose to utilize  attention model to combine multi context for human pose  estimation.  to the best of our knowledge  our work is the first to  leverage the attention model in rnns for scene labeling.  our attention model automatically selects relevant and restrains irrelevant dependencies for image units from dense  connections  further improving their discriminability.     . . review of dag structured rnns  the linear rnns in      are developed to handle sequential data tasks. specifically  a hidden unit ht in rnns at  time step t is represented with a non linear function over  current input xt and hidden layer at previous time step ht      and the output yt is connected to the hidden unit ht . given  an input sequence  xt  t          t   the hidden unit and output at time step t can be computed with  ht    u xt   w ht     b            yt    v ht   c            where u   v and w represent the transformation matrices  b  and c are bias terms  and      and      are non linear functions  respectively. since the inputs are progressively stored  in the hidden layers as in eq.      rnns are capable of  preserving the memory of entire sequence and thus capture  long range contextual dependencies in sequential data.  for an image  the interactions among image units can be  formulated as a graph in which the dependencies are forwarded through edges. the solution in      utilizes a standard ucg to represent an image  see again fig.   a  . to  break the loopy structure of ucg       further proposes to  decompose the ucg into four dags along different directions  see fig.   b  for a southeast example .  let g    v  e  represent the dag in fig.   b   where  v    vi  n  i   denotes the vertex set of n vertices  e     eij  n  i j   represents the edge set  and eij indicates a directed edge from vi to vj . a dag structured rnn resembles the identical topology of g  with a forward pass formulated as traversing g from the start vertex. in such modeling   the hidden layer of each vertex is dependent on the hidden  units of its adjacent predecessors   see fig.   b  . for vertex  vi   its hidden layer hvi and output can be expressed as  x  hvi    u xvi   w  hvj   b        vj  pg  vi      yvi    v hvi   c            where xvi denotes the local feature at vertex vi and pg  vi    represents the predecessor set of vi in g. by storing local  inputs into hidden layers and progressive forwarding among  them with eq.      the discriminative power of each image  unit is improved with dependencies from other units.     . . dense rnns     . the proposed approach  in this section  we describe the proposed approach in details. section  .  briefly reviews the dag structured rnns.  section  .  introduces dense rnns to capture richer dependencies in images. the attention model is applied to dense  rnns in section  . . section  .  describes the full labeling  system by integrating dense rnns with cnns.    in dag structured rnns  each image unit receives the  dependencies from other units through recurrent information forwarding between adjacent units. nevertheless  the  useful dependency information may be potentially degraded  after going through many conductors  resulting in a dependency decaying problem. for instance in fig.   b   the  most useful contextual cues from  water  units have to pass                            a  dag structured rnns     b  predecessors for      in dag rnns                of our dd rnns resembles the identical topology of d as  shown in fig.   c . in our dd rnns  the hidden layer of  each vertex is dependent on the hidden units of its all adjacent and non adjacent predecessors  which fundamentally  varies from      in which the hidden unit of each vertex  only relies on hidden units of its adjacent predecessors  see  fig.   b  . the forward pass at vi in dd rnns is expressed  as  x  h vi    hvj       vj  pd  vi               c  dag structured dense rnns  d  predecessors for      in dd rnns    figure  . the illustration of difference between dag structured  rnns      and our dd rnns. image  a  shows the dag structured rnns along southeast direction  and in image  b  the hidden  layer of vertex vi relies on its three adjacent predecessors  see the  red region in image  b  . image  c  is our dd rnns  and in image  d  the hidden layer of vi is dependent on all its adjacent and  non adjacent predecessors  see the red region in image  d  . best  viewed in color.    through conductors to arrive at the  sand  unit covered in red  region. a natural solution to remedy the problem of dependency decaying is to add additional pathes between hidden  layers of distant units and current image unit.  inspired by the recent state of the art densenet       we  propose dag structured dense rnns  dd rnns  to model  richer dependencies in images. in densenet       each  layer is connected to every other layer in a feed forward  fashion  which improves information flow between layers.  analogous to cnns  the dag structured rnns can be unfolded to a feed forward network  the dependency information in an image flows from start vertex at top left corner  to end vertex at bottom right corner. to capture richer dependencies in images  we introduce more connections in the  rnn feed forward network  resulting in the proposed ddrnns.  to achieve dense connections  we in this paper represent  an image with a d ucg  which is equivalent to a complete  graph  see fig.   c  for illustration . compared to standard  ucg  the d ucg allows each image unit to connect with  all of other units. because of the loopy property of d ucg   we adopt the strategy as in      to decompose the d ucg  to four d dags along four directions. one of the four ddags along southeast direction is shown in fig.   d .  let d represent the d dag in fig.   d . the structure    hvi    u xvi   w h vi   b            yvi    v hvi   c            where pd  vi   is the dense predecessor set of vi in d dag  d  and it contains both adjacent and non adjacent predecessors  see fig.   d  . compared to the dag structured rnns  in       our dd rnns are able to model richer dependencies in images through various dense connections.  a concern arisen naturally from the dense model is the  complexity. in fact  it is unrealistic to directly apply the  dd rnn to pixels of an image. fortunately  neither is it  necessary. as described in section  .   we typically apply  dd rnn to a high layer output of existing cnn models.  such strategy largely reduces the computational burden    as summarized in table    our final system runs faster than  state of the arts while achieving better labeling accuracies.     . . attention model in dd rnns  for the hidden layer at vertex vi   it receives dependency  information from various predecessors through dense connections. however  the dependency information from different predecessors are not always equally helpful to improve discriminative representation. for example  to distinguish  sand  units from visually alike  road  units in a beach  scene image  the most important contextual cues are probably the dependencies from  water  units instead of other  units such as  sky  or  tree . in this case  we term the relation from  water  units as relevant dependencies while the  information from  sky  or  tree  units as irrelevant ones.  to encourage relevant and restrain irrelevant dependencies for each image unit  we introduce a soft attention  model     into dd rnns. in      the attention model is  employed to softly assign importance to input words in a  sentence when predicting a target word for machine translation. in this paper  we leverage attention model to select  more relevant and useful dependencies for image units. to  this end  we do not use eq.     and eq.     to directly  model the relationships between hvi and its all predecessors. instead  we employ the following expression to model  the dependency between hvi and one of its predecessors hvj  hvi  vj     u xvi   w hvj   b             prediction    cnns features  input    cnns features    cnns features    d rnns features prediction    prediction    upsampling x      upsampling x      dd rnns    upsampling x      conv    pooling    conv    pooling    conv    pooling    conv    pooling    conv    pooling    prediction    prediction  labeling    figure  . the architecture of the proposed full labeling system. the dd rnns are placed on the top of feature maps obtained from the   th convolutional block to model long range dependencies in image  and the deconvolution is used to upsample the predictions. low level  and high level features are combined through skip strategy for final labeling  see the green arrows . best viewed in color.    where hvj represents the hidden layer of one predecessor  vj   pd  vi   of vi . the hvi  vj in eq.     models dependency information from hvj for hvi . the final hidden unit  hvi at vi is obtained by summating all hvi  vj with attention   and mathematically computed with  x  h vi    hvi  vj wvi  vj       vj  pd  vi      where the attention weight wvi  vj for hvj reflects the relevance of the predecessor vj to vi   calculated by  exp z t hvi  vj    wvi  vj   p  exp z t hvi  vk              vk  pd  vi      where z t represents a transformation matrix.  with the above attention model  we replace equations      and     with equations     and     for a forward pass at  vi in dd rnns. with standard stochastic gradient descent   sgd  method  the attentional dd rnns can be trained in  an end to end manner.     . . full labeling system  before showing the full labeling system  we first introduce the decomposition of d ucg. as in       we decompose the d ucg u into a set of d dags represented with   dl  l  l     where l is the number of d dags. since eq.      only computes the hidden layer at vertex vi in one of l ddags  the final output y vi at vi is derived by aggregating  the hidden layers at vi from all d dags. the mathematical  formulation for this process is expressed as  hlvi  vj    u l xvi   w l hlvj   bl    x  hlvi    hlvi  vj wvl i  vj                  vj  pdl  vi      xl  y vi      v l hlvi   c   l              through the equations above  we can then utilize the proposed dd rnns to model abundant dependencies among  image units.  we develop an end to end scene labeling system by integrating our approach with popular cnns for scene parsing  as shown in fig.  . the first five convolutional blocks  borrowed from the vgg network       are used to extract highlevel features for local regions. the proposed dd rnns are  placed on the top of feature maps obtained from the  th convolutional block to model long range dependencies in the  input image  and the deconvolution operations are used to  upsample the predictions. to produce the desired input size  of labeling result  we use the deconvolution      to upsample predictions. taking into consideration both spatial and  semantic information for scene labeling  we adopt the skip  strategy      to combine low level and high level features.  the whole system is trained end to end with the pixel wise  cross entropy loss. finally  we apply conditional random  field      to further polish the results.     . experimental results  implementation details. in our full labeling system  the  parameters for the five convolutional blocks are borrowed  from vgg network     . dd rnns are employed to model  dependencies among image units in the  th pooling layer.  the network takes           images as inputs  and outputs  the labeling results with same resolution. when evaluating  the labeling results are resized to the size of original inputs. the dimension of input  hidden and output units for drnns is set to    . the two non linear activations   and    are relu and softmax functions  respectively. the full networks are end to end trained with standard sgd method.  for convolutional blocks  the learning rate is initialized to  be      and decays exponentially with the rate of  .  after     epochs. for d rnns  the learning rate is initialized to  be      and decays exponentially with the rate of  .  after    epochs. the batch sizes for both training and testing  phases are set to  . the results are reported after    training     epoches. the networks are implemented in matlab using  matconvnet      on a single nvidia geforce titan gpu  with   gb memory.  evaluation metrics. in this work  we use three types of  metrics  i.e.  global pixel accuracy  gpa   average class accuracy  aca  and mean intersection over union  iou   to  evaluate the proposed method. for details of these metrics   readers are referred to     .  baseline. to better analyze the proposed method  we develop a baseline by using plain dag structured rnns to  model dependencies. it is worth noticing that the baseline varies from      because we do not use class weighting strategy and larger conventional kernel in our labeling  system.     . . results on pascal context  the pascal context      dataset consists of         images. following the split in             images are used  for training and the rest for testing. the images are collected from the pascal voc      dataset and re labeled  into     classes for pixel wise scene labeling. similar to  other literatures  we in this paper only consider the most  frequent    classes in the benchmark for evaluation.  table  . quantitative results and comparisons on pascal context          classes . for fair comparisons  we only present algorithms which utilize vgg network      for feature extraction.  algorithm gpa     aca     iou      o p      cfm       camn      pixelnet      fcn  s       ho crf      boxsup       parsenet       convpp         cnn crf       crf rnn       deeplab      deeplab crf      dag rnn       dag rnn crf         n a  n a    .   n a    .   n a  n a  n a  n a    .   n a  n a  n a    .     .     n a  n a    .     .     .   n a  n a  n a  n a    .   n a  n a  n a    .     .       .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     baseline  dd rnns w o crf  dd rnns      .     .     .       .     .     .       .     .     .     the quantitative results and comparisons with state ofthe art methods are summarized in table  . benefiting from  the power of cnns  the fcn  s      achieves promising  result with mean iou of   .  . to alleviate the boundary  issue in fcn  s  the crf rnn      and deeplab crf      propose to utilize probabilistic graphical model such as  crf in cnns  and obtain better performances with mean  ious of   .   and   .    respectively. other approaches    such as camn     and parsenet      suggest to improve  performance by incorporating global context into cnns  and obtain mean ious of   .   and   .  . despite better performance  these methods still ignore the long range  dependencies in images  which are of importance in inferring ambiguous pixels. the method in      employs rnns  to capture contextual dependencies among image units for  scene labeling and demonstrates outstanding performance  with mean iou of   .  . moreover  they utilize crf to improve the result to   .  . different from this method  we  propose dd rnns to model richer dependencies in images.  our baseline method shows the effectiveness of plain dag  structured rnns  i.e.  no dense connections  for scene labeling with mean iou of   .  . without any class weighting strategy and post operations  our dd rnns improves  the baseline method from   .   to   .    which outperforms the method in      by  .    showing the advantage  of dd rnns. further  we apply crf to polish the result  and achieve the mean iou of   .  .  fig.   demonstrates performance comparisons on each  individual class in pascal context      between fcn s      and our methods. from fig.    we can see that using rnns in our baseline method can improve the performance most categories including visually similar ones such  as  dog  and  horse  with long range contextual dependencies in images. however  for other similar classes such as   ground  and  sidewalk   the baseline method does not show  significant improvements. for few classes such as  bed  and   bench   the fcn  s      method even performs better than  the baseline. by replacing plain rnns with dense rnns   our dd rnns achieves significant gains on performance  for visually similar classes such as  mountain  and  rock   using richer dependency information.  fig.   displays qualitative labeling results on pascal  context     . without considering long range contextual  dependencies in images  fcn  s      is prone to cause misclassifications  see the third column in fig.   . our baseline approach are able to help alleviate this situation using  rnns to capture dependencies in images. for example  in  the first two rows in fig.    the  water  can be correctly recognized with the dependencies from  boat . however  the  plain rnns fail in more complex scenes  see the last three  rows in fig.   . for example  in the fourth row in fig.     most of  road  pixels are mistakenly classified into  ground   pixels because of not full use of dependencies from  bus .  by contrast  the proposed dd rnns are capable of recognizing most of  road  pixels by taking advantages of richer  dependencies from  bus  in images. by employing crf  the  labeling results are further polished  see the last column in  fig.   .     iou of individual class on pascal context    fcn  s    baseline    dd rnns w o crf        .     the value o iou     .    .    .    .    .    .    .    .          figure  . comparisons of iou on pascal context      for each individual class. best viewed in color.    input    groundtruth  fcn  s  baseline  dd rnns w o crf  figure  . qualitative labeling results on pascal context     . best viewed in color.     . . results on mit ade  k  the recently published mit ade  k      benchmark  consists of        images in training set and       images  in validation set. there are total     semantics classes in  the dataset. mit ade  k      is considered to be one of  the most challenging scene parsing benchmarks because of  its scene varieties and numerous annotated object instances.  table   summarizes the quantitative results and comparisons with other state of the art algorithms. the fcn s      method achieves the result with mean iou of   .  .  to incorporate multi scale context into cnns  the work  of      proposes the dilated convolution and improves the  performance to mean iou of   .  . to the same end  hung    dd rnns    et al.      suggest to embed global context into cnns to  obtain improvements. based on fcn  s      method  they  improve the performance to   .   with global spatial prior  and to   .   with global feature. though the aforementioned methods take global context of image into consideration  they still ignore the important contextual dependencies in images. in this work  we employ dd rnns to  model this dependency information for scene labeling. in  our baseline experiment  the plain dag structured rnns  obtain the result with mean iou of   .    which outperforms fcn  s      with mean iou of   .   and segnet      with mean iou of   .  . by using dense connections in  rnns  the result is further significantly improved to mean  iou of   .   without crf  demonstrating the effectiveness      . . ablation study on attention model    of dense rnns.  table  . quantitative results on mit ade  k     .  algorithm gpa     aca     iou      segnet      fcn  s       dilatednet       fcn  s prior       fcn  s feature       cascade segnet       cascade dilated           .     .     .     .     .     .     .       .     .     .   n a  n a    .     .       .     .     .     .     .     .     .     baseline  dd rnns w o crf  dd rnns      .     .     .       .     .     .       .     .     .      . . results on siftflow  the siftflow      dataset comprises       images captured from   typical scenes and are annotated with     classes. following the split in             images are utilized for training and the rest for testing.  table  . quantitative results on siftflow     .  algorithm gpa     aca     iou      rcnn       rcnn       fcn  s       liu et al       parsenet       classrare       tighe et al       cnn crf       dilatednet       convpp  s       cnn lstm      farabet et al       sharma et al       dag rnn       dag rnn crf           .     .     .     .     .     .     .     .     .   n a    .     .     .     .     .       .     .     .   n a    .     .     .     .   n a  n a    .     .     .     .     .     n a  n a    .   n a    .   n a  n a    .     .     .   n a  n a  n a    .     .     baseline  dd rnns w o crf  dd rnns      .     .     .       .     .     .       .     .     .     table   reports the quantitative results on siftflow     .  the fcn  s      approach obtains the result with mean iou  of   .  . by incorporating context  the dilatednet       and cnn crf      methods improve the results of mean  iou to   .   and   .  . the work of      applies dag  structured rnns to model dependencies in images for scene  labeling  and obtains the result with mean iou of   .  .  furthermore crf is adopted to refine the results and mean  iou is improved to   .  . without class weighting strategy  or crf  our dd rnns achieve the result with mean iou of    .    outperforming the approach in     . moreover  the  result is further improved to   .   with crf.    in this paper  we propose the dd rnns to model richer  dependencies in images  which significantly enhances discriminability for each image unit. however  different dependencies are not always equally helpful. for example  to  distinguish a  sand  unit in a beach scene image  the most  useful contextual cues are  water  units. other regions such  as  sky  should be paid less attention. to activate relevant  and restrain irrelevant dependencies  we introduce an attention model into dd rnns. in order to demonstrate the effectiveness of attention model  we conduct experiment by  removing attention model from dd rnns. table   summarizes the experimental results on three benchmarks. from  table    we can see that the attention model helps to further  improve performance.  table  . analysis on the impact of attention model without crf.  attention  gpa     aca     iou      model  pascal context                   .     .       .     .       .     .     mit ade  k                   .     .       .     .       .     .               .     .       .     .       .     .     siftflow          . . study on model complexity  to further analyze our approach  we show the model size  and efficiency in table  . the proposed method is based on  the vgg network      except for the last fully connected  layers. in addition  to generate full input size prediction  maps  we utilize three deconvolutional layers to upsample  feature maps. table   reports the model complexities  i.e.   model size and efficiency of one forward pass  and comparisons with other state of the art scene labeling algorithms.  table  . analysis of model size and efficiency.  model size inference  segnet      fcn  s       dilatednet             mb      mb      mb       ms      ms      ms    ours        mb        ms     . conclusion  in this paper  we propose dense rnns for scene labeling.  different from existing methods exploring limited dependencies  our dag structured dense rnns  dd rnns  exploit abundant contextual dependencies through dense connections in image  which better improves the discriminative  power of image unit. in addition  considering that different  dependencies are not always equally helpful to recognize     each image unit  we propose an attention model  which is  capable of assigning more importance to relevant dependencies. integrating with cnns  we develop an end toend scene labeling system. extensive experiments on three  benchmarks including pascal context  mit ade  k  and siftflow demonstrate that our dd rnns significantly  improve the baseline and outperform other state of the art  algorithms  evidencing the effectiveness of dense rnns.    