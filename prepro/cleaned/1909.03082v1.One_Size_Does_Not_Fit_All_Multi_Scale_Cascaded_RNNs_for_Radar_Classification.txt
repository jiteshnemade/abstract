introduction    with the rapid growth in deployment of internet of things  iot   sensors in smart cities  the need and opportunity for computing  increasingly sophisticated sensing inferences on the edge has also  grown. this has motivated several advances in designing resource  efficient sensor inferences  particularly those based on machine  learning and especially deep learning. the designs  however  encounter a basic tension between achieving efficiency while preserving predictive performance that motivates a reconsideration of  state of the art techniques.  in this paper  we consider a canonical inference pattern  namely  discriminating clutter from several types of sources  in the context  of a radar sensor. this sort of n    class classification problem   where n is the number of source types  has a variety of smart  city applications  where diverse clutter is the norm. these include  triggering streetlights smartly  monitoring active transportation  users  pedestrians  cyclists  and scooters   crowd counting  assistive  technology for safety  and property surveillance. as an example   streetlights should be smartly triggered on for pedestrians but  not for environmental clutter such as trees moving in the wind.  similarly  property owners should be notified only upon a legitimate  intrusion but not for passing animals.  the radar is well suited in the smart city context as it is privacy preserving in contrast to cameras. moreover  it consumes  low power     mw   because of which it can be deployed at operationally relevant sites with little dependence on infrastructure   using  for instance  a small panel solar harvester or even a modest  sized battery  as shown in figure  . experiences with deploying  sensors in visionary smart city projects such as chicago s array  of things         and sounds of new york city     have shown  that wired deployments on poles tend to be slow and costly  given  constraints of pole access rights  agency coordination  and labor  unions  and can sometimes be in suboptimal locations. using a     buildsys      november              new york  ny    d. roy  s. srivastava  a. kusupati  p. jain  m. varma  and a. arora  instance  radar sensing applications require that the clutter recall  be very high so that there are minimal false alarms. however  a solution that restricts false alarms at the cost of detectability  i.e.  low  source recall  where a source could be either human or non human   would be undesirable as it would have limited applicability in the  smart city contexts discussed above.     a  micro power pdr system  b  solar harvested signpost platform supporting low power sensors        figure    the micro power pulse doppler radar  pdr  device can be independently deployed or interfaced with existing multi sensor smart city platforms such as signpost  figure adapted from      copyright       acm  inc.   table    trade offs in accuracy and runtime efficiency for  the   class radar problem  window length  s  feature computation overhead ignored for svm  dataset and machine architecture details are in section     ml model    accuracy    svm     features   lstm  cnn   s fft   emi lstm  fastgrnn  emi fastgrnn     .     .     .     .     .     .      flops    k     k   . m    k    k   k    real time   yes  no  no  yes  yes  yes    low power sensor that is embedded wirelessly or simply plugged  in to existing platforms while imposing only a nominal power cost  simplifies smart city deployment.  table   illustrates an efficiency accuracy trade off for the canonical inference pattern with n      wherein clutter is distinguished  from human and other  i.e.  non human  sources. the more accurate  deep models  the convolutional neural network  cnn       and the  long short term memory  lstm        that we machine learned for  this   class classifier from a reference dataset are significantly less  efficient  in terms of speed and therefore power consumption. in contrast  the more efficient shallow solution  support vector machine   svm   is significantly less accurate. while the svm classifier has  been implemented to operate in near real time on the cortex m   single microcontroller processor in the device depicted in fig.   a    neither the cnn nor the lstm per se yield a near real time implementation. to implement deep models in near real time on the  m   we therefore consider model optimization with recent stateof art techniques such as fast gated rnns  fastgrnn       and  early exit multi instance rnns  emi lstm and emi fastgrnn       . however  table   illustrates that the trade off remains  the  best accuracy we achieve  namely with the fastgrnn  has significantly lower efficiency than the best efficiency achieved  namely  with emi fastgrnn  but that has an accuracy that is comparatively  significantly worse.  problem statement. in this work  we investigate alternative optimizations of deep models for the above classification task that  achieve both high accuracy and speed. in doing so  we do not wish  to sacrifice the recall performance for achieving high precision. for    solution overview. the n     class radar problem  where the     class is clutter  conflates discrimination between classes that  are conceptually different. in other words  discriminating clutter  from sources has a different complexity from that of disambiguating  source types. this insight generalizes when the sources themselves  are related by a hierarchical ontology  wherein different levels of  source types involve concepts of correspondingly different complexity of discrimination.  by way of example  in the   class clutter vs. human vs. nonhuman classification problem  discriminating clutter from sources  turns out to be simpler than discriminating the more subtle differences between the source types. using the same machine architecture for   classes of discrimination leads to the accuracy efficiency  trade off  as the last two rows of table   indicate. a more complex architecture suffices for discriminating among source types  accurately  whereas a simpler architecture more efficiently suffices  for discriminating clutter from sources  but hurts the accuracy of  discriminating between source types.  we  therefore  address the problem at hand with an architecture  that decomposes the classification inference into different hierarchical sub problems. for the   class problem  these are   a  clutter  vs sources  and  b  humans vs. non humans given sources. for  each sub problems we choose an appropriate learning architecture   given the results of table    both architectures are forms of rnn  albeit with learning at different time scales. the lower tier rnn for   a  uses a short time scale rnn  the early exit multi instance rnn   emi fastgrnn            whereas the higher tier for  b  uses a  longer time scale rnn  a fastgrnn       which operates at the  level of windows  contiguous  fixed length snippets extracted from  the time series  as opposed to short instances within the window.  the upper tier uses the features created by the lower tier as its input  for loss minimization  both tiers are jointly trained. to further  improve the efficiency  we observe that source type discrimination  needs to occur only when a source is detected and clutter may be  the norm in several application contexts. hence  the less efficient  classifier for  b  is invoked only when  a  discriminates a source  we  refer to this as cascading between tiers. the joint training loss function is refined to emulate this cascading. we call this architecture  multi scale  cascaded rnns  msc rnn .  contributions. our proposed architecture exploits conditional  inferencing at multiple time scales to jointly achieve superior sensing and runtime efficiency over state of the art alternatives. to the  best of our knowledge  this approach is novel to deep radar systems.  for the particular case of the   class problem  msc rnn performs  as follows on the cortex m    accuracy    clutter  recall    human  recall    non human  recall    flops     .             .       .        k     multi scale  cascaded rnns for radar classification    its accuracy and per class recalls are mostly better than  and in  remaining cases competitive with  the models in table  . likewise   its efficiency is competitive with that of emi fastgrnn  the most  efficient of all models  while substantially outperforming it in terms  of sensing quality. we also validate that this msc rnn solution is  superior to its shallow counterparts not only comprehensively  but  at each individual tier as well. the data and training code for this  project are open sourced at     .  other salient findings from our work are summarized as follows       even with deep feature learning purely in the time domain   msc rnn surprisingly outperforms handcrafted feature engineering in the amplitude  time  and spectral domains for  the source separation sub problem. further  this is achieved  with  .      improvement in the featurization overhead.      the tier   component of msc rnn  which classifies legitimate sources from clutter  improves detectability by up to   .   compared to popular background rejection mechanisms  in radar literature  even when the false alarm rate is controlled to be ultra low.      msc rnn seems to tolerate the data imbalance among its  source types better than other compared rnn models. in  particular  it enhances the non dominant human recall by  up to      while simultaneously maintaining or improving  the dominant non human recall and overall accuracy.  organization. in section    we present related research and outline the basics of micro power radar sensing in section  . in section     we detail the various components in our solution and discuss  the training and inference pipelines. we provide evaluation and  prototype implementation details in sections   and   respectively.  we conclude and motivate future research in section  .         related work    shallow radar sensing. micro doppler features have been used  in myriad applications ranging from classification              to  regression     . most of these applications employ the short time  fourier transform  stft  representation for analyzing micro doppler  signatures. although shallow classifiers can be computationally  cheaper than deep solutions  the spectrogram generation over a sliding window for the stft incurs significant computational overhead  for real time applications on single microcontroller devices. in order  to decrease this overhead for feature extraction  different feature extraction methods like linear predictive coding       discrete cosine  coefficients       log gabor filters with principal component analysis       empirical mode decomposition      have been investigated  in the past. we  on the other hand  use a deep learning approach  that learns relevant features from raw time series data  and avoid  spectrogram computation altogether. feature engineering requires  sophisticated domain knowledge  is not assured to be efficient per  se  and may not transfer well to solutions for other research problems. moreover  selection of relevant and non redundant features  requires care for sensing to be robust     .  deep radar sensing. in recent years  there has been significant use of deep learning for radar applications. most works use  spectrogram based input              with deep architectures like  cnns autoencoders. the authors of      digitize the radio receiver s    buildsys      november              new york  ny  signal and generate a unique spectral correlation function for the  deep belief network to learn signatures from. the pre processing  needed in these applications and the resulting model sizes make  them unsuitable for single microcontroller devices. we use raw  time series data in conjunction with variants of rnns to achieve a  faster and efficient solution.  efficient rnn. the ability of rnns in learning temporal features  has made it ubiquitous in various sequence modeling tasks. rnns   albeit theoretically powerful  often fail to reach the best performance due to instability in their training resulting from the exploding and vanishing gradient problem  evgp      . gated rnns  like lstm      and gru     have been proposed to circumvent  evgp and achieve the desired accuracy for the given task. a drawback of lstm and gru is their model size and compute overhead  which makes them unattractive for the near real time single microcontroller implementations. recently  fastgrnn      has been  proposed to achieve prediction accuracies comparable to lstm and  gru while ensuring that the learned models are smaller than     kb for diverse tasks. our proposed hierarchical classifier solution  is based on this architecture.  multi instance learning and early classification. mil is a  weakly supervised learning technique that is used to label subinstances of a window. mil has found use in applications from  vision      to natural language processing  nlp      . it enables  a reduction in the computational overhead of sequential models  like rnns by localizing the appropriate activity signature in a  given noisy and coarsely labeled time series data along with early  detection or rejection of a signal     . we use it as our lower tier  classifier for clutter versus source discrimination.  multi scale rnn. one of the early attempts to learn structure in  temporally extended sequences involved using reduced temporal  sequences      to make detectability over long temporal intervals  feasible in recurrent networks         . with the resurgence of  rnns  multi scale rnns can discover the latent hierarchical multiscale structure of sequences     . while they have been traditionally  used to capture long term dependencies  we use it to design a computationally efficient system. we use different scales of temporal  windows for the lower and upper tier rnn. by conditioning the  upper tier classifier  which works on longer windows and is hence  bulkier we make sure that the former is invoked only when necessary  i.e.  when the lower tier predicts a source.  compression techniques. sparsity  low rank  and quantization  have been proven to be effective ways of compressing deep architectures like rnns          and cnns         . many other  compression methods like householder reflectors in spectral rnn        kronecker factorization in kru      have been proposed   which are complementary to the solution proposed in this paper.  we incorporate low rank representation  q   quantization  and  piecewise linear approximation      to make msc rnn realizable  on cortex m  microcontrollers.      radar and classifier models   .  micro power radar model  the monostatic pdr sensor depicted in figure   has a bandwidth  of nearly     mhz and a center frequency at about  .  ghz. it is a     d. roy  s. srivastava  a. kusupati  p. jain  m. varma  and a. arora     .     classifier architectures     . .  input and feature representation. the radar classifier system  uses the aforementioned complex time series as input. extant endto end architectures for micro power radar sensing mostly eschew  deep feature learning for cheap handcrafted feature engineering in  the amplitude  time  and spectral domains         . however  these  solutions incur significant featurization overhead  this is exemplified in table   on   second snippets extracted from the complex  time series. even ignoring the svm computation latency  it can  be seen that the main computation bottleneck is this incremental  overhead which results in      duty cycle on the cortex m   of  which      constitutes the fft overhead alone.  table    computation overheads in a shallow  svm  radar  solution on cortex m      features   s windows   component  fft  incremental feature computation  svm inference      svs     latency  ms                   . .  shallow classifier architecture. as shown in figure    a prototypical shallow radar classifier system consists of three subsystems    i  a displacement detector for discriminating clutter vs. sources   ii   an incremental featurizer   iii  an end inference engine that discriminates source types  and  iv  a composition manager that handles  their interactions. the displacement detector is a simple module  that thresholds unwrapped phase over incoming windows of radar  data      s or   s  to detect legitimate source displacements in the  scene  filtering in situ clutter that tends to yield self canceling phase  unwraps. when a source displacement is speculatively detected   the featurizer is invoked till the current displacement ends or a prespecified time limit is reached. the final feature vector is fed to an  end classifier such as support vector machine     . note that incremental feature computation overhead is the primary impediment  in realizing efficiency in these systems  hence techniques like replacing the heavy svm classifier with the much lighter bonsai          incremental featurizer    phase  unwrapping  noise  filtering  clutter  rejection    amplitude    radar  signal    control    inference engine    svm  phase    decision    windows    data  spec. start   legit disp.  not a disp.  spec. end  disp. end    feature  vector    stft    composition  manager    bonsai    get  inference    figure    svm classifier data and control planes  control  signal response pairs are color coded  or observing longer displacements to run inference infrequently do  not alleviate this problem.  while we preserve this ontological hierarchy in our solution   we replace this simple  ensemble  with a principled   tier rnn  approach in the time domain. in the next sections  we present our  proposed architecture and discuss how deep feature learning can  be used to successfully resolve the above issues.           tier deep classifier architecture    msc rnn is a multi scale  cascaded architecture that uses emifastgrnn as the lower tier clutter discriminator and fastgrnn  as the upper tier source classifier. while emi fastgrnn efficiently  localizes the source signature in a clutter prone time series ensuring  smaller sequential inputs along with early classification  fastgrnn  reduces the per step computational overhead over much heavier  alternatives such as lstm. we begin with the relevant background  for each of these components.     .    . .  deep classifier architecture. deep radar classifier systems  such as cnns  or even some rnns  convert the raw time series  to stft  and hence also maintain this steady overhead in input  representation. in the interest of designing resource efficient solutions  in this work  we instead focus on being competitive with  all domain featurization using purely time domain learning.    displacement detector    time limit    short range radar with an anisotropic radiation pattern yielding a  maximum detection range of     m. sensing itself consumes   mw  of power  not counting the inference computation on the associated  microcontroller. the radar response is low pass filtered to     hz   hence the output is typically sampled at rates over    hz.  the output signal from the radar is a complex time series with  in phase  i  and quadrature  q  components. when a source moves  within the detection range  in addition to the change in received  power  the phase of this signal changes according to the direction  of motion. consequently  its relative displacement can be estimated  with high accuracy  typically  sub cm scale   and a rich set of features can be derived by tracking its phase evolution over time.    compute  reset  snapshot    buildsys      november              new york  ny    candidate classifiers    fastgrnn. fastrnn      provably stabilizes rnn training by  helping to avoid evgp by using only two additional scalars over  the traditional rnn. fastgrnn is built over fastrnn and it extends the scalars of fastrnns to vector gates while maximizing  the computation reuse. fastgrnn also ensures its parameter matrices are low rank  sparse and byte quantized to ensure very small  models and very fast computation. fastgrnn is shown to match  the accuracies of state of the art rnns  lstm and gru  across  various tasks like keyword spotting  activity recognition  sentiment  analysis  and language modeling while being up to   x faster.  let x    x    x    . . .   xt   be the input time series  where x t   rd .  the traditional rnn s hidden vector ht   rd  captures long term  dependencies of the input sequence  ht   tanh wxt   uht      b .  typically  learning u and w difficult due to the gradient instability.  fastgrnn  figure   a   uses a scalar controlled peephole connection  for every coordinate of ht    ht           zt           tanh wxt   uht      bh     zt   ht       zt      wxt   uht      bz    here                are trainable parameters  and   represents the  vector hadamard product.     multi scale  cascaded rnns for radar classification    buildsys      november              new york  ny  decision    xt    w         f zt          zt      tanh    fgrnn    fgrnn    fgrnn    fgrnn  source detected   activated     u    cascaded    ht    ht      embeddings     b  emi fastgrnn  always on     figure    fastgrnn   emi fastgrnn  images from            emi rnn. time series signals when annotated are rarely precise  and often coarsely labeled due to various factors like human errors  and smaller time frames of activities themselves. emi rnn       tackles the problem of signal localization using mil  by splitting  the i th data window into instances  z i          ...t      of a fixed  width    figure   b  . the algorithm alternates between training  the classifier and re labeling the data based on the learned classier  until convergence. a simple thresholding scheme is applied to  refine the instances  in each iteration  k consecutive instances are  found with maximum prediction sum for the class label. only these  instances are included in the training set for the next iteration. here   k is a hyperparameter that intuitively represents the number of  instances expected to cover the source signature. in the end  emirnn produces precise signal signatures which are much smaller  than the raw input  thus reducing the computation and memory  overhead over the traditional sequential techniques. emi rnn also  ensures early detection of noise or keywords thereby removing the  need of going through the entire signal before making a decision.  when combined  emi fastgrnn provides very small models along  with very fast inference for time series classification tasks. codes  for fastgrnn        emi rnn      are part of microsoft research  india s edgeml repository     .     .     msc rnn design    while emi rnn is by itself equipped to handle multi class classification efficiently  we find its accuracy and non dominant source recall  to be sub optimal for the radar time series  especially at smaller  hidden dimensions and shorter window lengths. fastgrnn  on the  other hand  is a relatively heavier solution to be used as a continuously running   class discriminator. to redress this trade off  we  make the following observations    i  clutter  which yields self canceling phase  can be rejected at  a relatively shorter time scale    ii  disambiguating source types from their complex returns is  a harder problem requiring a potentially longer window of  observation  and   iii  the common case in a realistic deployment constitutes clutter   legitimate displacements are relatively few.  msc rnn  therefore  handles the two sub problems at different time scales of featurization  see figure     the lower tier  an  emi fastgrnn  discriminates sources from clutter at the level of  short instances  while the upper one  a windowed fastgrnn  discriminates source types at the level of longer windows. further  the  upper tier is invoked only when a source is discriminated by the  lower tier and operates on the instance level embeddings generated  by the latter.   . .  joint training and inference. the training of the lower tier  inherits from that of emi training. we recap its training algorithm    always on     a  fastgrnn  cascaded     emifgrnn    emifgrnn    emifgrnn    emifgrnn    multiple  instances    complex radar time series    figure    msc rnn architecture   the lower emi fastgrnn  runs continuously  while the higher fastgrnn is invoked  only for legitimate displacements        which occurs in two phases  the mi phase and the emi phase.  in the mi phase  where the source boundaries are refined in a clutterprone window  the following objective function is optimized            si  si  k     fl  zi      yi    min  n  fl  s i  i    here    represents the loss function of fastgrnn  and the classifier fl is based on the final time step in an instance. in the emi  phase  which incorporates the early stopping  the loss lemi is obtained by replacing the previous loss function with the sum of the  t      classifier loss at every step  min    w t oi t    where w is the  i t       fully connected layer and oi t the output at step t. the overall training proceeds in several rounds  where the switch to the emi loss  function is typically made halfway in.  for training the upper tier  in keeping with the divide andconquer paradigm of msc rnn  the upper tier fastgrnn cell  should only learn to separate the source types  while ignoring instances of training data that are clutter. therefore  we devise a  conditional training strategy that captures the cascading behavior.  to achieve this  the standard cross entropy loss function of the  upper tier is modified as       tr       yi    min   yi       fu  e  zi    fu n  i  where fu represents the upper classifier  and e   r t         f    r t       hl represents the instance level embedding vector from  emi rnn with a hidden dimension of hl  here  f represents the  feature dimension for the radar time series . intuitively  this means  that the upper loss is unaffected by clutter points  and thus the tiers  can be kept separate.  the training algorithm for msc rnn is outlined in algorithm  .  the two tiers are first separately initialized using their respective  loss functions  and in the final phase  both are jointly trained to minimize the sum of their losses. inference is simple  the instance level  emi rnn stops early with a decision of  source  when a probability threshold p  is crossed    k consecutive positives constitute a  discrimination for which the cascade is activated.     buildsys      november              new york  ny     a  public park     b  indoor amphitheater    d. roy  s. srivastava  a. kusupati  p. jain  m. varma  and a. arora     c  parking garage bldg.     d  building foyer    figure    some locations where source and clutter data was collected for experiments  algorithm    msc rnn training algorithm  input  multi instance training data  tr    tr    z i          ...t        yi  i    ...n   the number of rounds nr   k  training   freeze fastgrnn  unfreeze emi fastgrnn  repeat  t r      t r  train emi fastgrnn   z i    yi         until convergence  freeze emi fastgrnn  unfreeze fastgrnn  repeat  t r    y t r      minimizing loss  train fastgrnn  e  z i    i        t  r  yi       fu  e  z i        yi    n    number of human and non human displacement points where possible  and windowed into snippets of     .   and   seconds which  correspond to           and     i q sample pairs respectively. we  note that due to the duration of collections and differences in average displacement lengths  etc.  humans are underrepresented in  these datasets compared to the other labels. table   b  shows the  number of training  validation  and test points for each of these  window lengths on a roughly       split. currently  only the cattle  set has multiple concurrent targets  efforts to expand our datasets  with target as well as radar type variations are ongoing.  table    radar evaluation datasets   a  source displacement counts and clutter durations    i    env.    until convergence  unfreeze both emi fastgrnn and fastgrnn  for r   nr do  if r   n r then  llower   mi loss  else  llower   emi loss  end if  repeat  t r      t r  train msc rnn   z i    yi        minimizing loss        t r      y    llower   n  yi       fu  e  z i    i    building foyer  indoor amphitheater  parking garage bldg.  parking lot  indoor soccer field  large classroom  cornfield  cattle shed  playground  parking garage bldg.  public park  garden  lawn    i    until convergence  end for      comparative   tier wise evaluation   .  datasets  table   a  lists the radar source and clutter datasets collected in  various indoor and outdoor environments  which are used in this  work. some of these locations are documented in figure    small or  crammed indoor spaces such as office cubicles have been avoided  to prevent the radar returns from being adversely affected by multipath effects and because they are not central to the smart city  scenarios. a partial distribution of displacement durations is provided in figure   a . each data collect has associated with it the  corresponding ground truth  recorded with motion activated trail  cameras or cellphone video cameras  with which the radar data  was correlated offline to  cut  and label the source displacement  snippets appropriately  . the datasets have been balanced in the    the    radar dataset  which we have open sourced  does not include individually identifiable information of living individuals and is thus not considered research with  human subjects per    cfr    .    e     ii .    type    data type    human  gym ball  human  gym ball  human  human  car  human  gym ball  human  gym ball  human  dog  cow  clutter  clutter  clutter  clutter  clutter    count                                                                mins     mins     mins     mins     mins     b  windowed data from  a  showing number of training  validation  and test points    window len.  s       .         .     training                         windows  validation                      testing                      evaluation methodology    our proposed architecture is compared with existing shallow radar  solutions that use feature handcrafting in the amplitude  phase  and spectral domains  as well as with other mil rnns. in all cases  involving rnns  the radar data is represented purely in the timedomain. the models chosen for this evaluation are    a    tier svm with phase unwrapped displacement detection. phase unwrapping      is a widely used technique in  radar displacement detection due to its computational efficiency. the idea is to construct the relative trajectory of a     multi scale  cascaded rnns for radar classification    buildsys      november              new york  ny  table    training hyperparameters used               .      .      recall    empirical cdf     .   min   .  s  max       s  median   .   s     .      .            .                     disp. duration  s                        .     results     . .  comparative classifier performance. we compare the inference accuracy and recalls of msc rnn  with the rnn and shallow  solutions outlined in section  . .  recall that we have purposefully devised a purely time domain  solution for source discrimination for efficiency reasons  since one  of the main components of featurization overhead is that of fft  computations. figure   compares msc rnn with engineered features in the amplitude  time  and spectral domains that are optimized for micro power radar classification. for the two tier svm   the source recalls for increasing window sizes are inferred from  figure    discussed in section  . .  . we find that msc rnn significantly outperforms the   tier svm solution in terms of human  and non human recalls  even with features learned from the raw  time series. similarly  for the   class case  our solution provides  much more stable noise robustness and is generally superior even  to the much heavier svm solution.             .    .    .   svm   f    tier   svm   f    class   msc rnn     .    .          noise  source                             k     a  disp. duration cdf  partial   b  impact of k on emi recalls    figure    source detected duration cdf for the data in table   a  and how the hyperparameter k in   class emi affects  their detection    second windows      .           .    .    .   svm   f    tier   svm   f    class   msc rnn     .    .          window len.  s         .              b  non human recall    accuracy  svm   f  msc rnn     class    .      .      .        .     window len.  s      a  human recall    win.  len.  s      .      values                       sigmoid  tanh  sigmoid  tanh       .    .     .   adam   .     .    .              e   e   e    .     .    .      .   .            c    svm     .       .          emi fastgrnn    hyperparameter  batch size  hidden size  gate nonlinearity  update nonlinearity  k  keep prob.  emi lstm   optimizer    non human recall     . .  hyperparameters. table   lists the hyperparameter combinations used in our experiments. for the upper tier source discrimination comparison in section  . .   fastgrnn is also allowed to  select its optimum input length from         and    samples.  the selection of the emi hyperparameter k merits some discussion  in that it controls the extent of  strictness  we assign to the  definition of displacement. a higher k makes it more difficult for  a current window to be classified as a source unless the feature of  interest is genuinely compelling. expectedly  this gives a trade off  between clutter and source recall as is illustrated in figure   b . as  explained in section    controlling for false positives is extremely  important in radar sensing contexts such as intrusion detection.  hence  we empirically set k to     the smallest value that gives a  clutter recall of  .    or higher in our windowed datasets.    model    human recall    source by accumulating differences in successive phase measurements  whereby clutter can be filtered out. we contrast  msc rnn with a two tier solution proposed in       which  uses a robust variant of phase unwrapping with adaptive  filtering of clutter samples.   b    class svm. a clutter vs human vs non human svm solution that uses feature handcrafting.   c  emi fastgrnn. an emi version of fastgrnn  section   .   d  emi lstm. an emi version of the lstm. note that this is  a much heavier architecture than the former  and should not  be regarded as suitable for a microcontroller device.  since shallow featurization incurs high incremental overhead   real time micro power radar solutions typically avoid techniques  such as pca      logistic regression      or low dimensional projection     . instead  the    best features are selected using the max.  relevance  min. redundancy  mrmr       algorithm.  for the mil experiments  the windowed data from table   b   is further reshaped into instances of length      samples with  a fixed stride of       where   refers to the number of features   i and q components of radar data . for example  for   second  windows  the shape of the training data for mil experiments is                      and the shape of the corresponding instance level  one hot labels is               . in the interest of fairness and also to  avoid a combinatorial exploration of architectural parameters  we  present results at fixed hidden sizes of         and   . for msc rnn   the lower tier s output  embedding  dimension and upper tier s  hidden dimension are kept equal  however  in practice  it is easy  to parameterize them differently since the former only affects the  latter s input dimension.     .      .      .       clutter recall  svm   f  msc rnn     class    .      .      .        .      .      .        c  accuracy and clutter recall    class svm and msc rnn     figure    classification comparison of purely time domain  fastgrnn with two svm solutions   a  a   tier system using  a phase unwrapped clutter rejector as the lower tier  and  b   a   class svm. both use    high information features handcrafted in the amplitude  time  and spectral domains     buildsys      november              new york  ny    d. roy  s. srivastava  a. kusupati  p. jain  m. varma  and a. arora   .     miss probability    figure   contrasts our model with   class emi fastgrnn and  emi lstm  for fixed hidden sizes of         and    respectively.  it can be seen that msc rnn outperforms the monolithic emi  algorithms on all three metrics of accuracy  non human and human  recalls  with one exception for emi lstm . notably  cascading  significantly enhances the non dominant class recall over the other  methods  especially for larger hidden sizes  and therefore offers  better resilience to the source type imbalance in radar datasets.      outof      fa week     outof      fa month   emi fastgrnn  h         fa yr   emi fastgrnn  h         fa yr   emi fastgrnn  h         fa yr      .    .    .    .                                  displacement duration  s      . .  runtime efficiency comparison   msc rnn vs. feature handcrafting. table   lists the runtime duty cycle estimates of mscrnn versus shallow svm alternatives in two deployment contexts  with realistic clutter conditions  supported by usage statistics of  a popular biking trail in columbus  oh    . while the   tier svm  understandably has the lowest duty cycle due to a cheap lower  tier  it is not a competitive solution as established in section  . . .  the   class svm  on the other hand  is dominated by the feature  computation overhead. while the      msc rnn formulation is  about  .    as efficient as using handcrafted features  it is possible  to reduce instance level computations even further by using longer  input vectors and reducing the number of iterations. as an example   msc rnn with a    dimensional input vector is    more efficient  than feature engineering.  table    estimated featurization duty cycle comparison on  arm cortex m   architecture  msc rnn  inp. dim.     msc rnn  inp. dim.        tier svm    class svm    est. duty cycle  cortex m        clutter      clutter    .       .      .       .       figure    comparison of miss probabilities versus displacement durations of tier   classifier vs.   outof   phase unwrapped displacement detector  window length    seconds   the underlying displacement detector for the latter. for this experiment  we train a   class fastgrnn on embeddings derived from  the lower layer emi fastgrnn. table   compares its performance  with the upper tier svm from the latter when trained with the best     cross domain features obtained from the raw radar samples. it  can be seen that the purely time domain fastgrnn still generally  outperforms the   class svm on all three metrics of accuracy  human recall  and non human recall. thus  it is possible to replace  feature engineering with deep feature learning and enjoy the dual  benefits of improved sensing and runtime efficiency for this class  of radar applications.  table    independent of the tier   classifier  the tier    source type classifier outperforms the svm  win.  len.   s       .       .     .      .        . .  tier wise evaluation. we next compare the lower tier and  upper tier classifiers individually to their shallow counterparts in  the   tier svm solution.  tier   classifier. figure   compares the probabilities of missed detects versus displacement durations for the   outof   displacement  detector and the emi component of our solution with   second  windows  for a principled approach to choosing parameters for  the former  refer to appendix a  at hidden sizes of         and    . it can be seen that  for the shortest cut length of  .  s in the  dataset  the detection probability is improved by up to  .     .     over the   outof   detector with false alarm rates of   week and    month respectively even when the false alarm rate    test clutter  recall  of emi is    which translates to a false alarm rate of    per  year. further  the emi detector converges to   false detects with  displacements   .  s  and is therefore able to reliably detect walks   .   shorter than the previous solution. therefore  it is possible to  restrict false positives much below   month while significantly improving detectability over the m outof n solution. since the clutter  and source datasets span various backgrounds  figure     msc rnn  offers superior cross environmental robustness.  tier   classifier. we now show that the gains of msc rnn over  the   tier svm solution are not  in fact  contingent on the quality of        .             accuracy  svm     f    fastgrnn     .     .     .       .     .     .      human  recall  svm fast   f grnn    non human  recall  svm fast   f grnn     .     .     .       .     .     .       .     .     .       .     .     .      low power implementation    the radar sensor described in figure   a  uses an arm cortex m   microcontroller with    kb of ram and   mb of flash storage. it  runs emote       a low jitter near real time operating system with  a small footprint. we emphasize that energy efficient compute  not  working memory or storage  is the bigger concern for efficient  real time operation. hence  we take several measures to efficiently  implement the multi scale rnn to run at a low duty cycle on the device. these include low rank representation of hidden states  q    quantization  and piecewise linear approximations of non linear  functions. the latter in particular ensures that all the computations  can be performed with integer arithmetic when the weights and  inputs are quantized. for example  tanh x  can be approximated as   quantt anh x    max min x           and si moid x  can be approximated as  quantsi m x    max min  x               . the underlying  linear algebraic operations are implemented using the cmsis dsp  library    . while advanced arm processors such as cortex m   offer floating point support  it should be noted that  for efficiency  reasons  using sparse  low rank matrices and quantization techniques are beneficial in general.      .       .      .      .     .   emi fastgrnn  emi lstm  msc rnn     .          .     emi fastgrnn  emi lstm  msc rnn     .    .                window len.  s      .      .     .   emi fastgrnn  emi lstm  msc rnn          .     human recall    accuracy     .       .      .       .    .      emi fastgrnn  emi lstm  msc rnn     .    .                 .      .     .   emi fastgrnn  emi lstm  msc rnn     .     human recall    accuracy     .       .           .          .      .    .     .    .      emi fastgrnn  emi lstm  msc rnn     .    .         emi fastgrnn  emi lstm  msc rnn     .           window len.  s      g  accuracy  h              .      .          window len.  s      .      .           .            .       .       .      c  non human recall  h         e  human recall  h         .       .      emi fastgrnn  emi lstm  msc rnn     .     window len.  s      d  accuracy  h         .      .    .      window len.  s      .      window len.  s      .       .    .            b  human recall  h         .       .      .      window len.  s      a  accuracy  h         .       .     non human recall     .      .    .       f  non human recall  h      non human recall     .       .      non human recall    buildsys      november              new york  ny     .      human recall    accuracy    multi scale  cascaded rnns for radar classification     .     .    .     .    .       .                window len.  s      h  human recall  h        emi fastgrnn  emi lstm  msc rnn     .    .          window len.  s      i  non human recall  h        figure    sensing performance comparison of msc rnn with emi fastgrnn and emi lstm         conclusion and future work    in this work  we introduce multi scale  cascaded rnns for radar  sensing  and show how leveraging the ontological decomposition  of a canonical classification problem into clutter vs. source classification  followed by source type discrimination on an on demand  basis can improve both sensing quality as well as runtime efficiency  over alternative systems. learning discriminators at the time scales  relevant to their respective tasks  and jointly training the discriminators while being cognizant of the cascading behavior between  them yields the desired improvement.  the extension of msc rnns to more complicated sensing contexts is a topic of future work. of interest are regression based radar   counting  problems such as occupancy estimation or active transportation monitoring  where the competitiveness of msc rnn to  architectures such as tcns     could be insightful. we also believe  that msc rnn could also apply to alternative sensing for smart  cities and built environments where the sources have intrinsic ontological hierarchies  such as in urban sound classification    .    acknowledgements  we thank our shepherd  zheng yang  and the anonymous reviewers  for their comments. we are indebted to don dennis  prateek jain     and harsha vardhan simhadri at microsoft research india for their  suggestions and feedback. the computation for this work was supported by the ohio supercomputer center     project pas      the  iit delhi hpc facility  and azure services provided by microsoft research summer workshop       machine learning on constrained  devices   .    