introduction  scene labeling is a fundamental task in computer vision.  its goal is to assign one of many pre defined category la      bels to each pixel in an image. it is usually formulated  as a pixel wise multi class classification problem. modern scene labeling methods rely heavily on convolutional  neural networks  cnns                 . cnns are capable of learning scale invariant discriminative features for  images. these features have proven more powerful than  traditional hand crafted features on many computer vision  tasks             . specially designed cnn architectures                     have shown superior performance on scene  labeling by using end to end training.  however  cnns have challenges in dealing with local  textures and fine structures in images and tend to oversegment or under segment objects in images. to accurately  segment small components and detect object boundaries   long range contextual dependencies in images are usually  desired when designing scene labeling algorithm. many  works have exploited probabilistic graphical models such as  conditional random fields  crfs       to capture structural  dependencies in images         . however  crfs usually  require carefully designed potentials and their exact inference is usually intractable. in contrast  recurrent neural networks  rnn   as another category of powerful contextual  dependency modeling methods  are free from these disadvantages and can learn contextual dependencies in a datadriven manner.  rnns have first proven effective in modeling data dependencies in domains such as natural language processing and speech recognition         . recently  there are  some attempts at applying rnns to images                .  because the spatial relationship among pixels in  d image  data is fundamentally different from the temporal relationship in the  d data in nlp or speech recognition  variants  of rnn architectures                              have been  proposed to handle  d image data  which typically involve  unfolding a  d lattice grid into a  d sequence. the unfolded  d sequence is usually much longer than the data  sequence in nlp or speech recognition. take a feature map  of size         for example. its unfolded  d sequence is of  length               . one major flaw of applying existing rnn units to sequences of such a long length is that the   impact vanishing  problem will raise and break the spatial  dependencies in images.  it is well known that long term dependency is hard to  learn in rnn units due to the gradient exploding or vanishing problems and rnn units such as long short term  memory  lstm  or gated recurrent unit  gru  can effectively avoid these problems. however  in this work  we  empirically show that even in lstms or grus  the dependency in a extremely long range is still hard to capture due  to the  impact vanishing  problem.  first  this paper studies the  impact vanishing  problem  when traditional rnns are applied to image data. then   we generalize traditional rnn units to rnn units with ex     plicit long range conditioning  rnn elc  to overcome  this problem. specifically  two variants  gru elc and  lstm elc  are designed and discussed.  compared with existing works                                rnn elcs can effectively capture long range contextual dependency in images with the help of their explicit long range conditioning architecture. in the rnnelc units  the present variable is explicitly conditioned on  multiple contextually related but sequentially distant variables. intuitively  it is adding skip connection between hidden states. adding skip connections in rnns to help learn  long term dependency first appears in     . our method  generalizes the idea to model more complex  d spatial dependencies. the rnn elc unit is applicable to both raw  pixels and image features. it can be naturally integrated in  cnns  thereby enabling joint end to end training.  in order to take the benefits of the new rnn units for  scene labeling tasks  we build a novel scene labeling system  using the gru elc units to model long range multi scale  contextual dependencies in image features.  in summary  our main contributions include     an empirical study of the  impact vanishing  problem  which  commonly exists in traditional rnn units when they are  applied to images     a new rnn unit with explicit  long range conditioning to alleviate the  impact vanishing  problem     a novel scene labeling algorithm based  on gru elcs. there are a few works utilizing grus for  scene labeling. however  we show that our gru elc units  can actually achieve state of the art performances in scene  labeling tasks  and    improved performances on several  standard scene labeling datasets.     . related work  scene labeling is one of the most challenging problems  in computer vision. recently  convolutional neural network  based methods achieved great success in this task. farabet et al.     made one of the earliest attempts at applying hierarchical features produced by cnns to scene labeling. eigen et al.     designed a multi scale convolutional  architecture to jointly segment images  predict depth  and  estimate normals for an image. long et al.      applied  fully convolutional network  fcn  to this task. noh et al.       also used deconvolution layers for image segmentation.  they adopted an encoder decoder architecture  where encoder part consists of convolution and pooling operations  and decoder part consists of deconvolution and unpooling  operations. badrinarayanan et al.     designed a similar  architecture named segnet. in       yu and koltun developed a dilated convolutional module to preserve multi scale  contextual information for image segmentation.  although cnn based methods introduced powerful  scale invariant features for scene labeling  they performed  poorly in preserving local textures and fine structures in     predictions. these problems were addressed by combining cnns with probabilistic graphical models such as conditional random fields  crfs . chen et al.     suggested  to put a fully connected crf      on top of fcn to capture structural dependencies in images. zheng et al.       showed that cnn and crf can be jointly trained by passing the inference errors of crfs back to cnn. liu et al.       improved      by introducing a more complex pairwise  term for crf. crf based methods usually require carefully  designed pair wise potentials and unfortunately their exact  inference is usually intractable.  rnns  as another powerful tool for modeling contextual  dependences in data  have achieved tremendous success in  many areas such as speech recognition      and natural language processing     . there is also a rich literature of using rnns for image related tasks                    .  liang et al.      designed a graph lstm to handle image data. however  their method is built on superpixels   which is computationally expensive and is not directly applicable to image features. byeon et al.     developed  a scene labeling method based on a  d lstm network   which first divided an input image into non overlapping  patches and then sequentially fed them into lstm networks  in four different orders.      built a rnn segmentation algorithm based on recently proposed renet     . their idea  was to to alternatively sweep an image in different directions and then sequentially input each row  or column  into  a rnn. shuai et al.          designed a quaddirectional  d  rnn architecture for scene labeling  where each pixel was  connected to its   nearest neighbors.  long range contextual dependencies are usually desired  for scene labeling tasks. in previous works                                the present variable only explicitly conditions on variables within a short range such as its   nearest  neighbors. however  as shown later  short range conditioning does not capture long range structural dependencies in  images. our labeling algorithm is a generalized version of              . but our model is different with them in that  i   our model is built upon a new rnn unit  gru elc unit   which is free of  impact vanishing  problem   ii . our models can effectively utilize multi scale contextual dependencies to provide better scene labeling performances.    probability of current time step output  p  y t  xt   ht          by the following equations     ht    h  xt wx   ht   wh   bh     t    y    y  h wy   by       it    i  xt wxi   ht   whi   wci  t    t    t      f    f  x wxf   h  t    c   ft    a vanilla rnn unit has two types of dense connections   namely  input to hidden and hidden to hidden connections.  at each time step t  the output y t conditions on the input  at current time step xt and the hidden state at previous time  step ht   . mathematically  given a sequence of input data  x    xt   t      ...  t    the vanilla rnn unit models the           whf   wcf    ct     bi             ct     bf             t    ct     it    t     c  x wxc   ht   whc   bc          t    o    o  x wxo   ht   who   wco  t    h  o    t    ct   bo      t     h  c                  grus compute the output by the following equations  with wxr hr xu hu xc hc and br u c being parameters.    rt    r  xt wxr   ht   whr   br    t    t      u    u  x wxu   h  t    t    c    c  x wxc   r  t     . . recurrent neural network           where      wx h y   bh y   is the parameter and  h and  y  are the nonlinearity functions of hidden and output layers   respectively. y t explicitly conditions only on xt and ht      but ht   explicitly conditions on previous input xt   and  hidden state ht     thus  y t actually implicitly conditions on  all previous inputs and hidden states. therefore  previous  variables can influence their following variables by passing  information through the hidden states.  however  vanilla rnns have the notorious gradient vanishing or exploding problem when they are applied to learn  long term dependencies        . in practical applications   two types of gated rnns are developed to avoid this problem  long short term memory  lstm  network      and  gated recurrent unit  gru  network    .  lstm uses the following equations to update its hidden states. let it   f t   ct   and ot denote the output of the  input gate  the forget gate  the cell gate  and the output  gate  respectively.  denotes element wise multiplication.  wxi xf xc xo hi hf hc ho   wci cf co   and bi f c o are parameters.  i f c o are nonlinearity functions.    t     . recurrent neural networks with explicit  long range conditioning    t    t    h        u      t    whu   bu      t       h    t      h    whc     bc    t     u    t    c                            lstms and grus have been widely used in modeling  long term dependencies as they can effectively prevent gradients from vanishing or exploding    . however  they are  still limited for image related applications because the  impact vanishing  is hard to avoid when dealing with a very  long sequence..      a  original  d image grid   a      b      c      d      b  unfolded image grid modeled by traditional rnn unit    figure    illustration of  impact vanishing  problem in  lstms and grus. fluctuation denotes the difference  caused by changing the first data x  in input sequence.   c  unfolded image grid modeled by rnn elc units     . . impact vanishing problem  here we design a concise and straightforward toy example to empirically demonstrate the existence of  impact vanishing  problem in lstm gru units.  assume x    xt   t      ...  t   is an input sequence.  t  x   rm  n is the input data at time step t. in this toy  example  xt is generated from a continuous uniform distribution u        and all weight parameters w in lstms and  grus are initialized with a guassian distribution n      .    and bias parameters are set to zero.  firstly  the entire sequence x is fed to lstms grus  which output y    y t   t      ...  t  . then  the data at  the first time step x  is replaced with x   which is generated  from same distribution u        and get a new input data sequence x     x     x    ...  xt  . feed x  to the same rnns  and get the new output y     y      y      ...  y  t  . if the information of the first input can successfully pass through  hidden states and make impact on following variables  we  should expect y  t to be different with y t when x  changes.  to measure how different y  t becomes  we calculate the following fluctuation metric        f    mn  t    m n  x    t    t     y  i  j    y   i  j                   i   j      we repeat this process by    times  collect all f t   and  report the mean of all    f t in the top left plot in fig. .  it shows that f t drops dramatically in the first    time  steps. when t       f t decreases to zero  which means  that y t stays unchanged when t      regardless of the  initial input x  . although ht implicitly depends on h   and x    the dependency between the  th and tth variables is actually broken when t     . in another word   p  ht  ht     ...  h    h      p  ht  ht     ...  h    when t     .    figure    graphical illustration of unfolding  d image data  into  d sequence and applying rnn units.    this phenomenon is referred as  impact vanishing  problem in this paper.  the mechanics behind  impact vanishing  problem is  similar to the gradient vanishing exploding problem     .  the tth variable makes impact on following variables by  storing its information in ht and passing it to following hidden states. during the flow  ht will be multiplied by fixed  weight matrixes many times. if the spectral radius of the  weight matrix is smaller than    the multiplication results  will vanish to zero. and if the spectral radius is larger than     multiplication results will explode to infinity and thus saturates the sigmoid and tanh functions. in both cases  information stored in ht has decreasing impact on ht k when k  becomes larger.     . . rnn units with explicit long range conditioning  the consequence of  impact vanishing  problem is that  dependencies between spatially related variables are broken. take the       image grid in fig. a for example. x   and x  are both degree   neighbors of x  . however  after  unfolding it into a  d sequence in a given direction  from  left to right and top to bottom  and applying a rnn to it  x   is only directly conditioned on variable x  . the information  from x  needs to flow through two more variables and then  impacts on x  . from the toy example in previous section   we know that when a large image neighborhood is involved   this impact will vanish in practice.  in order to overcome the  impact vanishing  problem  and bring back the contextual dependency  we generalize     figure    illustration of our scene labeling algorithm described in section  . blue cuboids denote a convolution  layer followed by a pooling layer. red blocks denote gruelc units with arrow representing the unfolding direction.  purple cuboids denote concatenation operation. yellow  cuboids denote a unpooling layer followed by a convolution  layer. in the gru elc block  s parallel branches are used  to model contextual dependencies between current variable  with its degree       ...  s neighbors. in each branch  four  gru elc units are used to model dependency relations in  four different unfolding directions. note that   denote concatenation operation here.  existing rnn units to incorporate with long range conditioning. mathematically  a vanilla rnn elc unit has the  following formulation      h    h  x wx    ht     ht s  wh   bh        t    t            ht s is the explicit long range conditioning and s is a conditioning skip stride.    is a constant term to keep ht stay in the  valid activation area of  h . this rnn elc unit models the  following conditional probability  p  y t  xt   ht     ht s     .  note that no extra weights are introduced here.  in the scenario in fig. a  we can set s     and the resulting graphical model is presented in fig. c. now  the information from x  flows directly into x  via a skip connection  and the impact from x  is back now.  in order to test the efficiency of the proposed rnn elc  units     we use the same data and weights as in previous  section and run the toy example again. the conditioning  skip stride s is set as    here. after repeating each experiment for    times  f t is plotted in the top right plot in fig. .  compared with a traditional lstm gru unit  f t of elclstm gru unit drops faster due to the constant term    .    it    is straightforward to generalize equation      for an lstm gru  unit. so we don t present them here for space reason    but  there is a strong peak around time step     which does  not exist in tradition rnn units. intuitively  the peak means  there is a strong dependency between the tth and  t   s th  variable  t      in this toy example  in rnn elc units  now as changing  t   s th variable has a huge impact on the  output of the tth variable.  in real world scenarios  a long range dependency is usually desired. the tth pixel could be treated as related to all  k pixels vertically above it. in this case  we need to model  the dependency between the tth variable and the  t   s th     t    s th   ...   t   ks th variables.  the top right plot in fig.  shows that the conditioning  encoded by equation      is still not powerful enough as  the peak around time step    is relatively smaller and f t  decreases to near zero again when t     . so  equation       is further generalized as below. k can be called as a  conditioning scale.  ht    h  xt wx   h t wh   bh    ht      k  x      ht      ht i s    k    i                    equations           are tested against the toy example  again. s is set to be    and k is set to be   and  . f t is  reported in the second row in fig. . it shows that by explicitly conditioning on related variables in a longer range  the  length of valid dependency becomes longer. next sections  show how to exploit this property of rnn elc units and  build a model for scene labeling which captures a desired  long range contextual dependency.     . scene labeling using gated recurrent units  with explicit long range conditioning  an overview of our scene labeling algorithm is presented  in fig. . it is based on gru elc units  and cnns. there  are three blocks  convolution block  gru elc block  and  final prediction block. the convolution block encodes images into features. it is initialized by certain layers from  vgg    network     . the final prediction block uses unpooling layers followed by convolution layers to make final  predictions of the same resolution as input images. this  block is trained from scratch. the gru elc block models  contextual dependencies over features.  a multi scale contextual dependency is encoded in our  gru elc block. for each variable  its relations with  neighbors from degree   to degree s are modeled in our  framework. take the  d grid in fig.  a for example. assume the grid is of width w and is unfolded into a  d sequence from left to right and top to bottom. for variable t     we choose gru elc units here instead of lstm elc units because  gru elc units decay slower than lstm elc units in our toy example  as shown in fig.       ht        t s   h    ht w s s   ht w s   ht w s s            rt    r  xt wxr   h t whr   br          ut    u  xt wxu   h t whu   bu    t     a  original  d grid and dependency relation.     b  graphical model of traditional gru unit.     c  graphical model of gru elc unit for degree s dependency of  the tth variable.    figure    graphical model examples of gru elc units.  note that in  d  only the graphical models of variable t and  its degree   neighboring variables are drew here. all other  variables are ignored as they are not implicitly dependent  with variable t.    tanh        denote the sigmoid activation  tangent activation  element wise addition  and   minus  input  respectively. best viewed with zoom in.    its degree   neighbors include the  t     th    t   w     th     t   w th    t   w     th variables and its degree   neighbors include the  t     th    t    w     th    t    w th   and   t    w     th variables   .  for dependency in degree k  a group of   gru elc  units is utilized  one gru elc unit for one unfolding direction. four directions are considered in our framework  as inspired by            . take the left to right and top tobottom direction for example. following the mechanics as  equations              the gru elc unit obeys the following equations.    t    c    c  x wxc   r  t    t    h        u      t    t             h whc     bc              t            t    h  u    t    c    here w is the width of input grid. for the scenario in  fig.  a  graphical model of gru elc unit used for degree  s dependency is presented in fig.  c. the blue lines denote the long range conditioning in gru elc units. they  are skip connections which help hidden states from neighboring variables flow directly into current variable. note  that in equation              variable t only conditions on its  degree s neighboringing variables. other neighboring variables will be modeled by other groups of gru elc units in  our scene labeling framework. all information will be aggregated together by concatenation operations and then fed  into final prediction block.     . experiment  in order to cover both outdoor and indoor scenes  we  select three challenging datasets to test our method  namely  the siftflow       nyudv        and stanford background       datasets. two metrics are used for evaluation  namely  global pixel accuracy  global  and average per class accuracy  class . first  a full exploration of different architecture choices is conducted on siftflow. then  state of theart results are presented for nyudv   and stanford background dataset.  the convolution block in fig.   is initialized by certain  layers from vgg    network     . equivalent number of  uppooling and convolution layers are used in final prediction block.  all experiments follow a same training protocol. images  with original size are used for training testing. the training process ends after    epochs for all models. the initial  learning rate is set as  .    and the poly learning policy is  adopted to decrease the learning rate after every epoch. all  models use recently developed adam solver      for gradient descent training. the cross entropy loss is used as objective function. median frequency balancing     is applied  for comparison. widely used data augmentation  cropping   flipping  and random jittering are adopted.     . . the siftflow dataset      note that we only consider neighboring variables in diagonal  vertical     and horizontal directions. because conditioning on too many variables in  one rnn elc unit will increase k in equation    and make the impact  decay faster.    the siftflow dataset contains       images with    object categories. all images are of size         and are captured in outdoor scenes like coast  highway  forest  city  etc.  all experiments follow the same           training testing  split as convention.     method  conv  decoder  conv  gru  conv  elc    conv  elc    conv  elc    conv  decoder  conv  gru  conv  elc    conv  elc    conv  elc      no balancing  global     class        .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     median balancing  global     class        .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     table    performance comparison of different choices for gru elc block on siftflow. the notation convention is    .  convx decoder denotes this model is built on top of the convx   layer of vgg    net and no gru elc block is used. only  final prediction block is stacked on top of convolution block    . convx   gru denotes only traditional gru units are used  in the model     convx elc s denotes gru elc units are used and the dependencies up to degree s is modeled.    figure    comparison between models with different settings of gru elc block in our system. all models are  trained with median frequency balancing. note that the  black color denotes unknown categories.    first  we explore different architecture choices for proposed scene labeling algorithm. we build our system on top  of conv    or conv    layer in vgg    net. we also tested  the conv    layer but the performance is not comparable so  we don t report it here. for each feature layer choice  different contextual dependency ranges  s set as       and    are  tested. we also run experiments for architectures without  gru units for comparison. all results are reported in table   .  experimental results show that gru elc models have  superior performances compared with models where only    gru units or no rnn units are used. some prediction results are visualized in fig.  . generally  models with longer  contextual dependencies have better quantitive and visual  performances. this demonstrates that the newly designed  gru elc units can effectively model desired long range  structure dependencies in images. specifically  elc   gives  much better performance than elc  . but elc   only has  subtle improvements compared to elc  . considering the  fact that elc   requires more computations  elc   actually is a better setting in our system. note that our models  built upon conv    give better results than conv   . however  this is not conclusive as we found conv    layer features could give better results on some other datasets. another observation to notice is that median frequency balancing helps the model achieve better average per class accuracy but the global pixel accuracy is sacrificed  which has  also been found in               .  our methods are also compared with other state of theart results in table  . comprehensive comparisons show  that our methods can outperform both rnn based and other  state of the art methods. especially the average class accuracy has been improved by near  .  . these results show  that the proposed algorithm with gru elc units can effectively model long range contextual dependencies in images  and thus benefit the scene labeling task a lot. results produced by our algorithm and fcn  s      are visually compared in fig. .     . . the nyudv  dataset  nyudv  is a rgb d dataset containing       rgb and  depth image pairs for indoor scenes. standard split contains      training images and     testing images.    categories       have been widely used to test the performance of la      method  attent to rare class       fcn   s       eigen et al.      eigen et al.     mb  parsenet       rcnn       dag rnn       rnn based  multi path       attention      conv  lc gru    conv  lc gru   mb    global        .     .     .     .     .     .     .     .     .     .     .     class        .     .     .     .     .     .     .     .     .     .     .     table    comparison with state of the art on siftflow. our  method is compared against rnn related and other stateof the art methods. mb denotes this model is trained with  median frequency balancing.    petitive against other methods which additionally use depth  or normal information.     . . the stanford background dataset  the stanford background dataset is composed of      images with   object categories. the images are captured  in outdoor scenes and most of them are of size        .  following the standard protocol       a   fold cross validation is used for measuring the performance  each of them  randomly selects     images for training and     images  for testing. the conv  elc   setting is adopted for this  dataset. results of our method are reported and compared  with other state of the art methods in table. . state of thearts results demonstrate the effective of long range dependency for scene labeling problems.     . conclusion  rnns are a class of neural network models that have  proven effective in modeling internal data dependencies in  many areas. there are also many works applying rnns for  image data. in this work  we empirically show that traditional rnn units are not powerful enough to model dependencies in very long sequences due to the  impact vanishing  problem. a new rnn unit with explicit long range  conditioning is designed to avoid this problem. based on  the rnn elc units  a new scene labeling algorithm is developed in this paper. various experimental results and  comparisons with other state of the art methods demonstrate that our algorithm can effectively capture long range  structure dependencies in images and thus give better performances in scene labeling.  potential directions for future works include    . extend our scene labeling algorithm to take multi modal input  information  like depth or normal information      apply  our new rnn elc unit to other image related applications  such as image inpainting and image generation.    figure    comparisons of results produced by fcn  s       and conv  elc   trained with median frequency balancing.  conv  elc   can accurately predict small objects in scenes  such the persons  poles  boards  and windows. note that the  black color denotes unknown categories.    beling algorithms. besides rgb images  depth information           and normal information     can also be used for  scene labeling. only rgb images are used in our algorithm  in order to get a clear sense about the capacity of our algorithm. the conv  elc   setting is applied for this dataset.  the comparison between our method and other state of theart methods are reported in table. . although only rgb information is used in our method  our results are quite com     appendices  a. network architecture  here we give details about our scene labeling network.  the convolution block in our network is initialized by  certain layers from vgg    network     . all conv  models are built on top of the conv    layer from vgg    network. and all conv  models are built on top of the conv     layer.  in conv  models  the final prediction block consists of  u  c    u  c    c   cn. here u denotes the upsampling layer and cx denotes a convolutional layer with  x feature maps. n is the number of categories. kernels of  size       are used in all convolutional layers except the last  one which uses     kernels. note that   up sampling layers     input information  rgb  rgb  rgb  rgb depth  rgb depth  rgb depth  rgb depth  rgb depth  rgb depth  rgb depth normal    method  fcn   s rgb       conv  elc    conv  elc   mb  gupta et al.          gupta et al.          fcn   s rgbd       fcn   s rgb hha       fcn   s rgb hha       wang et al.       eigen et al.        global        .     .     .     .     .     .     .     .     .     class        .     .     .     .     .     .     .     .     .     .     table    comparison with state of the art on nyu. mb denotes this model is trained with median frequency balancing.  method  sharma et al.       mostajabi et al.       liang et al.       multi path       conv  elc    conv  elc   mb    global        .     .     .     .     .     .     class        .     .     .     .     .     .     table    comparison with state of the art on stanford  background dataset.mb denotes this model is trained with  median frequency balancing.    are used here to upscale feature maps to the same resolution  of input. in all conv  models  the final prediction block  uses the follow architecture  u   c      u   c      u    c      c     cn.  in the gru elc block      feature maps are used in  each gru elc unit.    b. extended results  b. . per class analysis on the siftflow dataset  here we give a detailed list of per class accuracy produced by our best model  conv  elc   m b   on siftflow dataset. they are organized in table   in ascending  order by the data portion in training set. for example  there  are   .     of the training data  pixels  are sky but only   .     are bird.  generally  the model performs quite well on categories  with large amount of training data like sky  building  mountain  tree  road  etc. moreover  our model can also give reasonable performances on some categories where only limited training data are available. for example  our model  has a   .   accuracy on sun even when there are only   .     of training data are sun. on some other rare categories  such as sign  crosswalk  person  window  sidewalk     and sand  we have accuracies above average. we argue  that there are two main reasons for the good per class performances. firstly  our model can effectively capture long  range contextual dependencies in images and thus yields a  good performance on small objects which are usually rare  categories  such as the persons and poles shown in fig.   in  the main text . secondly  the median frequency balancing  is used in our conv  elc   m b model  which helps to  improve performances in rare categories  as also shown in               .    b. . visual results on the nyudv  and stanford  background dataset  some predictions on the nyudv  dataset produced by  our conv  elc   m b model are visualized in fig.  . results produced by     and      are compared in fig.   as  well. from fig.   we can see that our model performs  much better in local details than other two models in these  samples  such as the monitors in the first sample image  the  tv screen in the second sample image  and the objects on  the desk in the third sample image.  fig.   presents some samples of our results on the stanford background dataset. these results show that our model  can effectively detect boundaries and accurately segment  small objects in images  such as the poles  animals  persons   and vehicles in images.    