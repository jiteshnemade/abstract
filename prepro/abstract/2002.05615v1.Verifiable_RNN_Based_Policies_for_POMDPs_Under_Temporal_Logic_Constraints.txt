
recurrent neural networks (rnns) have emerged
as an effective representation of control policies in
sequential decision-making problems. however, a
major drawback in the application of rnn-based
policies is the difficulty in providing formal guarantees on the satisfaction of behavioral specifications,
e.g. safety and/or reachability. by integrating techniques from formal methods and machine learning,
we propose an approach to automatically extract a
finite-state controller (fsc) from an rnn, which,
when composed with a finite-state system model,
is amenable to existing formal verification tools.
specifically, we introduce an iterative modification
to the so-called quantized bottleneck insertion technique to create an fsc as a randomized policy with
memory. for the cases in which the resulting fsc
fails to satisfy the specification, verification generates diagnostic information. we utilize this information to either adjust the amount of memory in
the extracted fsc or perform focused retraining of
the rnn. while generally applicable, we detail the
resulting iterative procedure in the context of policy synthesis for partially observable markov decision processes (pomdps), which is known to be
notoriously hard. the numerical experiments show
that the proposed approach outperforms traditional
pomdp synthesis methods by 3 orders of magnitude within 2% of optimal benchmark values.

1 