

1

the need of interpreting deep learning (dl) models has led, during the past years, to a proliferation
of works concerned by this issue. among strategies
which aim at shedding some light on how information is represented internally in dl models, one consists in extracting symbolic rule-based machines from
connectionist models that are supposed to approximate well their behaviour. in order to better understand how reasonable these approximation strategies
are, we need to know the computational complexity
of measuring the quality of approximation. in this
article, we will prove some computational results related to the problem of extracting finite state machine (fsm) based models based on trained rnn language models. more precisely, we’ll show the following: (a) for general weighted rnn-lms with a single hidden layer and a relu activation: - the equivalence problem of a pdfa/pfa/wfa and a weighted
first-order rnn-lm is undecidable; - as a corollary,
the distance problem between languages generated by
pdfa/pfa/wfa and that of a weighted rnn-lm is
not recursive; -the intersection between a dfa and the
cut language of a weighted rnn-lm is undecidable; the equivalence of a pdfa/pfa/wfa and weighted
rnn-lm in a finite support is exp-hard; (b) for consistent weight rnn-lms with any computable activation function: - the tcheybechev distance approximation is decidable; - the tcheybechev distance approximation in a finite support is np-hard. moreover, our
reduction technique from 3-sat makes this latter fact
easily generalizable to other rnn architectures (e.g.
lstms/rnns), and rnns with finite precision.

recurrent neural networks and their different variants
represent an important family of deep learning models
suitable to learning tasks with sequential data. however, just like all deep learning models in general, this
class of models lacks interpretability, which restricts its
applicability to highly critical tasks related for instance
to security and health, where a formal specification of
systems is a mandatory requirement to be approved for
deployment in real-case situations. due to the crucial
importance of this limitation, the awareness of providing both expressive and interpretable models keeps
growing within the deep learning community, resulting in a proliferation of research works focusing on this
topic. in general, two major paradigms have been explored in the literature to tackle this issue:

mots-clef : recurrent neural networks, finite state
machines, distances, equivalence.

• post-hoc methods: techniques belonging to this
family subsume the existence of an already trained

